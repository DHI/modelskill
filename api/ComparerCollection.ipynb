{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "# ComparerCollection\n",
        "\n",
        "``` python\n",
        "ComparerCollection(self, comparers)\n",
        "```\n",
        "\n",
        "Collection of comparers.\n",
        "\n",
        "The `ComparerCollection` is one of the main objects of the `modelskill`\n",
        "package. It is a collection of\n",
        "[`Comparer`](../api/Comparer.html#modelskill.Comparer) objects and\n",
        "created either by the [`match()`](../api/match.html#modelskill.match)\n",
        "function, by passing a list of Comparers to the\n",
        "[`ComparerCollection`](../api/ComparerCollection.html#modelskill.ComparerCollection)\n",
        "constructor, or by reading a config file using the\n",
        "[`from_config()`](../api/from_config.html#modelskill.from_config)\n",
        "function.\n",
        "\n",
        "NOTE: In case of multiple model results with different time coverage,\n",
        "only the *overlapping* time period will be used! (intersection)\n",
        "\n",
        "Main functionality:\n",
        "\n",
        "-   selecting/filtering data\n",
        "    -   `__get_item__()` - get a single Comparer, e.g., `cc[0]` or\n",
        "        `cc['obs1']`\n",
        "    -   [`sel()`](../api/ComparerCollection.html#modelskill.ComparerCollection.sel)\n",
        "    -   `query()`\n",
        "-   skill assessment\n",
        "    -   [`skill()`](../api/ComparerCollection.html#modelskill.ComparerCollection.skill)\n",
        "    -   [`mean_skill()`](../api/ComparerCollection.html#modelskill.ComparerCollection.mean_skill)\n",
        "    -   [`gridded_skill()`](../api/ComparerCollection.html#modelskill.ComparerCollection.gridded_skill)\n",
        "        (for track observations)\n",
        "-   plotting\n",
        "    -   [`plot.scatter()`](../api/comparison.ComparerCollectionPlotter.html#modelskill.comparison.ComparerCollectionPlotter.scatter)\n",
        "    -   [`plot.kde()`](../api/comparison.ComparerCollectionPlotter.html#modelskill.comparison.ComparerCollectionPlotter.kde)\n",
        "    -   [`plot.hist()`](../api/comparison.ComparerCollectionPlotter.html#modelskill.comparison.ComparerCollectionPlotter.hist)\n",
        "-   load/save/export data\n",
        "    -   [`load()`](../api/ComparerCollection.html#modelskill.ComparerCollection.load)\n",
        "    -   [`save()`](../api/ComparerCollection.html#modelskill.ComparerCollection.save)\n",
        "\n",
        "## Parameters\n",
        "\n",
        "| Name      | Type             | Description       | Default    |\n",
        "|-----------|------------------|-------------------|------------|\n",
        "| comparers | list of Comparer | list of comparers | *required* |\n",
        "\n",
        "## Examples\n",
        "\n",
        "``` python\n",
        ">>> import modelskill as ms\n",
        ">>> mr = ms.DfsuModelResult(\"Oresund2D.dfsu\", item=0)\n",
        ">>> o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n",
        ">>> o2 = ms.PointObservation(\"drogden.dfs0\", item=0, x=355568.0, y=6156863.0)\n",
        ">>> cmp1 = ms.match(o1, mr)  # Comparer\n",
        ">>> cmp2 = ms.match(o2, mr)  # Comparer\n",
        ">>> ccA = ms.ComparerCollection([cmp1, cmp2])\n",
        ">>> ccB = ms.match(obs=[o1, o2], mod=mr)\n",
        ">>> sk = ccB.skill()\n",
        ">>> ccB[\"Klagshamn\"].plot.timeseries()\n",
        "```\n",
        "\n",
        "## Methods\n",
        "\n",
        "| Name | Description |\n",
        "|------------------------------------|------------------------------------|\n",
        "| [skill](#modelskill.ComparerCollection.skill) | Aggregated skill assessment of model(s) |\n",
        "| [mean_skill](#modelskill.ComparerCollection.mean_skill) | Weighted mean of skills |\n",
        "| [gridded_skill](#modelskill.ComparerCollection.gridded_skill) | Skill assessment of model(s) on a regular spatial grid. |\n",
        "| [score](#modelskill.ComparerCollection.score) | Weighted mean score of model(s) over all observations |\n",
        "| [rename](#modelskill.ComparerCollection.rename) | Rename observation, model or auxiliary data variables |\n",
        "| [sel](#modelskill.ComparerCollection.sel) | Select data based on model, time and/or area. |\n",
        "| [save](#modelskill.ComparerCollection.save) | Save the ComparerCollection to a zip file. |\n",
        "| [load](#modelskill.ComparerCollection.load) | Load a ComparerCollection from a zip file. |\n",
        "\n",
        "### skill\n",
        "\n",
        "``` python\n",
        "ComparerCollection.skill(by=None, metrics=None, observed=False)\n",
        "```\n",
        "\n",
        "Aggregated skill assessment of model(s)\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---|----|----------------------------------------------------------------|---|\n",
        "| by | str or List\\[str\\] | group by, by default \\[“model”, “observation”\\] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data. - by attributes, stored in the cc.data.attrs container, e.g.: ‘attrs:obs_provider’ = group by observation provider or ‘attrs:gtype’ = group by geometry type (track or point) | `None` |\n",
        "| metrics | list | list of modelskill.metrics (or str), by default modelskill.options.metrics.list | `None` |\n",
        "| observed | bool | This only applies if any of the groupers are Categoricals. - True: only show observed values for categorical groupers. - False: show all values for categorical groupers. | `False` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type       | Description                             |\n",
        "|------|------------|-----------------------------------------|\n",
        "|      | SkillTable | skill assessment as a SkillTable object |\n",
        "\n",
        "#### See also\n",
        "\n",
        "sel a method for filtering/selecting data\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> import modelskill as ms\n",
        ">>> cc = ms.match([HKNA,EPL,c2], mr)\n",
        ">>> cc.skill().round(2)\n",
        "               n  bias  rmse  urmse   mae    cc    si    r2\n",
        "observation\n",
        "HKNA         385 -0.20  0.35   0.29  0.25  0.97  0.09  0.99\n",
        "EPL           66 -0.08  0.22   0.20  0.18  0.97  0.07  0.99\n",
        "c2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> cc.sel(observation='c2', start='2017-10-28').skill().round(2)\n",
        "               n  bias  rmse  urmse   mae    cc    si    r2\n",
        "observation\n",
        "c2            41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> cc.skill(by='freq:D').round(2)\n",
        "              n  bias  rmse  urmse   mae    cc    si    r2\n",
        "2017-10-27  239 -0.15  0.25   0.21  0.20  0.72  0.10  0.98\n",
        "2017-10-28  162 -0.07  0.19   0.18  0.16  0.96  0.06  1.00\n",
        "2017-10-29  163 -0.21  0.52   0.47  0.42  0.79  0.11  0.99\n",
        "```\n",
        "\n",
        "### mean_skill\n",
        "\n",
        "``` python\n",
        "ComparerCollection.mean_skill(weights=None, metrics=None, **kwargs)\n",
        "```\n",
        "\n",
        "Weighted mean of skills\n",
        "\n",
        "First, the skill is calculated per observation, the weighted mean of the\n",
        "skills is then found.\n",
        "\n",
        "Warning: This method is NOT the mean skill of all observational points!\n",
        "(mean_skill_points)\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---|--------|----------------------------------------------------------|---|\n",
        "| weights | str or List(float) or Dict(str, float) | weighting of observations, by default None - None: use observations weight attribute (if assigned, else “equal”) - “equal”: giving all observations equal weight, - “points”: giving all points equal weight, - list of weights e.g. \\[0.3, 0.3, 0.4\\] per observation, - dictionary of observations with special weigths, others will be set to 1.0 | `None` |\n",
        "| metrics | list | list of modelskill.metrics, by default modelskill.options.metrics.list | `None` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type       | Description                                  |\n",
        "|------|------------|----------------------------------------------|\n",
        "|      | SkillTable | mean skill assessment as a SkillTable object |\n",
        "\n",
        "#### See also\n",
        "\n",
        "skill skill assessment per observation mean_skill_points skill\n",
        "assessment pooling all observation points together\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> import modelskill as ms\n",
        ">>> cc = ms.match([HKNA,EPL,c2], mod=HKZN_local)\n",
        ">>> cc.mean_skill().round(2)\n",
        "              n  bias  rmse  urmse   mae    cc    si    r2\n",
        "HKZN_local  564 -0.09  0.31   0.28  0.24  0.97  0.09  0.99\n",
        ">>> sk = cc.mean_skill(weights=\"equal\")\n",
        ">>> sk = cc.mean_skill(weights=\"points\")\n",
        ">>> sk = cc.mean_skill(weights={\"EPL\": 2.0}) # more weight on EPL, others=1.0\n",
        "```\n",
        "\n",
        "### gridded_skill\n",
        "\n",
        "``` python\n",
        "ComparerCollection.gridded_skill(\n",
        "    bins=5,\n",
        "    binsize=None,\n",
        "    by=None,\n",
        "    metrics=None,\n",
        "    n_min=None,\n",
        "    **kwargs,\n",
        ")\n",
        "```\n",
        "\n",
        "Skill assessment of model(s) on a regular spatial grid.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---|-----|--------------------------------------------------------------|---|\n",
        "| bins | int | criteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,\\[2,3,5\\]) | `5` |\n",
        "| binsize | float | bin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y)) | `None` |\n",
        "| by | (str, List\\[str\\]) | group by, by default \\[“model”, “observation”\\] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data. | `None` |\n",
        "| metrics | list | list of modelskill.metrics, by default modelskill.options.metrics.list | `None` |\n",
        "| n_min | int | minimum number of observations in a grid cell; cells with fewer observations get a score of `np.nan` | `None` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type      | Description                            |\n",
        "|------|-----------|----------------------------------------|\n",
        "|      | SkillGrid | skill assessment as a SkillGrid object |\n",
        "\n",
        "#### See also\n",
        "\n",
        "skill a method for aggregated skill assessment\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> import modelskill as ms\n",
        ">>> cc = ms.match([HKNA,EPL,c2], mr)  # with satellite track measurements\n",
        ">>> gs = cc.gridded_skill(metrics='bias')\n",
        ">>> gs.data\n",
        "<xarray.Dataset>\n",
        "Dimensions:      (x: 5, y: 5)\n",
        "Coordinates:\n",
        "    observation   'alti'\n",
        "* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n",
        "* y            (y) float64 50.6 51.66 52.7 53.75 54.8\n",
        "Data variables:\n",
        "    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n",
        "    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> gs = cc.gridded_skill(binsize=0.5)\n",
        ">>> gs.data.coords\n",
        "Coordinates:\n",
        "    observation   'alti'\n",
        "* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n",
        "* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n",
        "```\n",
        "\n",
        "### score\n",
        "\n",
        "``` python\n",
        "ComparerCollection.score(metric=mtr.rmse, weights=None, **kwargs)\n",
        "```\n",
        "\n",
        "Weighted mean score of model(s) over all observations\n",
        "\n",
        "Wrapping mean_skill() with a single metric.\n",
        "\n",
        "NOTE: will take simple mean over different quantities!\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|---|--------|----------------------------------------------------------|----|\n",
        "| weights | str or List(float) or Dict(str, float) | weighting of observations, by default None - None: use observations weight attribute (if assigned, else “equal”) - “equal”: giving all observations equal weight, - “points”: giving all points equal weight, - list of weights e.g. \\[0.3, 0.3, 0.4\\] per observation, - dictionary of observations with special weigths, others will be set to 1.0 | `None` |\n",
        "| metric | list | a single metric from modelskill.metrics, by default rmse | `mtr.rmse` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type | Description |\n",
        "|--------|-----------------|-----------------------------------------------|\n",
        "|  | Dict\\[str, float\\] | mean of skills score as a single number (for each model) |\n",
        "\n",
        "#### See also\n",
        "\n",
        "skill skill assessment per observation mean_skill weighted mean of\n",
        "skills assessment mean_skill_points skill assessment pooling all\n",
        "observation points together\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> import modelskill as ms\n",
        ">>> cc = ms.match([o1, o2], mod)\n",
        ">>> cc.score()\n",
        "{'mod': 0.30681206}\n",
        ">>> cc.score(weights=[0.1,0.1,0.8])\n",
        "{'mod': 0.3383011631797379}\n",
        "```\n",
        "\n",
        "``` python\n",
        ">>> cc.score(weights='points', metric=\"mape\")\n",
        "{'mod': 8.414442957854142}\n",
        "```\n",
        "\n",
        "### rename\n",
        "\n",
        "``` python\n",
        "ComparerCollection.rename(mapping)\n",
        "```\n",
        "\n",
        "Rename observation, model or auxiliary data variables\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name    | Type | Description                       | Default    |\n",
        "|---------|------|-----------------------------------|------------|\n",
        "| mapping | dict | mapping of old names to new names | *required* |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type               | Description |\n",
        "|------|--------------------|-------------|\n",
        "|      | ComparerCollection |             |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> cc = ms.match([o1, o2], [mr1, mr2])\n",
        ">>> cc.mod_names\n",
        "['mr1', 'mr2']\n",
        ">>> cc2 = cc.rename({'mr1': 'model1'})\n",
        ">>> cc2.mod_names\n",
        "['model1', 'mr2']\n",
        "```\n",
        "\n",
        "### sel\n",
        "\n",
        "``` python\n",
        "ComparerCollection.sel(\n",
        "    model=None,\n",
        "    observation=None,\n",
        "    quantity=None,\n",
        "    start=None,\n",
        "    end=None,\n",
        "    time=None,\n",
        "    area=None,\n",
        "    **kwargs,\n",
        ")\n",
        "```\n",
        "\n",
        "Select data based on model, time and/or area.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name | Type | Description | Default |\n",
        "|----|----------|-------------------------------------------------------|----|\n",
        "| model | str or int or list of str or list of int | Model name or index. If None, all models are selected. | `None` |\n",
        "| observation | str or int or list of str or list of int | Observation name or index. If None, all observations are selected. | `None` |\n",
        "| quantity | str or int or list of str or list of int | Quantity name or index. If None, all quantities are selected. | `None` |\n",
        "| start | str or datetime | Start time. If None, all times are selected. | `None` |\n",
        "| end | str or datetime | End time. If None, all times are selected. | `None` |\n",
        "| time | str or datetime | Time. If None, all times are selected. | `None` |\n",
        "| area | list of float | bbox: \\[x0, y0, x1, y1\\] or Polygon. If None, all areas are selected. | `None` |\n",
        "| \\*\\*kwargs | Any | Filtering by comparer attrs similar to xarray.Dataset.filter_by_attrs e.g. `sel(gtype='track')` or `sel(obs_provider='CMEMS')` if at least one comparer has an entry `obs_provider` with value `CMEMS` in its attrs container. Multiple kwargs are combined with logical AND. | `{}` |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type               | Description                                |\n",
        "|------|--------------------|--------------------------------------------|\n",
        "|      | ComparerCollection | New ComparerCollection with selected data. |\n",
        "\n",
        "### save\n",
        "\n",
        "``` python\n",
        "ComparerCollection.save(filename)\n",
        "```\n",
        "\n",
        "Save the ComparerCollection to a zip file.\n",
        "\n",
        "Each comparer is stored as a netcdf file in the zip file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name     | Type        | Description               | Default    |\n",
        "|----------|-------------|---------------------------|------------|\n",
        "| filename | str or Path | Filename of the zip file. | *required* |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> cc = ms.match(obs, mod)\n",
        ">>> cc.save(\"my_comparer_collection.msk\")\n",
        "```\n",
        "\n",
        "### load\n",
        "\n",
        "``` python\n",
        "ComparerCollection.load(filename)\n",
        "```\n",
        "\n",
        "Load a ComparerCollection from a zip file.\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "| Name     | Type        | Description               | Default    |\n",
        "|----------|-------------|---------------------------|------------|\n",
        "| filename | str or Path | Filename of the zip file. | *required* |\n",
        "\n",
        "#### Returns\n",
        "\n",
        "| Name | Type               | Description                    |\n",
        "|------|--------------------|--------------------------------|\n",
        "|      | ComparerCollection | The loaded ComparerCollection. |\n",
        "\n",
        "#### Examples\n",
        "\n",
        "``` python\n",
        ">>> cc = ms.match(obs, mod)\n",
        ">>> cc.save(\"my_comparer_collection.msk\")\n",
        ">>> cc2 = ms.ComparerCollection.load(\"my_comparer_collection.msk\")\n",
        "```"
      ],
      "id": "a962b3cc-8132-4a73-9fe6-b4eb9c03762f"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}