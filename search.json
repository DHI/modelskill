[
  {
    "objectID": "examples/Prematched_with_auxiliary.html",
    "href": "examples/Prematched_with_auxiliary.html",
    "title": "Pre-matched data with auxiliary data",
    "section": "",
    "text": "import modelskill as ms\nimport numpy as np\nimport pandas as pd\nimport mikeio\nfn = \"../data/SW/eur_matched.dfs0\"\nmikeio.read(fn)\n\n&lt;mikeio.Dataset&gt;\ndims: (time:67)\ntime: 2017-10-27 00:00:00 - 2017-10-29 18:00:00 (67 records)\ngeometry: GeometryUndefined()\nitems:\n  0:  Hm0, model &lt;Significant wave height&gt; (meter)\n  1:  Hm0, obs &lt;Significant wave height&gt; (meter)\n  2:  Wind speed &lt;Wind speed&gt; (meter per sec)\n  3:  Wind Direction &lt;Wind Direction&gt; (degree)\nThe function from_matched() takes a dataframe, a dfs0 or a mikeio.Dataset of already matched data and returns a Comparer object.\ncmp = ms.from_matched(fn, obs_item=1, mod_items=0, aux_items=[2,3])\ncmp.aux_names\n\n['Wind speed', 'Wind Direction']\n# NOTE: we rename data_vars to avoid spaces in names\ncmp = cmp.rename({\"Wind speed\": \"wind_speed\", \"Wind Direction\": \"wind_dir\"})\ncmp.aux_names\n\n['wind_speed', 'wind_dir']\ncmp\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: Hm0, obs, n_points=67\nModel(s):\n0: Hm0, model\n Auxiliary: wind_speed\n Auxiliary: wind_dir\ncmp.skill()\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nobservation\n\n\n\n\n\n\n\n\n\n\n\n\nHm0, obs\n67\n0.052239\n0.22824\n0.222181\n0.174851\n0.968321\n0.085898\n0.929767\ncmp.plot.scatter(quantiles=0, figsize=(6,6));\ncmp.plot.timeseries();",
    "crumbs": [
      "Examples",
      "Prematched with auxiliary"
    ]
  },
  {
    "objectID": "examples/Prematched_with_auxiliary.html#filter",
    "href": "examples/Prematched_with_auxiliary.html#filter",
    "title": "Pre-matched data with auxiliary data",
    "section": "Filter",
    "text": "Filter\nFilter on auxiliary data using query() or where(). Below, we consider only wave data when the wind speed is above 15 m/s.\n\ncmp.query(\"wind_speed &gt; 15.0\")\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: Hm0, obs, n_points=19\nModel(s):\n0: Hm0, model\n Auxiliary: wind_speed\n Auxiliary: wind_dir\n\n\n\ncmp2 = cmp.where(cmp.data.wind_speed&gt;15.0)\ncmp2\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: Hm0, obs, n_points=19\nModel(s):\n0: Hm0, model\n Auxiliary: wind_speed\n Auxiliary: wind_dir\n\n\n\n# notice that the model data is kept, but the observations are filtered\ncmp2.plot.timeseries();\n\n\n\n\n\n\n\n\nMore auxiliary data can be added, e.g. as derived data from the original data.\n\ncmp.data[\"residual\"] = cmp.data[\"Hm0, model\"] - cmp.data[\"Observation\"]\n\n\nlarge_residuals = np.abs(cmp.data.residual)&gt;0.1\ncmp3 = cmp.where(large_residuals)\ncmp3.plot.scatter(figsize=(6,6));\ncmp3.plot.timeseries();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncmp3.data.data_vars\n\nData variables:\n    Observation  (time) float64 320B 0.92 1.03 1.24 1.34 ... 3.46 3.37 3.24 3.23\n    Hm0, model   (time) float64 320B 1.43 1.655 1.789 ... 3.634 3.531 3.473\n    wind_speed   (time) float64 320B 9.754 11.06 11.42 10.93 ... 13.3 13.3 13.54\n    wind_dir     (time) float64 320B 327.4 331.5 333.3 ... 343.0 340.8 343.6\n    residual     (time) float64 320B 0.5101 0.6253 0.5495 ... 0.2907 0.2427\n\n\n\ncmp3.data.Observation.values\n\narray([0.92000002, 1.02999997, 1.24000001, 1.34000003, 1.54999995,\n       1.65999997, 1.79999995, 2.1500001 , 2.20000005, 2.1500001 ,\n       2.1500001 , 2.08999991, 2.01999998, 2.02999997, 1.88999999,\n       1.76999998, 2.1099999 , 2.27999997, 2.31999993, 2.77999997,\n       2.72000003, 2.61999989, 2.79999995, 2.91000009, 2.96000004,\n       3.31999993, 2.86999989, 3.3599999 , 4.13000011, 4.01000023,\n       3.97000003, 3.8900001 , 4.17999983, 3.63000011, 3.79999995,\n       3.47000003, 3.46000004, 3.36999989, 3.24000001, 3.23000002])",
    "crumbs": [
      "Examples",
      "Prematched with auxiliary"
    ]
  },
  {
    "objectID": "examples/Prematched_with_auxiliary.html#aggregate",
    "href": "examples/Prematched_with_auxiliary.html#aggregate",
    "title": "Pre-matched data with auxiliary data",
    "section": "Aggregate",
    "text": "Aggregate\nLet’s split the data based on wind direction sector and aggregate the skill calculation of the significant wave height predition for each sector.\nNote: in this short example wind direction is between 274 and 353 degrees\n\ndf = cmp.data.wind_dir.to_dataframe()\nwindsectors = pd.cut(df.wind_dir,\n                                [255, 285, 315, 345, 360],\n                                labels=[\"W\", \"WNW\", \"NNW\", \"N\"])\ncmp.data[\"windsector\"] = windsectors.astype(str)\n\n\ncmp.skill(by=\"windsector\")\n\n\n\n\n\n\n\n\nobservation\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nwindsector\n\n\n\n\n\n\n\n\n\n\n\n\n\nNNW\nHm0, obs\n28\n0.115715\n0.285428\n0.260920\n0.230681\n0.969837\n0.103408\n0.927645\n\n\nN\nHm0, obs\n7\n0.070214\n0.252445\n0.242484\n0.222582\n0.991219\n0.082961\n0.859219\n\n\nWNW\nHm0, obs\n15\n-0.044628\n0.141796\n0.134590\n0.107524\n0.984303\n0.049652\n0.965368\n\n\nW\nHm0, obs\n17\n0.025762\n0.164749\n0.162723\n0.122650\n0.962449\n0.066609\n0.903978\n\n\n\n\n\n\n\n\ncmp.skill(by=\"windsector\").rmse.plot.bar(title=\"Hm0 RMSE by wind sector\");\n\n\n\n\n\n\n\n\n\ncmp.where(cmp.data.windsector==\"W\").plot.timeseries();",
    "crumbs": [
      "Examples",
      "Prematched with auxiliary"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html",
    "href": "examples/Gridded_NetCDF_ModelResult.html",
    "title": "Gridded NetCDF modelresults",
    "section": "",
    "text": "2D modelresults stored in NetCDF or Grib can be loaded to ModelSkill using xarray. In this way, MIKE 21 modelresults in dfsu format can easily be compared to model results from third party providers often stored in NetCDF.\nimport xarray as xr\nimport modelskill as ms",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#observations",
    "href": "examples/Gridded_NetCDF_ModelResult.html#observations",
    "title": "Gridded NetCDF modelresults",
    "section": "Observations",
    "text": "Observations\n\no1 = ms.PointObservation('../data/SW/HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\no2 = ms.PointObservation(\"../data/SW/eur_Hm0.dfs0\", item=0, x=3.2760, y=51.9990, name=\"EPL\")\no3 = ms.TrackObservation(\"../data/SW/Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#mike-modelresult",
    "href": "examples/Gridded_NetCDF_ModelResult.html#mike-modelresult",
    "title": "Gridded NetCDF modelresults",
    "section": "MIKE ModelResult",
    "text": "MIKE ModelResult\n\nmrMIKE = ms.model_result('../data/SW/HKZN_local_2017_DutchCoast.dfsu', name='MIKE21SW', item=0)",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#netcdf-modelresult",
    "href": "examples/Gridded_NetCDF_ModelResult.html#netcdf-modelresult",
    "title": "Gridded NetCDF modelresults",
    "section": "NetCDF ModelResult",
    "text": "NetCDF ModelResult\n\nfn = \"../data/SW/ERA5_DutchCoast.nc\"\nxr.open_dataset(fn)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 590kB\nDimensions:    (longitude: 20, latitude: 11, time: 67)\nCoordinates:\n  * longitude  (longitude) float32 80B -1.0 -0.5 0.0 0.5 1.0 ... 7.0 7.5 8.0 8.5\n  * latitude   (latitude) float32 44B 55.0 54.5 54.0 53.5 ... 51.0 50.5 50.0\n  * time       (time) datetime64[ns] 536B 2017-10-27 ... 2017-10-29T18:00:00\nData variables:\n    mwd        (time, latitude, longitude) float64 118kB ...\n    mwp        (time, latitude, longitude) float64 118kB ...\n    mp2        (time, latitude, longitude) float64 118kB ...\n    pp1d       (time, latitude, longitude) float64 118kB ...\n    swh        (time, latitude, longitude) float64 118kB ...\nAttributes:\n    Conventions:  CF-1.6\n    history:      2021-06-07 12:25:02 GMT by grib_to_netcdf-2.16.0: /opt/ecmw...xarray.DatasetDimensions:longitude: 20latitude: 11time: 67Coordinates: (3)longitude(longitude)float32-1.0 -0.5 0.0 0.5 ... 7.5 8.0 8.5units :degrees_eastlong_name :longitudearray([-1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,\n        5. ,  5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5], dtype=float32)latitude(latitude)float3255.0 54.5 54.0 ... 51.0 50.5 50.0units :degrees_northlong_name :latitudearray([55. , 54.5, 54. , 53.5, 53. , 52.5, 52. , 51.5, 51. , 50.5, 50. ],\n      dtype=float32)time(time)datetime64[ns]2017-10-27 ... 2017-10-29T18:00:00long_name :timearray(['2017-10-27T00:00:00.000000000', '2017-10-27T01:00:00.000000000',\n       '2017-10-27T02:00:00.000000000', '2017-10-27T03:00:00.000000000',\n       '2017-10-27T04:00:00.000000000', '2017-10-27T05:00:00.000000000',\n       '2017-10-27T06:00:00.000000000', '2017-10-27T07:00:00.000000000',\n       '2017-10-27T08:00:00.000000000', '2017-10-27T09:00:00.000000000',\n       '2017-10-27T10:00:00.000000000', '2017-10-27T11:00:00.000000000',\n       '2017-10-27T12:00:00.000000000', '2017-10-27T13:00:00.000000000',\n       '2017-10-27T14:00:00.000000000', '2017-10-27T15:00:00.000000000',\n       '2017-10-27T16:00:00.000000000', '2017-10-27T17:00:00.000000000',\n       '2017-10-27T18:00:00.000000000', '2017-10-27T19:00:00.000000000',\n       '2017-10-27T20:00:00.000000000', '2017-10-27T21:00:00.000000000',\n       '2017-10-27T22:00:00.000000000', '2017-10-27T23:00:00.000000000',\n       '2017-10-28T00:00:00.000000000', '2017-10-28T01:00:00.000000000',\n       '2017-10-28T02:00:00.000000000', '2017-10-28T03:00:00.000000000',\n       '2017-10-28T04:00:00.000000000', '2017-10-28T05:00:00.000000000',\n       '2017-10-28T06:00:00.000000000', '2017-10-28T07:00:00.000000000',\n       '2017-10-28T08:00:00.000000000', '2017-10-28T09:00:00.000000000',\n       '2017-10-28T10:00:00.000000000', '2017-10-28T11:00:00.000000000',\n       '2017-10-28T12:00:00.000000000', '2017-10-28T13:00:00.000000000',\n       '2017-10-28T14:00:00.000000000', '2017-10-28T15:00:00.000000000',\n       '2017-10-28T16:00:00.000000000', '2017-10-28T17:00:00.000000000',\n       '2017-10-28T18:00:00.000000000', '2017-10-28T19:00:00.000000000',\n       '2017-10-28T20:00:00.000000000', '2017-10-28T21:00:00.000000000',\n       '2017-10-28T22:00:00.000000000', '2017-10-28T23:00:00.000000000',\n       '2017-10-29T00:00:00.000000000', '2017-10-29T01:00:00.000000000',\n       '2017-10-29T02:00:00.000000000', '2017-10-29T03:00:00.000000000',\n       '2017-10-29T04:00:00.000000000', '2017-10-29T05:00:00.000000000',\n       '2017-10-29T06:00:00.000000000', '2017-10-29T07:00:00.000000000',\n       '2017-10-29T08:00:00.000000000', '2017-10-29T09:00:00.000000000',\n       '2017-10-29T10:00:00.000000000', '2017-10-29T11:00:00.000000000',\n       '2017-10-29T12:00:00.000000000', '2017-10-29T13:00:00.000000000',\n       '2017-10-29T14:00:00.000000000', '2017-10-29T15:00:00.000000000',\n       '2017-10-29T16:00:00.000000000', '2017-10-29T17:00:00.000000000',\n       '2017-10-29T18:00:00.000000000'], dtype='datetime64[ns]')Data variables: (5)mwd(time, latitude, longitude)float64...units :Degree truelong_name :Mean wave direction[14740 values with dtype=float64]mwp(time, latitude, longitude)float64...units :slong_name :Mean wave period[14740 values with dtype=float64]mp2(time, latitude, longitude)float64...units :slong_name :Mean zero-crossing wave period[14740 values with dtype=float64]pp1d(time, latitude, longitude)float64...units :slong_name :Peak wave period[14740 values with dtype=float64]swh(time, latitude, longitude)float64...units :mlong_name :Significant height of combined wind waves and swell[14740 values with dtype=float64]Indexes: (3)longitudePandasIndexPandasIndex(Index([-1.0, -0.5,  0.0,  0.5,  1.0,  1.5,  2.0,  2.5,  3.0,  3.5,  4.0,  4.5,\n        5.0,  5.5,  6.0,  6.5,  7.0,  7.5,  8.0,  8.5],\n      dtype='float32', name='longitude'))latitudePandasIndexPandasIndex(Index([55.0, 54.5, 54.0, 53.5, 53.0, 52.5, 52.0, 51.5, 51.0, 50.5, 50.0], dtype='float32', name='latitude'))timePandasIndexPandasIndex(DatetimeIndex(['2017-10-27 00:00:00', '2017-10-27 01:00:00',\n               '2017-10-27 02:00:00', '2017-10-27 03:00:00',\n               '2017-10-27 04:00:00', '2017-10-27 05:00:00',\n               '2017-10-27 06:00:00', '2017-10-27 07:00:00',\n               '2017-10-27 08:00:00', '2017-10-27 09:00:00',\n               '2017-10-27 10:00:00', '2017-10-27 11:00:00',\n               '2017-10-27 12:00:00', '2017-10-27 13:00:00',\n               '2017-10-27 14:00:00', '2017-10-27 15:00:00',\n               '2017-10-27 16:00:00', '2017-10-27 17:00:00',\n               '2017-10-27 18:00:00', '2017-10-27 19:00:00',\n               '2017-10-27 20:00:00', '2017-10-27 21:00:00',\n               '2017-10-27 22:00:00', '2017-10-27 23:00:00',\n               '2017-10-28 00:00:00', '2017-10-28 01:00:00',\n               '2017-10-28 02:00:00', '2017-10-28 03:00:00',\n               '2017-10-28 04:00:00', '2017-10-28 05:00:00',\n               '2017-10-28 06:00:00', '2017-10-28 07:00:00',\n               '2017-10-28 08:00:00', '2017-10-28 09:00:00',\n               '2017-10-28 10:00:00', '2017-10-28 11:00:00',\n               '2017-10-28 12:00:00', '2017-10-28 13:00:00',\n               '2017-10-28 14:00:00', '2017-10-28 15:00:00',\n               '2017-10-28 16:00:00', '2017-10-28 17:00:00',\n               '2017-10-28 18:00:00', '2017-10-28 19:00:00',\n               '2017-10-28 20:00:00', '2017-10-28 21:00:00',\n               '2017-10-28 22:00:00', '2017-10-28 23:00:00',\n               '2017-10-29 00:00:00', '2017-10-29 01:00:00',\n               '2017-10-29 02:00:00', '2017-10-29 03:00:00',\n               '2017-10-29 04:00:00', '2017-10-29 05:00:00',\n               '2017-10-29 06:00:00', '2017-10-29 07:00:00',\n               '2017-10-29 08:00:00', '2017-10-29 09:00:00',\n               '2017-10-29 10:00:00', '2017-10-29 11:00:00',\n               '2017-10-29 12:00:00', '2017-10-29 13:00:00',\n               '2017-10-29 14:00:00', '2017-10-29 15:00:00',\n               '2017-10-29 16:00:00', '2017-10-29 17:00:00',\n               '2017-10-29 18:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (2)Conventions :CF-1.6history :2021-06-07 12:25:02 GMT by grib_to_netcdf-2.16.0: /opt/ecmwf/eccodes/bin/grib_to_netcdf -S param -o /cache/data8/adaptor.mars.internal-1623068689.815175-27387-9-f370172c-9b84-4760-b5e5-32e00e3964bd.nc /cache/tmp/f370172c-9b84-4760-b5e5-32e00e3964bd-adaptor.mars.internal-1623068689.81571-27387-2-tmp.grib\n\n\n\nmrERA5 = ms.model_result(fn, item=\"swh\", name='ERA5')\n\n\nmrERA5\n\n&lt;GridModelResult&gt;: ERA5\nTime: 2017-10-27 00:00:00 - 2017-10-29 18:00:00\nQuantity: Significant height of combined wind waves and swell [m]\n\n\n\nmrERA5.data  # mr contains the xr.Dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 119kB\nDimensions:  (time: 67, y: 11, x: 20)\nCoordinates:\n  * x        (x) float32 80B -1.0 -0.5 0.0 0.5 1.0 1.5 ... 6.5 7.0 7.5 8.0 8.5\n  * y        (y) float32 44B 55.0 54.5 54.0 53.5 53.0 ... 51.5 51.0 50.5 50.0\n  * time     (time) datetime64[ns] 536B 2017-10-27 ... 2017-10-29T18:00:00\nData variables:\n    swh      (time, y, x) float64 118kB ...\nAttributes:\n    Conventions:  CF-1.6\n    history:      2021-06-07 12:25:02 GMT by grib_to_netcdf-2.16.0: /opt/ecmw...xarray.DatasetDimensions:time: 67y: 11x: 20Coordinates: (3)x(x)float32-1.0 -0.5 0.0 0.5 ... 7.5 8.0 8.5units :degrees_eastlong_name :longitudearray([-1. , -0.5,  0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,\n        5. ,  5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5], dtype=float32)y(y)float3255.0 54.5 54.0 ... 51.0 50.5 50.0units :degrees_northlong_name :latitudearray([55. , 54.5, 54. , 53.5, 53. , 52.5, 52. , 51.5, 51. , 50.5, 50. ],\n      dtype=float32)time(time)datetime64[ns]2017-10-27 ... 2017-10-29T18:00:00long_name :timearray(['2017-10-27T00:00:00.000000000', '2017-10-27T01:00:00.000000000',\n       '2017-10-27T02:00:00.000000000', '2017-10-27T03:00:00.000000000',\n       '2017-10-27T04:00:00.000000000', '2017-10-27T05:00:00.000000000',\n       '2017-10-27T06:00:00.000000000', '2017-10-27T07:00:00.000000000',\n       '2017-10-27T08:00:00.000000000', '2017-10-27T09:00:00.000000000',\n       '2017-10-27T10:00:00.000000000', '2017-10-27T11:00:00.000000000',\n       '2017-10-27T12:00:00.000000000', '2017-10-27T13:00:00.000000000',\n       '2017-10-27T14:00:00.000000000', '2017-10-27T15:00:00.000000000',\n       '2017-10-27T16:00:00.000000000', '2017-10-27T17:00:00.000000000',\n       '2017-10-27T18:00:00.000000000', '2017-10-27T19:00:00.000000000',\n       '2017-10-27T20:00:00.000000000', '2017-10-27T21:00:00.000000000',\n       '2017-10-27T22:00:00.000000000', '2017-10-27T23:00:00.000000000',\n       '2017-10-28T00:00:00.000000000', '2017-10-28T01:00:00.000000000',\n       '2017-10-28T02:00:00.000000000', '2017-10-28T03:00:00.000000000',\n       '2017-10-28T04:00:00.000000000', '2017-10-28T05:00:00.000000000',\n       '2017-10-28T06:00:00.000000000', '2017-10-28T07:00:00.000000000',\n       '2017-10-28T08:00:00.000000000', '2017-10-28T09:00:00.000000000',\n       '2017-10-28T10:00:00.000000000', '2017-10-28T11:00:00.000000000',\n       '2017-10-28T12:00:00.000000000', '2017-10-28T13:00:00.000000000',\n       '2017-10-28T14:00:00.000000000', '2017-10-28T15:00:00.000000000',\n       '2017-10-28T16:00:00.000000000', '2017-10-28T17:00:00.000000000',\n       '2017-10-28T18:00:00.000000000', '2017-10-28T19:00:00.000000000',\n       '2017-10-28T20:00:00.000000000', '2017-10-28T21:00:00.000000000',\n       '2017-10-28T22:00:00.000000000', '2017-10-28T23:00:00.000000000',\n       '2017-10-29T00:00:00.000000000', '2017-10-29T01:00:00.000000000',\n       '2017-10-29T02:00:00.000000000', '2017-10-29T03:00:00.000000000',\n       '2017-10-29T04:00:00.000000000', '2017-10-29T05:00:00.000000000',\n       '2017-10-29T06:00:00.000000000', '2017-10-29T07:00:00.000000000',\n       '2017-10-29T08:00:00.000000000', '2017-10-29T09:00:00.000000000',\n       '2017-10-29T10:00:00.000000000', '2017-10-29T11:00:00.000000000',\n       '2017-10-29T12:00:00.000000000', '2017-10-29T13:00:00.000000000',\n       '2017-10-29T14:00:00.000000000', '2017-10-29T15:00:00.000000000',\n       '2017-10-29T16:00:00.000000000', '2017-10-29T17:00:00.000000000',\n       '2017-10-29T18:00:00.000000000'], dtype='datetime64[ns]')Data variables: (1)swh(time, y, x)float64...units :mlong_name :Significant height of combined wind waves and swell[14740 values with dtype=float64]Indexes: (3)xPandasIndexPandasIndex(Index([-1.0, -0.5,  0.0,  0.5,  1.0,  1.5,  2.0,  2.5,  3.0,  3.5,  4.0,  4.5,\n        5.0,  5.5,  6.0,  6.5,  7.0,  7.5,  8.0,  8.5],\n      dtype='float32', name='x'))yPandasIndexPandasIndex(Index([55.0, 54.5, 54.0, 53.5, 53.0, 52.5, 52.0, 51.5, 51.0, 50.5, 50.0], dtype='float32', name='y'))timePandasIndexPandasIndex(DatetimeIndex(['2017-10-27 00:00:00', '2017-10-27 01:00:00',\n               '2017-10-27 02:00:00', '2017-10-27 03:00:00',\n               '2017-10-27 04:00:00', '2017-10-27 05:00:00',\n               '2017-10-27 06:00:00', '2017-10-27 07:00:00',\n               '2017-10-27 08:00:00', '2017-10-27 09:00:00',\n               '2017-10-27 10:00:00', '2017-10-27 11:00:00',\n               '2017-10-27 12:00:00', '2017-10-27 13:00:00',\n               '2017-10-27 14:00:00', '2017-10-27 15:00:00',\n               '2017-10-27 16:00:00', '2017-10-27 17:00:00',\n               '2017-10-27 18:00:00', '2017-10-27 19:00:00',\n               '2017-10-27 20:00:00', '2017-10-27 21:00:00',\n               '2017-10-27 22:00:00', '2017-10-27 23:00:00',\n               '2017-10-28 00:00:00', '2017-10-28 01:00:00',\n               '2017-10-28 02:00:00', '2017-10-28 03:00:00',\n               '2017-10-28 04:00:00', '2017-10-28 05:00:00',\n               '2017-10-28 06:00:00', '2017-10-28 07:00:00',\n               '2017-10-28 08:00:00', '2017-10-28 09:00:00',\n               '2017-10-28 10:00:00', '2017-10-28 11:00:00',\n               '2017-10-28 12:00:00', '2017-10-28 13:00:00',\n               '2017-10-28 14:00:00', '2017-10-28 15:00:00',\n               '2017-10-28 16:00:00', '2017-10-28 17:00:00',\n               '2017-10-28 18:00:00', '2017-10-28 19:00:00',\n               '2017-10-28 20:00:00', '2017-10-28 21:00:00',\n               '2017-10-28 22:00:00', '2017-10-28 23:00:00',\n               '2017-10-29 00:00:00', '2017-10-29 01:00:00',\n               '2017-10-29 02:00:00', '2017-10-29 03:00:00',\n               '2017-10-29 04:00:00', '2017-10-29 05:00:00',\n               '2017-10-29 06:00:00', '2017-10-29 07:00:00',\n               '2017-10-29 08:00:00', '2017-10-29 09:00:00',\n               '2017-10-29 10:00:00', '2017-10-29 11:00:00',\n               '2017-10-29 12:00:00', '2017-10-29 13:00:00',\n               '2017-10-29 14:00:00', '2017-10-29 15:00:00',\n               '2017-10-29 16:00:00', '2017-10-29 17:00:00',\n               '2017-10-29 18:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (2)Conventions :CF-1.6history :2021-06-07 12:25:02 GMT by grib_to_netcdf-2.16.0: /opt/ecmwf/eccodes/bin/grib_to_netcdf -S param -o /cache/data8/adaptor.mars.internal-1623068689.815175-27387-9-f370172c-9b84-4760-b5e5-32e00e3964bd.nc /cache/tmp/f370172c-9b84-4760-b5e5-32e00e3964bd-adaptor.mars.internal-1623068689.81571-27387-2-tmp.grib",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#test-extract-from-xarray",
    "href": "examples/Gridded_NetCDF_ModelResult.html#test-extract-from-xarray",
    "title": "Gridded NetCDF modelresults",
    "section": "Test extract from XArray",
    "text": "Test extract from XArray\n\nExtract point\nExtract track\n\n\nmrERA5.extract(o1, spatial_method=\"nearest\").data.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104B\nDimensions:  (time: 5)\nCoordinates:\n  * time     (time) datetime64[ns] 40B 2017-10-27 ... 2017-10-27T04:00:00\n    x        float64 8B 4.242\n    y        float64 8B 52.69\n    z        object 8B None\nData variables:\n    ERA5     (time) float64 40B 1.22 1.347 1.466 1.612 1.793\nAttributes:\n    gtype:               point\n    modelskill_version:  1.3.dev0xarray.DatasetDimensions:time: 5Coordinates: (4)time(time)datetime64[ns]2017-10-27 ... 2017-10-27T04:00:00array(['2017-10-27T00:00:00.000000000', '2017-10-27T01:00:00.000000000',\n       '2017-10-27T02:00:00.000000000', '2017-10-27T03:00:00.000000000',\n       '2017-10-27T04:00:00.000000000'], dtype='datetime64[ns]')x()float644.242array(4.242)y()float6452.69array(52.6887)z()objectNonearray(None, dtype=object)Data variables: (1)ERA5(time)float641.22 1.347 1.466 1.612 1.793long_name :Significant height of combined wind waves and swellunits :mis_directional :0kind :modelcolor :#ebdc78array([1.22033748, 1.34657334, 1.46574705, 1.61175692, 1.79290097])Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2017-10-27 00:00:00', '2017-10-27 01:00:00',\n               '2017-10-27 02:00:00', '2017-10-27 03:00:00',\n               '2017-10-27 04:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (2)gtype :pointmodelskill_version :1.3.dev0\n\n\n\nmrERA5.extract(o3).data.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 168B\nDimensions:  (time: 5)\nCoordinates:\n    x        (time) float64 40B 2.423 2.414 2.405 2.396 2.387\n    y        (time) float64 40B 51.25 51.31 51.37 51.42 51.48\n  * time     (time) datetime64[ns] 40B 2017-10-27T12:52:52.337000 ... 2017-10...\n    z        float64 8B nan\nData variables:\n    ERA5     (time) float64 40B 1.439 1.464 1.489 1.514 1.538\nAttributes:\n    gtype:               track\n    modelskill_version:  1.3.dev0xarray.DatasetDimensions:time: 5Coordinates: (4)x(time)float642.423 2.414 2.405 2.396 2.387array([2.42285442, 2.4137888 , 2.40471053, 2.39561939, 2.38651562])y(time)float6451.25 51.31 51.37 51.42 51.48array([51.25335312, 51.3102684 , 51.36718369, 51.42409897, 51.48101425])time(time)datetime64[ns]2017-10-27T12:52:52.337000 ... 2...array(['2017-10-27T12:52:52.337000000', '2017-10-27T12:52:53.280000000',\n       '2017-10-27T12:52:54.224000000', '2017-10-27T12:52:55.167000000',\n       '2017-10-27T12:52:56.111000000'], dtype='datetime64[ns]')z()float64nanarray(nan)Data variables: (1)ERA5(time)float641.439 1.464 1.489 1.514 1.538long_name :Significant height of combined wind waves and swellunits :mkind :modelcolor :#ebdc78array([1.43880867, 1.46419095, 1.48919941, 1.51383323, 1.53809179])Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2017-10-27 12:52:52.337000', '2017-10-27 12:52:53.280000',\n               '2017-10-27 12:52:54.224000', '2017-10-27 12:52:55.167000',\n               '2017-10-27 12:52:56.111000'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (2)gtype :trackmodelskill_version :1.3.dev0",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#multi-file-modelresult",
    "href": "examples/Gridded_NetCDF_ModelResult.html#multi-file-modelresult",
    "title": "Gridded NetCDF modelresults",
    "section": "Multi-file ModelResult",
    "text": "Multi-file ModelResult\nUse mfdataset to load multiple files as a single ModelResult.\n\nfn = \"../data/SW/CMEMS_DutchCoast_*.nc\"\nmrCMEMS = ms.model_result(fn, item=\"VHM0\", name='CMEMS')\nmrCMEMS\n\n&lt;GridModelResult&gt;: CMEMS\nTime: 2017-10-28 00:00:00 - 2017-10-29 18:00:00\nQuantity: Spectral significant wave height (Hm0) [m]",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#connect-multiple-models-and-observations-and-extract",
    "href": "examples/Gridded_NetCDF_ModelResult.html#connect-multiple-models-and-observations-and-extract",
    "title": "Gridded NetCDF modelresults",
    "section": "Connect multiple models and observations and extract",
    "text": "Connect multiple models and observations and extract\n\nms.plotting.temporal_coverage(obs=[o1,o2,o3], mod=[mrERA5, mrCMEMS, mrMIKE])\n\n\n\n\n\n\n\n\n\n# o1 is slightly outside the model domain of mrERA5, \n# we therefore use \"nearest\" instead of the default spatial interpolation method  \ncc = ms.match(\n    obs=[o1, o2, o3], \n    mod=[mrERA5, mrCMEMS, mrMIKE], \n    spatial_method='nearest',\n)",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Gridded_NetCDF_ModelResult.html#analysis-and-plotting",
    "href": "examples/Gridded_NetCDF_ModelResult.html#analysis-and-plotting",
    "title": "Gridded NetCDF modelresults",
    "section": "Analysis and plotting",
    "text": "Analysis and plotting\nWhich model is better?\n\nsk = cc.skill()\nsk.swaplevel().sort_index(level=\"observation\").style()\n\n\n\n\n\n\n \n \nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nobservation\nmodel\n \n \n \n \n \n \n \n \n\n\n\n\nEPL\nCMEMS\n43\n-0.441\n0.519\n0.273\n0.443\n0.920\n0.090\n0.445\n\n\nERA5\n43\n-0.247\n0.335\n0.226\n0.269\n0.948\n0.074\n0.769\n\n\nMIKE21SW\n43\n-0.078\n0.205\n0.189\n0.174\n0.973\n0.062\n0.913\n\n\nHKNA\nCMEMS\n242\n-0.742\n0.882\n0.476\n0.742\n0.903\n0.128\n0.222\n\n\nERA5\n242\n-0.551\n0.654\n0.352\n0.556\n0.954\n0.094\n0.572\n\n\nMIKE21SW\n242\n-0.230\n0.411\n0.341\n0.296\n0.949\n0.092\n0.831\n\n\nc2\nCMEMS\n36\n-0.200\n0.412\n0.360\n0.339\n0.930\n0.093\n0.807\n\n\nERA5\n36\n-0.540\n0.653\n0.368\n0.573\n0.951\n0.095\n0.513\n\n\nMIKE21SW\n36\n0.315\n0.405\n0.254\n0.349\n0.962\n0.065\n0.813\n\n\n\n\n\n\nsk[\"urmse\"].plot.bar(figsize=(6,3));\n\n\n\n\n\n\n\n\n\ncc.mean_skill().style()\n\n\n\n\n\n\n \nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nmodel\n \n \n \n \n \n \n \n \n\n\n\n\nCMEMS\n321\n-0.461\n0.604\n0.370\n0.508\n0.918\n0.103\n0.491\n\n\nERA5\n321\n-0.446\n0.547\n0.315\n0.466\n0.951\n0.088\n0.618\n\n\nMIKE21SW\n321\n0.002\n0.340\n0.262\n0.273\n0.962\n0.073\n0.852\n\n\n\n\n\n\ncc.plot.taylor(figsize=6)",
    "crumbs": [
      "Examples",
      "Gridded NetCDF ModelResult"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html",
    "href": "examples/Metocean_track_comparison.html",
    "title": "Metocean track comparison",
    "section": "",
    "text": "Comparing MIKE 21 HD dfsu model result with satellite track observation of surface elevation.\nThis notebook also includes gridded spatial skill assessments.\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport modelskill as ms",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html#extract-track-data",
    "href": "examples/Metocean_track_comparison.html#extract-track-data",
    "title": "Metocean track comparison",
    "section": "Extract track data",
    "text": "Extract track data\n\nmr = ms.model_result('../data/NorthSeaHD_and_windspeed.dfsu',\n                     name='HD', item=0)\nmr\n\n&lt;DfsuModelResult&gt;: HD\nTime: 2017-10-27 00:00:00 - 2017-10-29 18:00:00\nQuantity: Surface Elevation [m]\n\n\nIn this case, the track observations are stored in a csv file, which we can read in using pandas. Any file format that can be read into a pandas dataframe can be used here.\n\ndf = pd.read_csv('../data/altimetry_NorthSea_20171027.csv',\n                  index_col=0, parse_dates=True)\ndf.head()\n\n\n\n\n\n\n\n\nlon\nlat\nsurface_elevation\nsignificant_wave_height\nwind_speed\n\n\ndate\n\n\n\n\n\n\n\n\n\n2017-10-26 04:37:37\n8.757272\n53.926136\n1.6449\n0.426\n6.100000\n\n\n2017-10-26 04:37:54\n8.221631\n54.948459\n1.1200\n1.634\n9.030000\n\n\n2017-10-26 04:37:55\n8.189390\n55.008547\n1.0882\n1.717\n9.370000\n\n\n2017-10-26 04:37:56\n8.157065\n55.068627\n1.0309\n1.869\n9.559999\n\n\n2017-10-26 04:37:58\n8.124656\n55.128700\n1.0369\n1.939\n9.980000\n\n\n\n\n\n\n\nCsv files have no metadata on which quantity it contains, we add this manually, consistent with the model result, using the TrackObservation class.\n\no1 = ms.TrackObservation(df, item=\"surface_elevation\", name='alti',\n                         quantity=ms.Quantity(name=\"Surface Elevation\", unit=\"meter\")) \no1\n\n/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/modelskill/timeseries/_track.py:136: UserWarning:\n\nRemoved 22 duplicate timestamps with keep=first\n\n\n\n&lt;TrackObservation&gt;: alti\nTime: 2017-10-26 04:37:37 - 2017-10-30 20:54:47\nQuantity: Surface Elevation [meter]\n\n\n\nms.plotting.spatial_overview(o1, mr);\n\n\n\n\n\n\n\n\n\ncmp = ms.match(o1, mr)\ncmp\n\n&lt;Comparer&gt;\nQuantity: Surface Elevation [meter]\nObservation: alti, n_points=532\nModel(s):\n0: HD\n\n\n\ncmp.plot.scatter();",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html#extract-track-from-dfs0",
    "href": "examples/Metocean_track_comparison.html#extract-track-from-dfs0",
    "title": "Metocean track comparison",
    "section": "Extract track from dfs0",
    "text": "Extract track from dfs0\nUsing the TrackModelResult class.\n\nmr = ms.TrackModelResult('../data/NorthSeaHD_extracted_track.dfs0',\n                          name='HD', item=2)\nmr\n\n/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/modelskill/timeseries/_track.py:136: UserWarning:\n\nRemoved 22 duplicate timestamps with keep=first\n\n\n\n&lt;TrackModelResult&gt;: HD\nTime: 2017-10-26 04:37:37 - 2017-10-30 20:54:47\nQuantity: Undefined [undefined]\n\n\n\ndf = pd.read_csv('../data/altimetry_NorthSea_20171027.csv',\n                  index_col=0, parse_dates=True)\no1 = ms.TrackObservation(df, item=2, name='alti',\n                         quantity=ms.Quantity(name=\"Surface Elevation\", unit=\"meter\"))\no1\n\n/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/modelskill/timeseries/_track.py:136: UserWarning:\n\nRemoved 22 duplicate timestamps with keep=first\n\n\n\n&lt;TrackObservation&gt;: alti\nTime: 2017-10-26 04:37:37 - 2017-10-30 20:54:47\nQuantity: Surface Elevation [meter]\n\n\n\ncmp = ms.match(o1, mr)\ncmp\n\n&lt;Comparer&gt;\nQuantity: Surface Elevation [meter]\nObservation: alti, n_points=532\nModel(s):\n0: HD\n\n\n\ncmp.plot.scatter();",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html#gridded-skill",
    "href": "examples/Metocean_track_comparison.html#gridded-skill",
    "title": "Metocean track comparison",
    "section": "Gridded skill",
    "text": "Gridded skill\nLoad model, load observation, add observation to model and extract.\n\nmr = ms.model_result('../data/NorthSeaHD_and_windspeed.dfsu',\n                     name='HD', item=0)\n\ndf = pd.read_csv('../data/altimetry_NorthSea_20171027.csv',\n                 index_col=0, parse_dates=True)\no1 = ms.TrackObservation(df, item=2, name='alti',\n                         quantity=ms.Quantity(name=\"Surface Elevation\", unit=\"meter\"))\ncmp = ms.match(o1, mr)\ncmp\n\n/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/modelskill/timeseries/_track.py:136: UserWarning:\n\nRemoved 22 duplicate timestamps with keep=first\n\n\n\n&lt;Comparer&gt;\nQuantity: Surface Elevation [meter]\nObservation: alti, n_points=532\nModel(s):\n0: HD\n\n\nGet metrics binned by a regular spatial grid, returns xarray Dataset\n\ngs = cmp.gridded_skill(metrics=['bias'])\ngs\n\n&lt;SkillGrid&gt;\nDimensions: (x: 5, y: 5)\n\n\n\nfig, axes = plt.subplots(ncols=2, nrows=1, figsize = (10, 5))\ngs.n.plot(ax=axes[0])\ngs.bias.plot(ax=axes[1]);",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html#minimum-number-of-observations",
    "href": "examples/Metocean_track_comparison.html#minimum-number-of-observations",
    "title": "Metocean track comparison",
    "section": "Minimum number of observations",
    "text": "Minimum number of observations\n\ngs = cmp.gridded_skill(metrics=['bias'], n_min=25)\nfig, axes = plt.subplots(ncols=2, nrows=1, figsize=(10, 5))\ngs.n.plot(ax=axes[0])\ngs.bias.plot(ax=axes[1]);",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html#multiple-bins---gridded-skill-for-water-level-categories",
    "href": "examples/Metocean_track_comparison.html#multiple-bins---gridded-skill-for-water-level-categories",
    "title": "Metocean track comparison",
    "section": "Multiple bins - gridded skill for water level categories",
    "text": "Multiple bins - gridded skill for water level categories\nGet data from comparer as dataframe and add a water level category as a new column.\n\ndftmp = cmp.data.to_dataframe()\ndftmp[\"wl category\"] = 'high'\ndftmp.loc[dftmp['HD']&lt;0, \"wl category\"] = 'low'\n\nAdd the “wl category” to the comparer’s data structure.\n\ncmp.data[\"wl category\"] = dftmp[\"wl category\"]\n\nNow aggregate the data by the new column (and x and y):\n\ngs = cmp.gridded_skill(by=['wl category'], metrics=['bias'], n_min=5)\ngs\n\n&lt;SkillGrid&gt;\nDimensions: (x: 5, y: 5)\n\n\n\ngs.bias.plot();",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/Metocean_track_comparison.html#multiple-observations",
    "href": "examples/Metocean_track_comparison.html#multiple-observations",
    "title": "Metocean track comparison",
    "section": "Multiple observations",
    "text": "Multiple observations\nAdd fake 2nd observation to model\n\nimport warnings\n\ndf2 = df.copy()\ndf2['surface_elevation'] = df2['surface_elevation'] - 0.2\no2 = ms.TrackObservation(df2, item=2, name='alti2')\n\nwarnings.filterwarnings('ignore', message=\"duplicate\")\ncmp2 = ms.match(o2, mr)\n\n/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/modelskill/timeseries/_track.py:136: UserWarning:\n\nRemoved 22 duplicate timestamps with keep=first\n\n\n\nExtract, gridded skill, add attrs, plot.\n\ncmp = cmp + cmp2\ngs = cmp.gridded_skill(metrics=['bias'], n_min=20)\ngs.bias.data.attrs = dict(long_name=\"Bias of surface elevation\", units=\"m\")\ngs.bias.plot(figsize=(10,5));",
    "crumbs": [
      "Examples",
      "Metocean track comparison"
    ]
  },
  {
    "objectID": "examples/MIKE21HD_dfsu.html",
    "href": "examples/MIKE21HD_dfsu.html",
    "title": "MIKE21 HD",
    "section": "",
    "text": "Water level comparison between MIKE21 HD and observations from the Oresund.\nimport modelskill as ms\nmr = ms.model_result('../data/Oresund2D.dfsu',\n                     item='Surface elevation')\nmr\n\n&lt;DfsuModelResult&gt;: Oresund2D\nTime: 2018-03-04 00:00:00 - 2018-03-10 22:40:00\nQuantity: Surface Elevation [m]\nmr.data.geometry.plot(cmap=\"Blues_r\");\nmr.data.geometry.projection\n\n'UTM-33'\nCoordinate reference system used in this model is UTM-33.\no1 = ms.PointObservation('../data/smhi_2095_klagshamn.dfs0', item=0,\n    x=366844.15, y=6154291.6) # UTM-33\no1\n\n&lt;PointObservation&gt;: smhi_2095_klagshamn\nLocation: 366844.15, 6154291.6\nTime: 2015-01-01 01:00:00 - 2020-09-28 00:00:00\nQuantity: Water Level [m]",
    "crumbs": [
      "Examples",
      "MIKE21 HD"
    ]
  },
  {
    "objectID": "examples/MIKE21HD_dfsu.html#spatial-overview",
    "href": "examples/MIKE21HD_dfsu.html#spatial-overview",
    "title": "MIKE21 HD",
    "section": "Spatial overview",
    "text": "Spatial overview\nConfirm that the observation is correctly located in the model domain.\n\nms.plotting.spatial_overview(o1, mr, figsize=(4, 4));\n\n\n\n\n\n\n\n\nMatch the observed data to the model result (interpolate the model result to the observation points).\n\ncmp = ms.match(o1, mr)\ncmp\n\n&lt;Comparer&gt;\nQuantity: Water Level [m]\nObservation: smhi_2095_klagshamn, n_points=167\nModel(s):\n0: Oresund2D\n\n\n\nfig = cmp.plot.timeseries(backend=\"plotly\")\nfig.show()\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nThe reference level is not the same for the model and the observation. We can remove the bias from the model result to make the comparison more fair.\n\nub_cmp = cmp.remove_bias()\nub_cmp.plot.timeseries(backend=\"plotly\").show();\n\n                            \n                                            \n\n\nThe bias is removed, which affects the rmse, but not the un-biased version urmse.\n\ncmp.skill()\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nobservation\n\n\n\n\n\n\n\n\n\n\n\n\nsmhi_2095_klagshamn\n167\n0.185752\n0.190176\n0.04078\n0.185752\n0.83973\n0.377661\n-5.4291\n\n\n\n\n\n\n\n\nub_cmp.skill()\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nobservation\n\n\n\n\n\n\n\n\n\n\n\n\nsmhi_2095_klagshamn\n167\n-2.393295e-17\n0.04078\n0.04078\n0.033354\n0.83973\n0.377661\n0.704384",
    "crumbs": [
      "Examples",
      "MIKE21 HD"
    ]
  },
  {
    "objectID": "examples/MIKE21HD_dfsu.html#scatter-plot",
    "href": "examples/MIKE21HD_dfsu.html#scatter-plot",
    "title": "MIKE21 HD",
    "section": "Scatter plot",
    "text": "Scatter plot\n\nms.load_style(\"MOOD\")\nub_cmp.plot.scatter(skill_table=True);",
    "crumbs": [
      "Examples",
      "MIKE21 HD"
    ]
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Examples",
    "section": "",
    "text": "Comparing Directional Data (e.g. wind direction)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustom Metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGridded NetCDF modelresults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHydrology example from the Vistula catchment in Poland\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs my model better than predicting the mean?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIKE21 HD\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetocean track comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPre-matched data with auxiliary data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "user-guide/selecting-data.html",
    "href": "user-guide/selecting-data.html",
    "title": "Selecting data",
    "section": "",
    "text": "The primary data filtering method of ModelSkill is the sel() method which is accesible on most ModelSkill data structures. The sel() method is a wrapper around xarray.Dataset.sel and can be used to select data based on time, location and/or variable. The sel() method returns a new data structure of the same type with the selected data.",
    "crumbs": [
      "User Guide",
      "Selecting data"
    ]
  },
  {
    "objectID": "user-guide/selecting-data.html#timeseries-data",
    "href": "user-guide/selecting-data.html#timeseries-data",
    "title": "Selecting data",
    "section": "TimeSeries data",
    "text": "TimeSeries data\nPoint and track timeseries data of both observation and model result kinds are stored in TimeSeries objects which uses xarray.Dataset as data container. The sel() method can be used to select data based on time and returns a new TimeSeries object with the selected data.\n\nimport modelskill as ms\no = ms.observation(\"../data/obs.nc\", item=\"waterlevel\", gtype='point')\no_1month = o.sel(time=slice(\"2018-01-01\", \"2018-02-01\"))\no_1month\n\n&lt;PointObservation&gt;: obs\nLocation: nan, nan\nTime: 2018-01-01 00:00:00 - 2018-02-01 23:00:00\nQuantity:  []",
    "crumbs": [
      "User Guide",
      "Selecting data"
    ]
  },
  {
    "objectID": "user-guide/selecting-data.html#comparer-objects",
    "href": "user-guide/selecting-data.html#comparer-objects",
    "title": "Selecting data",
    "section": "Comparer objects",
    "text": "Comparer objects\nThe Comparer and ComparerCollection objects hold matched data from observations and model results, enabling you to evaluate model performance effectively. These objects provide intuitive methods to filter and query data based on time, model, quantity, or spatial criteria.\nThe primary methods for filtering the data are:\n\nsel(): Use for structured selections based on time, model, or spatial boundaries.\nwhere(): Use for conditional filtering based on logical criteria.\nquery(): Use for flexible, expression-based filtering in a pandas-like style.\n\n\n\nObservation and model data\no = ms.observation(\"../data/SW/HKNA_Hm0.dfs0\", item=0,\n                    x=4.2420, y=52.6887,\n                    name=\"HKNA\")\nm1 = ms.model_result(\"../data/SW/HKZN_local_2017_DutchCoast.dfsu\", \n                      item=\"Sign. Wave Height\",\n                      name=\"m1\")\nm2 = ms.model_result(\"../data/SW/CMEMS_DutchCoast_2017-10-28.nc\", \n                      item=\"VHM0\",\n                      name=\"m2\")\n\n\n\ncmp = ms.match(o, [m1, m2])\n\n\nsel() method\nThe sel method allows you to select data based on specific criteria such as time, model name, or spatial area. It returns a new Comparer object with the selected data. This method is highly versatile and supports multiple selection parameters, which can be combined.\nSyntax: Comparer.sel(model=None, time=None, area=None)\n\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr, int, or list\nModel name or index. Selects specific models.\nNone\n\n\ntime\nstr, datetime, or slice\nSpecific time or range for selection.\nNone\n\n\narea\nlist of float or Polygon\nBounding box [x0, y0, x1, y1] or a polygon area filter.\nNone\n\n\n\nExample 1: Selecting data by time\n\ncmp_12hrs = cmp.sel(time=slice('2017-10-28', '2017-10-28 12:00'))\ncmp_12hrs\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA, n_points=66\nModel(s):\n0: m1\n1: m2\n\n\nThis selects data within the specified time range.\nExample 2: Selecting a specific model\n\ncmp_m1 = cmp.sel(model='m1')\ncmp_m1\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA, n_points=120\nModel(s):\n0: m1\n\n\nThis filters the data to include only the model named “m1”.\nExample 3: Selecting a spatial area\n\ncmp_area = cmp.sel(area=[4.0, 52.5, 5.0, 53.0])\n\nThis filters the data within the bounding box defined by [x0, y0, x1, y1].\n\n\nwhere() method\nThe where method is used to filter data conditionally. It works similarly to xarray’s where method and returns a new Comparer object with values satisfying a given condition. Other values will be masked (set to NaN).\nSyntax: Comparer.where(cond)\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\n\n\n\n\ncond\nbool, np.ndarray, or xr.DataArray\nCondition to filter values (True or False).\n\n\n\nExample 4: Filtering data conditionally\n\ncmp.where(cmp.data.Observation &gt; 3)\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA, n_points=52\nModel(s):\n0: m1\n1: m2\n\n\nThis filters out any rows where the observation values are not greater than 3.\nExample 5: Multiple conditions\n\ncmp.where((cmp.data.m1 &lt; 2.9) & (cmp.data.Observation &gt; 3))\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA, n_points=8\nModel(s):\n0: m1\n1: m2\n\n\nThis filters the data to include rows where m1 &lt; 2.9 and Observation &gt; 3.0.\n\n\nquery() method\nThe query method uses a pandas.DataFrame.query-style syntax to filter data based on string-based expressions. It provides a flexible way to apply complex filters using column names and logical operators.\nSyntax: Comparer.query(query)\n\n\n\nParameter\nType\nDescription\n\n\n\n\nquery\nstr\nQuery string for filtering data.\n\n\n\nExample 6: Querying data\n\ncmp.query(\"Observation &gt; 3.0 and m1 &lt; 2.9\")\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA, n_points=8\nModel(s):\n0: m1\n1: m2\n\n\nThis filters the data where Observation is greater than 3.0 and m1 is less than 2.9.",
    "crumbs": [
      "User Guide",
      "Selecting data"
    ]
  },
  {
    "objectID": "user-guide/selecting-data.html#skill-objects",
    "href": "user-guide/selecting-data.html#skill-objects",
    "title": "Selecting data",
    "section": "Skill objects",
    "text": "Skill objects\nThe skill() and mean_skill() methods return a SkillTable object with skill scores from comparing observation and model result data using different metrics (e.g. root mean square error). It returns a SkillTable object, which wraps a pandas.DataFrame and organizes the skill scores for further filtering, visualization, or analysis.\nThe resulting SkillTable object provides several methods to facilitate filtering and formatting: - sel(): Select specific models or observations. - query(): Apply flexible conditions with pandas-like queries.\n\nsk = cmp.skill(metrics=[\"rmse\", \"mae\", \"si\"])\nsk\n\n\n\n\n\n\n\n\n\nn\nrmse\nmae\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nHKNA\n120\n0.190451\n0.155128\n0.060252\n\n\nm2\nHKNA\n120\n0.574975\n0.525915\n0.080212\n\n\n\n\n\n\n\nExample 7: Select model\n\nsk.sel(model='m1')\n\n\n\n\n\n\n\n\nmodel\nobservation\nn\nrmse\nmae\nsi\n\n\n\n\n0\nm1\nHKNA\n120\n0.190451\n0.155128\n0.060252\n\n\n\n\n\n\n\nHere, sk contains skill scores for all models, and sk_m1 filters the results to include only model “m1”. Observations can be selected in the same way.\nExample 8: Querying skill scores\n\nsk_high_rmse = sk.query(\"rmse &gt; 0.3\")\nsk_high_rmse\n\n\n\n\n\n\n\n\n\nn\nrmse\nmae\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm2\nHKNA\n120\n0.574975\n0.525915\n0.080212\n\n\n\n\n\n\n\nThis filters the SkillTable to include only rows where the root mean square error (RMSE) exceeds 0.3.\nExample 9: Accessing and visualizing specific metrics\n\nsk_rmse = sk.rmse\nsk_rmse\n\n\n\n\n\n\n\n\n\nrmse\n\n\nmodel\nobservation\n\n\n\n\n\nm1\nHKNA\n0.190451\n\n\nm2\nHKNA\n0.574975\n\n\n\n\n\n\n\n\nsk_rmse.plot.bar(figsize=(5,3))\n\n\n\n\n\n\n\n\nThe rmse attribute directly accesses the RMSE column from the SkillTable, which can then be plotted or analyzed further.",
    "crumbs": [
      "User Guide",
      "Selecting data"
    ]
  },
  {
    "objectID": "user-guide/vision.html",
    "href": "user-guide/vision.html",
    "title": "Vision",
    "section": "",
    "text": "ModelSkill would like to be your modelling companion. It should be indispensable good such that you want to use it every time you do a MIKE simulation.\n\n\nWe want ModelSkill to make it easy to\n\nassess the skill of a model by comparing with measurements\nassess model skill also when result is split on several files (2d, 3d, yearly, ...)\ncompare the skill of different calibration runs\ncompare your model with other models\nuse a wide range of common evaluation metrics\ncreate common plots such as time series, scatter and taylor diagrams\ndo aggregations - assess for all observations, geographic areas, monthly, ...\ndo filtering - assess for a subset of observations, geographic areas, ...\nmake fast comparisons (optimized code)\n\nAnd it should be\n\nDifficult to make mistakes by verifying input\nTrustworthy by having &gt;95% test coverage\nEasy to install ($ pip install modelskill)\nEasy to get started by providing many notebook examples and documentation\n\n\n\n\nModelSkill wants to balance general and specific needs:\n\nIt should be general enough to cover &gt;90% of MIKE simulations\nIt should be general enough to cover generic modelling irrespective of software.\nBut specific enough to be useful\n\nSupport dfs files (using mikeio)\nHandle circular variables such as wave direction\n\n\n\n\n\nModelSkill does not wish to cover\n\nExtreme value analysis\nDeterministic wave analysis such as crossing analysis\nRare alternative file types\nRarely used model result types\nRare observation types\nAnything project specific\n\n\n\n\n\n\nIt should be possible to compare forecasts with observations using forecast lead time as a dimension. Planned 2024.\n\n\n\nCurrently 3D data is supported only as point data and only if data has already been extracted from model result files. It should be possible to extract date from 3D files directly. Furthermore, vertical columns data should be supported as an observation type with z as a dimension. Planned 2024.\n\n\n\nCreate a web app that wraps this library.\n\n\n\nBoth static as markdown, docx, pptx and interactive as html."
  },
  {
    "objectID": "user-guide/vision.html#objective",
    "href": "user-guide/vision.html#objective",
    "title": "Vision",
    "section": "",
    "text": "We want ModelSkill to make it easy to\n\nassess the skill of a model by comparing with measurements\nassess model skill also when result is split on several files (2d, 3d, yearly, ...)\ncompare the skill of different calibration runs\ncompare your model with other models\nuse a wide range of common evaluation metrics\ncreate common plots such as time series, scatter and taylor diagrams\ndo aggregations - assess for all observations, geographic areas, monthly, ...\ndo filtering - assess for a subset of observations, geographic areas, ...\nmake fast comparisons (optimized code)\n\nAnd it should be\n\nDifficult to make mistakes by verifying input\nTrustworthy by having &gt;95% test coverage\nEasy to install ($ pip install modelskill)\nEasy to get started by providing many notebook examples and documentation"
  },
  {
    "objectID": "user-guide/vision.html#scope",
    "href": "user-guide/vision.html#scope",
    "title": "Vision",
    "section": "",
    "text": "ModelSkill wants to balance general and specific needs:\n\nIt should be general enough to cover &gt;90% of MIKE simulations\nIt should be general enough to cover generic modelling irrespective of software.\nBut specific enough to be useful\n\nSupport dfs files (using mikeio)\nHandle circular variables such as wave direction"
  },
  {
    "objectID": "user-guide/vision.html#limitations",
    "href": "user-guide/vision.html#limitations",
    "title": "Vision",
    "section": "",
    "text": "ModelSkill does not wish to cover\n\nExtreme value analysis\nDeterministic wave analysis such as crossing analysis\nRare alternative file types\nRarely used model result types\nRare observation types\nAnything project specific"
  },
  {
    "objectID": "user-guide/vision.html#future",
    "href": "user-guide/vision.html#future",
    "title": "Vision",
    "section": "",
    "text": "It should be possible to compare forecasts with observations using forecast lead time as a dimension. Planned 2024.\n\n\n\nCurrently 3D data is supported only as point data and only if data has already been extracted from model result files. It should be possible to extract date from 3D files directly. Furthermore, vertical columns data should be supported as an observation type with z as a dimension. Planned 2024.\n\n\n\nCreate a web app that wraps this library.\n\n\n\nBoth static as markdown, docx, pptx and interactive as html."
  },
  {
    "objectID": "user-guide/getting-started.html",
    "href": "user-guide/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "This page describes a simple ModelSkill workflow when model results and observations are already matched. See workflow page for a more elaborate workflow.",
    "crumbs": [
      "User Guide",
      "Getting started"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#installation",
    "href": "user-guide/getting-started.html#installation",
    "title": "Getting started",
    "section": "Installation",
    "text": "Installation\n\n\n\n\n\n\nUsing uv\n\n\n\nuv is an extremely fast Python package and project manager that is 10-100x faster than pip, and also makes it easy to install Python and manage projects. With uv, creating a virtual environment is as easy as uv venv.\n\n\nTo install ModelSkill, run this command in a terminal:\n\npipuv\n\n\npip install modelskill\n\n\nuv pip install modelskill",
    "crumbs": [
      "User Guide",
      "Getting started"
    ]
  },
  {
    "objectID": "user-guide/getting-started.html#skill-assessment",
    "href": "user-guide/getting-started.html#skill-assessment",
    "title": "Getting started",
    "section": "Skill assessment",
    "text": "Skill assessment\nThe simplest use-case for skill assessment is when you have a dataset of matched model results and observations in tabular format.\n\nimport pandas as pd\nimport modelskill as ms\ndf = pd.read_csv(\"../data/Vistula/sim1/6158100.csv\", parse_dates=True, index_col=\"Date\")\ndf.head()\n\n\n\n\n\n\n\n\nQobs\nQsim\nPrec\n\n\nDate\n\n\n\n\n\n\n\n2000-01-02\n5.2\n4.641\n0.11\n\n\n2000-01-03\n5.2\n4.666\n0.05\n\n\n2000-01-04\n5.2\n4.556\n0.72\n\n\n2000-01-05\n5.2\n4.470\n0.30\n\n\n2000-01-06\n5.2\n4.391\n1.38\n\n\n\n\n\n\n\n\ncmp = ms.from_matched(df, obs_item=\"Qobs\", mod_items=\"Qsim\", quantity=ms.Quantity(\"Discharge\", \"m3/s\"))\ncmp\n\n&lt;Comparer&gt;\nQuantity: Discharge [m3/s]\nObservation: Qobs, n_points=3653\nModel(s):\n0: Qsim\n\n\nA time series plot is a common way to visualize the comparison.\n\ncmp.plot.timeseries()\n\n\n\n\n\n\n\n\nAnother more quantitative way to analyze the compared data is to use a scatter plot, which optionally includes a skill table (Definition of the metrics).\n\ncmp.plot.scatter(skill_table=True)\n\n\n\n\n\n\n\n\nThe skill table can also be produced in tabular format, including specifing other metrics.\n\ncmp.skill(metrics=[\"bias\", \"mae\", \"rmse\", \"kge\", \"si\"])\n\n\n\n\n\n\n\n\nn\nbias\nmae\nrmse\nkge\nsi\n\n\nobservation\n\n\n\n\n\n\n\n\n\n\nQobs\n3653\n-5.303471\n7.473344\n14.903921\n0.360125\n0.866969",
    "crumbs": [
      "User Guide",
      "Getting started"
    ]
  },
  {
    "objectID": "user-guide/terminology.html",
    "href": "user-guide/terminology.html",
    "title": "Terminology",
    "section": "",
    "text": "ModelSkill is a library for assessing the skill of numerical models. It provides tools for comparing model results with observations, plotting the results and calculating validation metrics. This page defines some of the key terms used in the documentation.\n\n\nSkill refers to the ability of a numerical model to accurately represent the real-world phenomenon it aims to simulate. It is a measure of how well the model performs in reproducing the observed system. Skill can be assessed using various metrics, such as accuracy, precision, and reliability, depending on the specific goals of the model and the nature of the data. In ModelSkill, skill is also a specific method on Comparer objects that returns a SkillTable with aggregated skill scores per observation and model for a list of selected metrics.\n\n\n\nValidation is the process of assessing the model’s performance by comparing its output to real-world observations or data collected from the system being modeled. It helps ensure that the model accurately represents the system it simulates. Validation is typically performed before the model is used for prediction or decision-making.\n\n\n\nCalibration is the process of adjusting the model’s parameters or settings to improve its performance. It involves fine-tuning the model to better match observed data. Calibration aims to reduce discrepancies between model predictions and actual measurements. At the end of the calibration process, the calibrated model should be validated with independent data.\n\n\n\nPerformance is a measure of how well a numerical model operates in reproducing the observed system. It can be assessed using various metrics, such as accuracy, precision, and reliability, depending on the specific goals of the model and the nature of the data. In this context, performance is synonymous with skill.\n\n\n\nA timeseries is a sequence of data points in time. In ModelSkill, The data can either be from observations or model results. Timeseries can univariate or multivariate; ModelSkill primarily supports univariate timeseries. Multivariate timeseries can be assessed one variable at a time. Timeseries can also have different spatial dimensions, such as point, track, line, or area.\n\n\n\nAn observation refers to real-world data or measurements collected from the system you are modeling. Observations serve as a reference for assessing the model’s performance. These data points are used to compare with the model’s predictions during validation and calibration. Observations are usually based on field measurements or laboratory experiments, but for the purposes of model validation, they can also be derived from other models (e.g. a reference model). ModelSkill supports point and track observation types.\n\n\n\nA measurement is called observation in ModelSkill.\n\n\n\nA model result is the output of any type of numerical model. It is the data generated by the model during a simulation. Model results can be compared with observations to assess the model’s performance. In the context of validation, the term “model result” is often used interchangeably with “model output” or “model prediction”. ModelSkill supports point, track, dfsu and grid model result types.\n\n\n\nA metric is a quantitative measure (a mathematical expression) used to evaluate the performance of a numerical model. Metrics provide a standardized way to assess the model’s accuracy, precision, and other attributes. A metric aggregates the skill of a model into a single number. See list of metrics supported by ModelSkill.\n\n\n\nA score is a numerical value that summarizes the model’s performance based on chosen metrics. Scores can be used to rank or compare different models or model configurations. In the context of validation, the “skill score” or “validation score” often quantifies the model’s overall performance. The score of a model is a single number, calculated as a weighted average for all time-steps, observations and variables. If you want to perform automated calibration, you can use the score as the objective function. In ModelSkill, score is also a specific method on Comparer objects that returns a single number aggregated score using a specific metric.\n\n\n\nIn ModelSkill, observations and model results are matched when they refer to the same positions in space and time. If the observations and model results are already matched, the from_matched function can be used to create a Comparer directly. Otherwise, the match function can be used to match the observations and model results in space and time.\n\n\n\nThe function match is used to match a model result with observations. It returns a Comparer object or a ComparerCollection object.\n\n\n\nA Comparer is an object that stores the matched observation and model result data for a single observation. It is used to calculate validation metrics and generate plots. A Comparer can be created using the match function.\n\n\n\nA ComparerCollection is a collection of Comparers. It is used to compare multiple observations with one or more model results. A ComparerCollection can be created using the match function or by passing a list of Comparers to the ComparerCollection constructor.\n\n\n\nIn past versions of FMSkill/ModelSkill, the Connector class was used to connect observations and model results. This class has been deprecated and is no longer in use.\n\n\n\n\n\n\nAbbreviation\nMeaning\n\n\n\n\nms\nModelSkill\n\n\no or obs\nObservation\n\n\nmr or mod\nModel result\n\n\ncmp\nComparer\n\n\ncc\nComparerCollection\n\n\nsk\nSkillTable\n\n\nmtr\nMetric\n\n\nq\nQuantity",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#skill",
    "href": "user-guide/terminology.html#skill",
    "title": "Terminology",
    "section": "",
    "text": "Skill refers to the ability of a numerical model to accurately represent the real-world phenomenon it aims to simulate. It is a measure of how well the model performs in reproducing the observed system. Skill can be assessed using various metrics, such as accuracy, precision, and reliability, depending on the specific goals of the model and the nature of the data. In ModelSkill, skill is also a specific method on Comparer objects that returns a SkillTable with aggregated skill scores per observation and model for a list of selected metrics.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#validation",
    "href": "user-guide/terminology.html#validation",
    "title": "Terminology",
    "section": "",
    "text": "Validation is the process of assessing the model’s performance by comparing its output to real-world observations or data collected from the system being modeled. It helps ensure that the model accurately represents the system it simulates. Validation is typically performed before the model is used for prediction or decision-making.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#calibration",
    "href": "user-guide/terminology.html#calibration",
    "title": "Terminology",
    "section": "",
    "text": "Calibration is the process of adjusting the model’s parameters or settings to improve its performance. It involves fine-tuning the model to better match observed data. Calibration aims to reduce discrepancies between model predictions and actual measurements. At the end of the calibration process, the calibrated model should be validated with independent data.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#performance",
    "href": "user-guide/terminology.html#performance",
    "title": "Terminology",
    "section": "",
    "text": "Performance is a measure of how well a numerical model operates in reproducing the observed system. It can be assessed using various metrics, such as accuracy, precision, and reliability, depending on the specific goals of the model and the nature of the data. In this context, performance is synonymous with skill.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#timeseries",
    "href": "user-guide/terminology.html#timeseries",
    "title": "Terminology",
    "section": "",
    "text": "A timeseries is a sequence of data points in time. In ModelSkill, The data can either be from observations or model results. Timeseries can univariate or multivariate; ModelSkill primarily supports univariate timeseries. Multivariate timeseries can be assessed one variable at a time. Timeseries can also have different spatial dimensions, such as point, track, line, or area.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#observation",
    "href": "user-guide/terminology.html#observation",
    "title": "Terminology",
    "section": "",
    "text": "An observation refers to real-world data or measurements collected from the system you are modeling. Observations serve as a reference for assessing the model’s performance. These data points are used to compare with the model’s predictions during validation and calibration. Observations are usually based on field measurements or laboratory experiments, but for the purposes of model validation, they can also be derived from other models (e.g. a reference model). ModelSkill supports point and track observation types.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#measurement",
    "href": "user-guide/terminology.html#measurement",
    "title": "Terminology",
    "section": "",
    "text": "A measurement is called observation in ModelSkill.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#model-result",
    "href": "user-guide/terminology.html#model-result",
    "title": "Terminology",
    "section": "",
    "text": "A model result is the output of any type of numerical model. It is the data generated by the model during a simulation. Model results can be compared with observations to assess the model’s performance. In the context of validation, the term “model result” is often used interchangeably with “model output” or “model prediction”. ModelSkill supports point, track, dfsu and grid model result types.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#metric",
    "href": "user-guide/terminology.html#metric",
    "title": "Terminology",
    "section": "",
    "text": "A metric is a quantitative measure (a mathematical expression) used to evaluate the performance of a numerical model. Metrics provide a standardized way to assess the model’s accuracy, precision, and other attributes. A metric aggregates the skill of a model into a single number. See list of metrics supported by ModelSkill.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#score",
    "href": "user-guide/terminology.html#score",
    "title": "Terminology",
    "section": "",
    "text": "A score is a numerical value that summarizes the model’s performance based on chosen metrics. Scores can be used to rank or compare different models or model configurations. In the context of validation, the “skill score” or “validation score” often quantifies the model’s overall performance. The score of a model is a single number, calculated as a weighted average for all time-steps, observations and variables. If you want to perform automated calibration, you can use the score as the objective function. In ModelSkill, score is also a specific method on Comparer objects that returns a single number aggregated score using a specific metric.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#matched-data",
    "href": "user-guide/terminology.html#matched-data",
    "title": "Terminology",
    "section": "",
    "text": "In ModelSkill, observations and model results are matched when they refer to the same positions in space and time. If the observations and model results are already matched, the from_matched function can be used to create a Comparer directly. Otherwise, the match function can be used to match the observations and model results in space and time.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#match",
    "href": "user-guide/terminology.html#match",
    "title": "Terminology",
    "section": "",
    "text": "The function match is used to match a model result with observations. It returns a Comparer object or a ComparerCollection object.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#comparer",
    "href": "user-guide/terminology.html#comparer",
    "title": "Terminology",
    "section": "",
    "text": "A Comparer is an object that stores the matched observation and model result data for a single observation. It is used to calculate validation metrics and generate plots. A Comparer can be created using the match function.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#comparercollection",
    "href": "user-guide/terminology.html#comparercollection",
    "title": "Terminology",
    "section": "",
    "text": "A ComparerCollection is a collection of Comparers. It is used to compare multiple observations with one or more model results. A ComparerCollection can be created using the match function or by passing a list of Comparers to the ComparerCollection constructor.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#connector",
    "href": "user-guide/terminology.html#connector",
    "title": "Terminology",
    "section": "",
    "text": "In past versions of FMSkill/ModelSkill, the Connector class was used to connect observations and model results. This class has been deprecated and is no longer in use.",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/terminology.html#abbreviations",
    "href": "user-guide/terminology.html#abbreviations",
    "title": "Terminology",
    "section": "",
    "text": "Abbreviation\nMeaning\n\n\n\n\nms\nModelSkill\n\n\no or obs\nObservation\n\n\nmr or mod\nModel result\n\n\ncmp\nComparer\n\n\ncc\nComparerCollection\n\n\nsk\nSkillTable\n\n\nmtr\nMetric\n\n\nq\nQuantity",
    "crumbs": [
      "User Guide",
      "Terminology"
    ]
  },
  {
    "objectID": "user-guide/plotting.html",
    "href": "user-guide/plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "PointObservations and PointModelResults can be plotted using their plot accessor:\n\n\nObservation and model data\nimport modelskill as ms\no = ms.PointObservation('../data/SW/HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887)\nmr = ms.PointModelResult('../data/SW/ts_storm_4.dfs0', item=0) # TODO coords\n\n\n\no.plot.timeseries();\n\n\n\n\n\n\n\n\n\nmr.plot.timeseries();\n\n\n\n\n\n\n\n\n\nmr.plot.hist();",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/plotting.html#plotting-observations-and-model-results",
    "href": "user-guide/plotting.html#plotting-observations-and-model-results",
    "title": "Plotting",
    "section": "",
    "text": "PointObservations and PointModelResults can be plotted using their plot accessor:\n\n\nObservation and model data\nimport modelskill as ms\no = ms.PointObservation('../data/SW/HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887)\nmr = ms.PointModelResult('../data/SW/ts_storm_4.dfs0', item=0) # TODO coords\n\n\n\no.plot.timeseries();\n\n\n\n\n\n\n\n\n\nmr.plot.timeseries();\n\n\n\n\n\n\n\n\n\nmr.plot.hist();",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/plotting.html#temporal-coverage",
    "href": "user-guide/plotting.html#temporal-coverage",
    "title": "Plotting",
    "section": "Temporal coverage",
    "text": "Temporal coverage\nThe temporal coverage of observations and model results can be plotted using the temporal_coverage function:\n\n\nObservation and model data\no1 = ms.PointObservation('../data/SW/HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887)\no2 = ms.TrackObservation(\"../data/SW/Alti_c2_Dutch.dfs0\", item=3)\nmr = ms.DfsuModelResult('../data/SW/HKZN_local_2017_DutchCoast.dfsu', item=0)\n\n\nWith a few observation and model result objects, the temporal coverage can be plotted:\n\nms.plotting.temporal_coverage(obs=[o1, o2], mod=mr);",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/plotting.html#spatial-overview",
    "href": "user-guide/plotting.html#spatial-overview",
    "title": "Plotting",
    "section": "Spatial overview",
    "text": "Spatial overview\nThe spatial coverage of observations and model results can be plotted using the spatial_overview function:\n\nms.plotting.spatial_overview([o1, o2], mr);",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/plotting.html#compared-data",
    "href": "user-guide/plotting.html#compared-data",
    "title": "Plotting",
    "section": "Compared data",
    "text": "Compared data\nThe plot accessor on a Comparer or ComparerCollection object can be used to plot the compared data:\n\ncmp = ms.match(obs=o1, mod=mr)\ncmp\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA_Hm0, n_points=386\nModel(s):\n0: HKZN_local_2017_DutchCoast\n\n\n\ncmp.plot.timeseries();\n\n\n\n\n\n\n\n\n\ncmp.plot.scatter();",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/plotting.html#taylor-diagrams",
    "href": "user-guide/plotting.html#taylor-diagrams",
    "title": "Plotting",
    "section": "Taylor diagrams",
    "text": "Taylor diagrams\nA Taylor diagram shows how well a model result matches an observation in terms of correlation, standard deviation and root mean squared error. The taylor plot can be accessed through the Comparer plot accessor or the ComparerCollection plot accessor:\n\ncmp.plot.taylor()\n\n\n\n\n\n\n\n\nThe radial distance from the point to the observation point is the standard deviation ratio, the angle is the correlation coefficient and the distance from the observation point to the model point is the root mean square error ratio. The closer the model point is to the observation point, the better the model result matches the observation. The closer the model point is to the origin, the better the model result matches the observation in terms of standard deviation and root mean square error. The closer the model point is to the horizontal axis, the better the model result matches the observation in terms of correlation.",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/plotting.html#directional-data-e.g.-wind-or-currents",
    "href": "user-guide/plotting.html#directional-data-e.g.-wind-or-currents",
    "title": "Plotting",
    "section": "Directional data (e.g. wind or currents)",
    "text": "Directional data (e.g. wind or currents)\nDirectional data can be plotted using the wind_rose. The function takes an array-like structure with speed and direction as columns (from one or two sources) and plots a wind rose:\n\nimport mikeio\nds = mikeio.read(\"../data/wave_dir.dfs0\")\ndf = ds[[0,2,1,3]].to_dataframe()\ndf.round(2).head()\n\n\n\n\n\n\n\n\nChina_Model: Sign. Wave Height\nChina_Model: Mean Wave Direction\nChina_Measured: Sign. Wave Height\nChina_Measured: Mean Wave Direction\n\n\n\n\n2006-12-20 22:00:00\n0.30\n320.58\n0.25\n330.39\n\n\n2006-12-20 23:00:00\n0.43\n316.24\n0.23\n329.59\n\n\n2006-12-21 00:00:00\n0.38\n316.11\n0.20\n321.02\n\n\n2006-12-21 01:00:00\n0.37\n315.34\n0.18\n311.00\n\n\n2006-12-21 02:00:00\n0.41\n313.36\n0.18\n300.78\n\n\n\n\n\n\n\n\nms.plotting.wind_rose(df, figsize=(12,6));",
    "crumbs": [
      "User Guide",
      "Plotting"
    ]
  },
  {
    "objectID": "user-guide/data-structures.html",
    "href": "user-guide/data-structures.html",
    "title": "Data Structures",
    "section": "",
    "text": "The main data structures in ModelSkill can be grouped into three categories:\n\nPrimary data (observations and model results)\nComparer objects\nSkill objects\n\nAll objects share some common principles:\n\nThe data container is accesssible via the data attribute.\nThe data container is an xarray object (except for the SkillTable object, which is a pandas object).\nThe main data selection method is sel, which is a wrapper around xarray.Dataset.sel.\nAll plotting are accessible via the plot accessor of the object.\n\n\n\nThe primary data of ModelSkill are the data that needs to be compared: observations and model results. The underlying data structures are very similar and can be grouped according to the spatial dimensionality (gtype) of the data:\n\npoint: 0D time series data\ntrack: 0D time series data at moving locations (trajectories)\ngrid: gridded 2D data\ndfsu: flexible mesh 2D data\n\nPoint and track data are both TimeSeries objects, while grid and dfsu data are both SpatialField objects. TimeSeries objects are ready to be compared whereas data from SpatialField object needs to be extracted first (the extracted object will be of the TimeSeries type).\nTimeSeries objects contains its data in an xarray.Dataset with the actual data in the first DataArray and optional auxilliary data in the following DataArrays. The DataArrays have a kind attribute with either observation or model.\n\n\n\nComparer objects are results of a matching procedure (between observations and model results) or constructed directly from already matched data. A comparison of a single observation and one or more model results are stored in a Comparer object. A comparison of multiple observations and one or more model results are stored in a ComparerCollection object which is a collection of Comparer objects.\nThe matched data in a Comparer is stored in an xarray.Dataset which can be accessed via the data attribute. The Dataset has an attribute gtype which is a string describing the type of data (e.g. point, track). The first DataArray in the Dataset is the observation data, the next DataArrays are model result data and optionally additional DataArrays are auxilliarye data. Each of the DataArrays have a kind attribute with either observation, model or aux.\nBoth Comparer and ComparerCollection have a plot accessor for plotting the data (e.g. cmp.plot.timeseries() or cmp.plot.scatter()).\n\n\n\nCalling a skill method on a comparer object will return a skill object with skill scores (statistics) from comparing observation and model result data using different metrics (e.g. root mean square error). Two skill objects are currently implemented: SkillTable and SkillGrid. The first is relevant for all ModelSkill users while the latter is relevant for users of the track data (e.g. MetOcean studies using satellite altimetry data).\nIf c is a comparer object, then the following skill methods are available:\n\nc.skill() -&gt; SkillTable\nc.mean_skill() -&gt; SkillTable\nc.gridded_skill() -&gt; SkillGrid",
    "crumbs": [
      "User Guide",
      "Data Structures"
    ]
  },
  {
    "objectID": "user-guide/data-structures.html#observations-and-model-results",
    "href": "user-guide/data-structures.html#observations-and-model-results",
    "title": "Data Structures",
    "section": "",
    "text": "The primary data of ModelSkill are the data that needs to be compared: observations and model results. The underlying data structures are very similar and can be grouped according to the spatial dimensionality (gtype) of the data:\n\npoint: 0D time series data\ntrack: 0D time series data at moving locations (trajectories)\ngrid: gridded 2D data\ndfsu: flexible mesh 2D data\n\nPoint and track data are both TimeSeries objects, while grid and dfsu data are both SpatialField objects. TimeSeries objects are ready to be compared whereas data from SpatialField object needs to be extracted first (the extracted object will be of the TimeSeries type).\nTimeSeries objects contains its data in an xarray.Dataset with the actual data in the first DataArray and optional auxilliary data in the following DataArrays. The DataArrays have a kind attribute with either observation or model.",
    "crumbs": [
      "User Guide",
      "Data Structures"
    ]
  },
  {
    "objectID": "user-guide/data-structures.html#comparer-objects",
    "href": "user-guide/data-structures.html#comparer-objects",
    "title": "Data Structures",
    "section": "",
    "text": "Comparer objects are results of a matching procedure (between observations and model results) or constructed directly from already matched data. A comparison of a single observation and one or more model results are stored in a Comparer object. A comparison of multiple observations and one or more model results are stored in a ComparerCollection object which is a collection of Comparer objects.\nThe matched data in a Comparer is stored in an xarray.Dataset which can be accessed via the data attribute. The Dataset has an attribute gtype which is a string describing the type of data (e.g. point, track). The first DataArray in the Dataset is the observation data, the next DataArrays are model result data and optionally additional DataArrays are auxilliarye data. Each of the DataArrays have a kind attribute with either observation, model or aux.\nBoth Comparer and ComparerCollection have a plot accessor for plotting the data (e.g. cmp.plot.timeseries() or cmp.plot.scatter()).",
    "crumbs": [
      "User Guide",
      "Data Structures"
    ]
  },
  {
    "objectID": "user-guide/data-structures.html#skill-objects",
    "href": "user-guide/data-structures.html#skill-objects",
    "title": "Data Structures",
    "section": "",
    "text": "Calling a skill method on a comparer object will return a skill object with skill scores (statistics) from comparing observation and model result data using different metrics (e.g. root mean square error). Two skill objects are currently implemented: SkillTable and SkillGrid. The first is relevant for all ModelSkill users while the latter is relevant for users of the track data (e.g. MetOcean studies using satellite altimetry data).\nIf c is a comparer object, then the following skill methods are available:\n\nc.skill() -&gt; SkillTable\nc.mean_skill() -&gt; SkillTable\nc.gridded_skill() -&gt; SkillGrid",
    "crumbs": [
      "User Guide",
      "Data Structures"
    ]
  },
  {
    "objectID": "api/PointObservation.html",
    "href": "api/PointObservation.html",
    "title": "PointObservation",
    "section": "",
    "text": "PointObservation(\n    self,\n    data,\n    *,\n    item=None,\n    x=None,\n    y=None,\n    z=None,\n    name=None,\n    weight=1.0,\n    quantity=None,\n    aux_items=None,\n    attrs=None,\n)\nClass for observations of fixed locations\nCreate a PointObservation from a dfs0 file or a pd.DataFrame.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n(str, Path, mikeio.Dataset, mikeio.DataArray, pd.DataFrame, pd.Series, xr.Dataset or xr.DataArray)\nfilename (.dfs0 or .nc) or object with the data\nrequired\n\n\nitem\n(int, str)\nindex or name of the wanted item/column, by default None if data contains more than one item, item must be given\nNone\n\n\nx\nfloat\nx-coordinate of the observation point, inferred from data if not given, else None\nNone\n\n\ny\nfloat\ny-coordinate of the observation point, inferred from data if not given, else None\nNone\n\n\nz\nfloat\nz-coordinate of the observation point, inferred from data if not given, else None\nNone\n\n\nname\nstr\nuser-defined name for easy identification in plots etc, by default file basename\nNone\n\n\nquantity\nQuantity\nThe quantity of the observation, for validation with model results For MIKE dfs files this is inferred from the EUM information\nNone\n\n\naux_items\nlist\nlist of names or indices of auxiliary items, by default None\nNone\n\n\nattrs\ndict\nadditional attributes to be added to the data, by default None\nNone\n\n\nweight\nfloat\nweighting factor for skill scores, by default 1.0\n1.0\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o2 = ms.PointObservation(\"klagshamn.dfs0\", item=\"Water Level\", x=366844, y=6154291)\n&gt;&gt;&gt; o3 = ms.PointObservation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o4 = ms.PointObservation(df[\"Water Level\"], x=366844, y=6154291)\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nattrs\nAttributes of the observation\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nweight\nWeighting factor for skill scores\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate\n\n\nz\nz-coordinate of observation point\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nPointObservation.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nPointObservation.sel(**kwargs)\nSelect data by label\n\n\n\nPointObservation.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nPointObservation.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Observations",
      "PointObservation"
    ]
  },
  {
    "objectID": "api/PointObservation.html#parameters",
    "href": "api/PointObservation.html#parameters",
    "title": "PointObservation",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\n(str, Path, mikeio.Dataset, mikeio.DataArray, pd.DataFrame, pd.Series, xr.Dataset or xr.DataArray)\nfilename (.dfs0 or .nc) or object with the data\nrequired\n\n\nitem\n(int, str)\nindex or name of the wanted item/column, by default None if data contains more than one item, item must be given\nNone\n\n\nx\nfloat\nx-coordinate of the observation point, inferred from data if not given, else None\nNone\n\n\ny\nfloat\ny-coordinate of the observation point, inferred from data if not given, else None\nNone\n\n\nz\nfloat\nz-coordinate of the observation point, inferred from data if not given, else None\nNone\n\n\nname\nstr\nuser-defined name for easy identification in plots etc, by default file basename\nNone\n\n\nquantity\nQuantity\nThe quantity of the observation, for validation with model results For MIKE dfs files this is inferred from the EUM information\nNone\n\n\naux_items\nlist\nlist of names or indices of auxiliary items, by default None\nNone\n\n\nattrs\ndict\nadditional attributes to be added to the data, by default None\nNone\n\n\nweight\nfloat\nweighting factor for skill scores, by default 1.0\n1.0",
    "crumbs": [
      "API Reference",
      "Observations",
      "PointObservation"
    ]
  },
  {
    "objectID": "api/PointObservation.html#examples",
    "href": "api/PointObservation.html#examples",
    "title": "PointObservation",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o2 = ms.PointObservation(\"klagshamn.dfs0\", item=\"Water Level\", x=366844, y=6154291)\n&gt;&gt;&gt; o3 = ms.PointObservation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o4 = ms.PointObservation(df[\"Water Level\"], x=366844, y=6154291)",
    "crumbs": [
      "API Reference",
      "Observations",
      "PointObservation"
    ]
  },
  {
    "objectID": "api/PointObservation.html#attributes",
    "href": "api/PointObservation.html#attributes",
    "title": "PointObservation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nattrs\nAttributes of the observation\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nweight\nWeighting factor for skill scores\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate\n\n\nz\nz-coordinate of observation point",
    "crumbs": [
      "API Reference",
      "Observations",
      "PointObservation"
    ]
  },
  {
    "objectID": "api/PointObservation.html#methods",
    "href": "api/PointObservation.html#methods",
    "title": "PointObservation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nPointObservation.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nPointObservation.sel(**kwargs)\nSelect data by label\n\n\n\nPointObservation.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nPointObservation.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Observations",
      "PointObservation"
    ]
  },
  {
    "objectID": "api/GridModelResult.html",
    "href": "api/GridModelResult.html",
    "title": "GridModelResult",
    "section": "",
    "text": "GridModelResult(\n    self,\n    data,\n    *,\n    name=None,\n    item=None,\n    quantity=None,\n    aux_items=None,\n)\nConstruct a GridModelResult from a file or xarray.Dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\ntypes.GridType\nthe input data or file path\nrequired\n\n\nname\nstr\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nitem\nstr or int\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nextract\nExtract ModelResult at observation positions\n\n\n\n\n\nGridModelResult.extract(observation, spatial_method=None)\nExtract ModelResult at observation positions\nNote: this method is typically not called directly, but through the match() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobservation\n or \npositions (and times) at which modelresult should be extracted\nrequired\n\n\nspatial_method\nOptional[str]\nmethod in xarray.Dataset.interp, typically either “nearest” or “linear”, by default None = ‘linear’\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPointModelResult or TrackModelResult\nextracted modelresult",
    "crumbs": [
      "API Reference",
      "Model Result",
      "GridModelResult"
    ]
  },
  {
    "objectID": "api/GridModelResult.html#parameters",
    "href": "api/GridModelResult.html#parameters",
    "title": "GridModelResult",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\ntypes.GridType\nthe input data or file path\nrequired\n\n\nname\nstr\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nitem\nstr or int\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone",
    "crumbs": [
      "API Reference",
      "Model Result",
      "GridModelResult"
    ]
  },
  {
    "objectID": "api/GridModelResult.html#methods",
    "href": "api/GridModelResult.html#methods",
    "title": "GridModelResult",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nextract\nExtract ModelResult at observation positions\n\n\n\n\n\nGridModelResult.extract(observation, spatial_method=None)\nExtract ModelResult at observation positions\nNote: this method is typically not called directly, but through the match() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobservation\n or \npositions (and times) at which modelresult should be extracted\nrequired\n\n\nspatial_method\nOptional[str]\nmethod in xarray.Dataset.interp, typically either “nearest” or “linear”, by default None = ‘linear’\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPointModelResult or TrackModelResult\nextracted modelresult",
    "crumbs": [
      "API Reference",
      "Model Result",
      "GridModelResult"
    ]
  },
  {
    "objectID": "api/Quantity.html",
    "href": "api/Quantity.html",
    "title": "Quantity",
    "section": "",
    "text": "Quantity(self, name, unit, is_directional=False)\nQuantity of data",
    "crumbs": [
      "API Reference",
      "Quantity"
    ]
  },
  {
    "objectID": "api/Quantity.html#parameters",
    "href": "api/Quantity.html#parameters",
    "title": "Quantity",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of the quantity\nrequired\n\n\nunit\nstr\nUnit of the quantity\nrequired\n\n\nis_directional\nbool\nWhether the quantity is directional (e.g. Wind Direction), by default False\nFalse",
    "crumbs": [
      "API Reference",
      "Quantity"
    ]
  },
  {
    "objectID": "api/Quantity.html#examples",
    "href": "api/Quantity.html#examples",
    "title": "Quantity",
    "section": "Examples",
    "text": "Examples\n\nfrom modelskill import Quantity\nwl = Quantity(name=\"Water Level\", unit=\"meter\")\nwl\n\nQuantity(name='Water Level', unit='meter')\n\n\n\nwl.name\n'Water Level'\n\n'Water Level'\n\n\n\nwl.unit\n\n'meter'\n\n\n\nwl.is_compatible(wl)\n\nTrue\n\n\n\nQuantity(name=\"Wind Direction\", unit=\"degree\", is_directional=True)\n\nQuantity(name='Wind Direction', unit='degree', is_directional=True)",
    "crumbs": [
      "API Reference",
      "Quantity"
    ]
  },
  {
    "objectID": "api/Quantity.html#methods",
    "href": "api/Quantity.html#methods",
    "title": "Quantity",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nfrom_cf_attrs\nCreate a Quantity from a CF compliant attributes dictionary\n\n\nfrom_mikeio_eum_name\nCreate a Quantity from a name recognized by mikeio\n\n\nfrom_mikeio_iteminfo\nCreate a Quantity from mikeio ItemInfo\n\n\nis_compatible\nCheck if the quantity is compatible with another quantity\n\n\n\n\nfrom_cf_attrs\nQuantity.from_cf_attrs(attrs)\nCreate a Quantity from a CF compliant attributes dictionary\nIf units is “degree”, “degrees” or “Degree true”, the quantity is assumed to be directional. Based on https://codes.ecmwf.int/grib/param-db/ and https://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nattrs\nMapping[str, str]\nAttributes dictionary\nrequired\n\n\n\n\n\nExamples\n\nQuantity.from_cf_attrs({'long_name': 'Water Level', 'units': 'meter'})\n\nQuantity(name='Water Level', unit='meter')\n\n\n\nQuantity.from_cf_attrs({'long_name': 'Wind direction', 'units': 'degree'})\n\nQuantity(name='Wind direction', unit='degree', is_directional=True)\n\n\n\n\n\nfrom_mikeio_eum_name\nQuantity.from_mikeio_eum_name(type_name)\nCreate a Quantity from a name recognized by mikeio\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntype_name\nstr\nName of the quantity\nrequired\n\n\n\n\n\nExamples\n\nQuantity.from_mikeio_eum_name(\"Water Level\")\n\n/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/modelskill/quantity.py:166: UserWarning:\n\nunit='meter' was automatically set for type_name='Water Level'\n\n\n\nQuantity(name='Water Level', unit='meter')\n\n\n\n\n\nfrom_mikeio_iteminfo\nQuantity.from_mikeio_iteminfo(iteminfo)\nCreate a Quantity from mikeio ItemInfo\nIf the unit is “degree”, the quantity is assumed to be directional.\n\n\nis_compatible\nQuantity.is_compatible(other)\nCheck if the quantity is compatible with another quantity\n\nExamples\n\nwl = Quantity(name=\"Water Level\", unit=\"meter\")\nws = Quantity(name=\"Wind Speed\", unit=\"meter per second\")\nwl.is_compatible(ws)\n\nFalse\n\n\n\nuq = Quantity(name=\"Undefined\", unit=\"Undefined\")\nwl.is_compatible(uq)\n\nTrue",
    "crumbs": [
      "API Reference",
      "Quantity"
    ]
  },
  {
    "objectID": "api/observation.html",
    "href": "api/observation.html",
    "title": "observation",
    "section": "",
    "text": "observation(data, *, gtype=None, **kwargs)\nCreate an appropriate observation object.\nA factory function for creating an appropriate observation object based on the data and args.\nIf ‘x’ or ‘y’ is given, a PointObservation is created. If ‘x_item’ or ‘y_item’ is given, a TrackObservation is created.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nDataInputType\nThe data to be used for creating the Observation object.\nrequired\n\n\ngtype\nOptional[Literal['point', 'track']]\nThe geometry type of the data. If not specified, it will be guessed from the data.\nNone\n\n\n**kwargs\n\nAdditional keyword arguments to be passed to the Observation constructor.\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o_pt = ms.observation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o_tr = ms.observation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)",
    "crumbs": [
      "API Reference",
      "Observations",
      "observation"
    ]
  },
  {
    "objectID": "api/observation.html#parameters",
    "href": "api/observation.html#parameters",
    "title": "observation",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\nDataInputType\nThe data to be used for creating the Observation object.\nrequired\n\n\ngtype\nOptional[Literal['point', 'track']]\nThe geometry type of the data. If not specified, it will be guessed from the data.\nNone\n\n\n**kwargs\n\nAdditional keyword arguments to be passed to the Observation constructor.\n{}",
    "crumbs": [
      "API Reference",
      "Observations",
      "observation"
    ]
  },
  {
    "objectID": "api/observation.html#examples",
    "href": "api/observation.html#examples",
    "title": "observation",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o_pt = ms.observation(df, item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o_tr = ms.observation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)",
    "crumbs": [
      "API Reference",
      "Observations",
      "observation"
    ]
  },
  {
    "objectID": "api/TrackModelResult.html",
    "href": "api/TrackModelResult.html",
    "title": "TrackModelResult",
    "section": "",
    "text": "TrackModelResult(\n    self,\n    data,\n    *,\n    name=None,\n    item=None,\n    quantity=None,\n    x_item=0,\n    y_item=1,\n    keep_duplicates='first',\n    aux_items=None,\n)\nModel result for a track.\nConstruct a TrackModelResult from a dfs0 file, mikeio.Dataset, pandas.DataFrame or a xarray.Datasets\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\ntypes.TrackType\nThe input data or file path\nrequired\n\n\nname\nOptional[str]\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nitem\nstr | int | None\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nx_item\nstr | int | None\nItem of the first coordinate of positions, by default None\n0\n\n\ny_item\nstr | int | None\nItem of the second coordinate of positions, by default None\n1\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\nkeep_duplicates\n(str, bool)\nStrategy for handling duplicate timestamps (wraps xarray.Dataset.drop_duplicates) “first” to keep first occurrence, “last” to keep last occurrence, False to drop all duplicates, “offset” to add milliseconds to consecutive duplicates, by default “first”\n'first'\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nTrackModelResult.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nTrackModelResult.sel(**kwargs)\nSelect data by label\n\n\n\nTrackModelResult.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nTrackModelResult.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "TrackModelResult"
    ]
  },
  {
    "objectID": "api/TrackModelResult.html#parameters",
    "href": "api/TrackModelResult.html#parameters",
    "title": "TrackModelResult",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\ntypes.TrackType\nThe input data or file path\nrequired\n\n\nname\nOptional[str]\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nitem\nstr | int | None\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nx_item\nstr | int | None\nItem of the first coordinate of positions, by default None\n0\n\n\ny_item\nstr | int | None\nItem of the second coordinate of positions, by default None\n1\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\nkeep_duplicates\n(str, bool)\nStrategy for handling duplicate timestamps (wraps xarray.Dataset.drop_duplicates) “first” to keep first occurrence, “last” to keep last occurrence, False to drop all duplicates, “offset” to add milliseconds to consecutive duplicates, by default “first”\n'first'\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone",
    "crumbs": [
      "API Reference",
      "Model Result",
      "TrackModelResult"
    ]
  },
  {
    "objectID": "api/TrackModelResult.html#attributes",
    "href": "api/TrackModelResult.html#attributes",
    "title": "TrackModelResult",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate",
    "crumbs": [
      "API Reference",
      "Model Result",
      "TrackModelResult"
    ]
  },
  {
    "objectID": "api/TrackModelResult.html#methods",
    "href": "api/TrackModelResult.html#methods",
    "title": "TrackModelResult",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nTrackModelResult.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nTrackModelResult.sel(**kwargs)\nSelect data by label\n\n\n\nTrackModelResult.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nTrackModelResult.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "TrackModelResult"
    ]
  },
  {
    "objectID": "api/skill.SkillArray.html",
    "href": "api/skill.SkillArray.html",
    "title": "skill.SkillArray",
    "section": "",
    "text": "skill.SkillArray(self, data)\nVisualize skill metric.\nObtained by selecting a single metric from a SkillTable.\n\n\n&gt;&gt;&gt; sk = cc.skill()   # SkillTable\n&gt;&gt;&gt; sk.rmse           # SkillArray\n&gt;&gt;&gt; sk.rmse.plot.line()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nname\nName of the metric\n\n\nplot\nPlot using the SkillArrayPlotter\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nto_dataframe\nConvert SkillArray to pd.DataFrame\n\n\nto_geodataframe\nConvert SkillArray to geopandas.GeoDataFrame\n\n\n\n\n\nskill.SkillArray.to_dataframe(drop_xy=True)\nConvert SkillArray to pd.DataFrame\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndrop_xy\nbool\nDrop the x, y coordinates?, by default True\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nSkill data as pd.DataFrame\n\n\n\n\n\n\n\nskill.SkillArray.to_geodataframe(crs='EPSG:4326')\nConvert SkillArray to geopandas.GeoDataFrame\nNote: requires geopandas to be installed\nNote: requires x and y columns to be present\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system identifier passed to the GeoDataFrame constructor, by default “EPSG:4326”\n'EPSG:4326'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ngpd.GeoDataFrame\nSkill data as GeoDataFrame",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillArray"
    ]
  },
  {
    "objectID": "api/skill.SkillArray.html#examples",
    "href": "api/skill.SkillArray.html#examples",
    "title": "skill.SkillArray",
    "section": "",
    "text": "&gt;&gt;&gt; sk = cc.skill()   # SkillTable\n&gt;&gt;&gt; sk.rmse           # SkillArray\n&gt;&gt;&gt; sk.rmse.plot.line()",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillArray"
    ]
  },
  {
    "objectID": "api/skill.SkillArray.html#attributes",
    "href": "api/skill.SkillArray.html#attributes",
    "title": "skill.SkillArray",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nname\nName of the metric\n\n\nplot\nPlot using the SkillArrayPlotter",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillArray"
    ]
  },
  {
    "objectID": "api/skill.SkillArray.html#methods",
    "href": "api/skill.SkillArray.html#methods",
    "title": "skill.SkillArray",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nto_dataframe\nConvert SkillArray to pd.DataFrame\n\n\nto_geodataframe\nConvert SkillArray to geopandas.GeoDataFrame\n\n\n\n\n\nskill.SkillArray.to_dataframe(drop_xy=True)\nConvert SkillArray to pd.DataFrame\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndrop_xy\nbool\nDrop the x, y coordinates?, by default True\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nSkill data as pd.DataFrame\n\n\n\n\n\n\n\nskill.SkillArray.to_geodataframe(crs='EPSG:4326')\nConvert SkillArray to geopandas.GeoDataFrame\nNote: requires geopandas to be installed\nNote: requires x and y columns to be present\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system identifier passed to the GeoDataFrame constructor, by default “EPSG:4326”\n'EPSG:4326'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ngpd.GeoDataFrame\nSkill data as GeoDataFrame",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillArray"
    ]
  },
  {
    "objectID": "api/comparison.ComparerCollectionPlotter.html",
    "href": "api/comparison.ComparerCollectionPlotter.html",
    "title": "comparison.ComparerCollectionPlotter",
    "section": "",
    "text": "comparison.ComparerCollectionPlotter(self, cc)\nPlotter for ComparerCollection\n\n\n&gt;&gt;&gt; cc.plot.scatter()\n&gt;&gt;&gt; cc.plot.hist()\n&gt;&gt;&gt; cc.plot.kde()\n&gt;&gt;&gt; cc.plot.taylor()\n&gt;&gt;&gt; cc.plot.box()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nbox\nPlot box plot of observations and model data.\n\n\nhist\nPlot histogram of specific model and all observations.\n\n\nkde\nPlot kernel density estimate of observation and model data.\n\n\nqq\nMake quantile-quantile (q-q) plot of model data and observations.\n\n\nresidual_hist\nplot histogram of residual values\n\n\nscatter\nScatter plot tailored for comparing model output with observations.\n\n\nspatial_overview\nPlot observation points on a map showing the model domain\n\n\ntaylor\nTaylor diagram for model skill comparison.\n\n\ntemporal_coverage\nPlot graph showing temporal coverage for all observations and models\n\n\n\n\n\ncomparison.ComparerCollectionPlotter.box(\n    ax=None,\n    figsize=None,\n    title=None,\n    **kwargs,\n)\nPlot box plot of observations and model data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nAxes\nmatplotlib axes, by default None\nNone\n\n\nfigsize\ntuple\nwidth and height of the figure, by default None\nNone\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\n**kwargs\n\npassed to pandas.DataFrame.plot.box()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxes\nmatplotlib axes\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.box()\n&gt;&gt;&gt; cc.plot.box(showmeans=True)\n&gt;&gt;&gt; cc.plot.box(ax=ax, title=\"Box plot\")\n\n\n\n\ncomparison.ComparerCollectionPlotter.hist(\n    bins=100,\n    *,\n    model=None,\n    title=None,\n    density=True,\n    alpha=0.5,\n    ax=None,\n    figsize=None,\n    **kwargs,\n)\nPlot histogram of specific model and all observations.\nWraps pandas.DataFrame hist() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\nnumber of bins, by default 100\n100\n\n\ntitle\nstr\nplot title, default: observation name\nNone\n\n\ndensity\nbool\nIf True, draw and return a probability density, by default True\nTrue\n\n\nalpha\nfloat\nalpha transparency fraction, by default 0.5\n0.5\n\n\nax\nmatplotlib axes\naxes to plot on, by default None\nNone\n\n\nfigsize\ntuple\nwidth and height of the figure, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to df.hist()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.hist()\n&gt;&gt;&gt; cc.plot.hist(bins=100)\n\n\n\npandas.Series.hist matplotlib.axes.Axes.hist\n\n\n\n\ncomparison.ComparerCollectionPlotter.kde(\n    ax=None,\n    figsize=None,\n    title=None,\n    **kwargs,\n)\nPlot kernel density estimate of observation and model data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nAxes\nmatplotlib axes, by default None\nNone\n\n\nfigsize\ntuple\nwidth and height of the figure, by default None\nNone\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\n**kwargs\n\npassed to pandas.DataFrame.plot.kde()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxes\nmatplotlib axes\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.kde()\n&gt;&gt;&gt; cc.plot.kde(bw_method=0.5)\n&gt;&gt;&gt; cc.plot.kde(bw_method='silverman')\n\n\n\n\ncomparison.ComparerCollectionPlotter.qq(\n    quantiles=None,\n    *,\n    title=None,\n    ax=None,\n    figsize=None,\n    **kwargs,\n)\nMake quantile-quantile (q-q) plot of model data and observations.\nPrimarily used to compare multiple models.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\ntitle\nstr\nplot title, default: “Q-Q plot for [observation name]”\nNone\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.plot()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.qq()\n\n\n\n\ncomparison.ComparerCollectionPlotter.residual_hist(\n    bins=100,\n    title=None,\n    color=None,\n    figsize=None,\n    ax=None,\n    **kwargs,\n)\nplot histogram of residual values\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\nspecification of bins, by default 100\n100\n\n\ntitle\nstr\nplot title, default: Residuals, [name]\nNone\n\n\ncolor\nstr\nresidual color, by default “#8B8D8E”\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\nax\nAxes | list[Axes]\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.hist()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxes | list[Axes]\n\n\n\n\n\n\n\n\ncomparison.ComparerCollectionPlotter.scatter(\n    bins=120,\n    quantiles=None,\n    fit_to_quantiles=False,\n    show_points=None,\n    show_hist=None,\n    show_density=None,\n    norm=None,\n    backend='matplotlib',\n    figsize=(8, 8),\n    xlim=None,\n    ylim=None,\n    reg_method='ols',\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    skill_table=None,\n    ax=None,\n    **kwargs,\n)\nScatter plot tailored for comparing model output with observations.\nOptionally, with density histogram.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint | float\nbins for the 2D histogram on the background. By default 120 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges\n120\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000); if int, this is the number of points; if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\nfit_to_quantiles\nbool\nby default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution, by default False\nFalse\n\n\nshow_points\n(bool, int, float)\nShould the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. e.g. 0.5 shows 50% of the points. int: if ‘n’ (int) given, then ‘n’ points will be displayed, randomly selected\nNone\n\n\nshow_hist\nbool\nshow the data density as a a 2d histogram, by default None\nNone\n\n\nshow_density\nOptional[bool]\nshow the data density as a colormap of the scatter, by default None. If both show_density and show_hist are None, then show_density is used by default. If number of points is less than 200, then show_density is False as default. For binning the data, the kword bins=Float is used.\nNone\n\n\nnorm\nmatplotlib.colors norm\ncolormap normalization. If None, defaults to matplotlib.colors.PowerNorm(vmin=1, gamma=0.5)\nNone\n\n\nbackend\nstr\nuse “plotly” (interactive) or “matplotlib” backend, by default “matplotlib”\n'matplotlib'\n\n\nfigsize\ntuple\nwidth and height of the figure, by default (8, 8)\n(8, 8)\n\n\nxlim\ntuple\nplot range for the observation (xmin, xmax), by default None\nNone\n\n\nylim\ntuple\nplot range for the model (ymin, ymax), by default None\nNone\n\n\nreg_method\nstr or bool\nmethod for determining the regression line “ols” : ordinary least squares regression “odr” : orthogonal distance regression, False : no regression line, by default “ols”\n'ols'\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\nxlabel\nstr\nx-label text on plot, by default None\nNone\n\n\nylabel\nstr\ny-label text on plot, by default None\nNone\n\n\nskill_table\nOptional[Union[str, List[str], Mapping[str, str], bool]]\nlist of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list. This kword adds a box at the right of the scatter plot. mapping can be used to rename the metrics in the table. by default False\nNone\n\n\nax\nmatplotlib axes\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to matplotlib.pyplot.scatter()\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.scatter()\n&gt;&gt;&gt; cc.plot.scatter(bins=0.2, backend='plotly')\n&gt;&gt;&gt; cc.plot.scatter(show_points=False, title='no points')\n&gt;&gt;&gt; cc.plot.scatter(xlabel='all observations', ylabel='my model')\n&gt;&gt;&gt; cc.sel(model='HKZN_v2').plot.scatter(figsize=(10, 10))\n&gt;&gt;&gt; cc.sel(observations=['c2','HKNA']).plot.scatter()\n\n\n\n\ncomparison.ComparerCollectionPlotter.spatial_overview(\n    ax=None,\n    figsize=None,\n    title=None,\n)\nPlot observation points on a map showing the model domain\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\n(float, float)\nfigure size, by default None\nNone\n\n\ntitle\nOptional[str]\nplot title, default empty\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\nThe matplotlib axes object\n\n\n\n\n\n\n\ncomparison.ComparerCollectionPlotter.taylor(\n    normalize_std=False,\n    aggregate_observations=True,\n    figsize=(7, 7),\n    marker='o',\n    marker_size=6.0,\n    title='Taylor diagram',\n)\nTaylor diagram for model skill comparison.\nTaylor diagram showing model std and correlation to observation in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnormalize_std\nbool\nplot model std normalized with observation std, default False\nFalse\n\n\naggregate_observations\nbool\nshould multiple observations be aggregated before plotting (or shown individually), default True\nTrue\n\n\nfigsize\ntuple\nwidth and height of the figure (should be square), by default (7, 7)\n(7, 7)\n\n\nmarker\nstr\nmarker type e.g. “x”, “*“, by default”o”\n'o'\n\n\nmarker_size\nfloat\nsize of the marker, by default 6\n6.0\n\n\ntitle\nstr\ntitle of the plot, by default “Taylor diagram”\n'Taylor diagram'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.figure.Figure\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.taylor()\n&gt;&gt;&gt; cc.sel(observation=\"c2\").plot.taylor()\n&gt;&gt;&gt; cc.plot.taylor(start=\"2017-10-28\", figsize=(5,5))\n\n\n\nCopin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin yannick.copin@laposte.net\n\n\n\n\ncomparison.ComparerCollectionPlotter.temporal_coverage(\n    limit_to_model_period=True,\n    marker='_',\n    ax=None,\n    figsize=None,\n    title=None,\n)\nPlot graph showing temporal coverage for all observations and models\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlimit_to_model_period\nbool\nShow temporal coverage only for period covered by the model, by default True\nTrue\n\n\nmarker\nstr\nplot marker for observations, by default “_”\n'_'\n\n\nax\nAny | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\nTuple(float, float)\nsize of figure, by default (7, 0.45*n_lines)\nNone\n\n\ntitle\nAny | None\nplot title, default empty\nNone",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollectionPlotter"
    ]
  },
  {
    "objectID": "api/comparison.ComparerCollectionPlotter.html#examples",
    "href": "api/comparison.ComparerCollectionPlotter.html#examples",
    "title": "comparison.ComparerCollectionPlotter",
    "section": "",
    "text": "&gt;&gt;&gt; cc.plot.scatter()\n&gt;&gt;&gt; cc.plot.hist()\n&gt;&gt;&gt; cc.plot.kde()\n&gt;&gt;&gt; cc.plot.taylor()\n&gt;&gt;&gt; cc.plot.box()",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollectionPlotter"
    ]
  },
  {
    "objectID": "api/comparison.ComparerCollectionPlotter.html#methods",
    "href": "api/comparison.ComparerCollectionPlotter.html#methods",
    "title": "comparison.ComparerCollectionPlotter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbox\nPlot box plot of observations and model data.\n\n\nhist\nPlot histogram of specific model and all observations.\n\n\nkde\nPlot kernel density estimate of observation and model data.\n\n\nqq\nMake quantile-quantile (q-q) plot of model data and observations.\n\n\nresidual_hist\nplot histogram of residual values\n\n\nscatter\nScatter plot tailored for comparing model output with observations.\n\n\nspatial_overview\nPlot observation points on a map showing the model domain\n\n\ntaylor\nTaylor diagram for model skill comparison.\n\n\ntemporal_coverage\nPlot graph showing temporal coverage for all observations and models\n\n\n\n\n\ncomparison.ComparerCollectionPlotter.box(\n    ax=None,\n    figsize=None,\n    title=None,\n    **kwargs,\n)\nPlot box plot of observations and model data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nAxes\nmatplotlib axes, by default None\nNone\n\n\nfigsize\ntuple\nwidth and height of the figure, by default None\nNone\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\n**kwargs\n\npassed to pandas.DataFrame.plot.box()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxes\nmatplotlib axes\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.box()\n&gt;&gt;&gt; cc.plot.box(showmeans=True)\n&gt;&gt;&gt; cc.plot.box(ax=ax, title=\"Box plot\")\n\n\n\n\ncomparison.ComparerCollectionPlotter.hist(\n    bins=100,\n    *,\n    model=None,\n    title=None,\n    density=True,\n    alpha=0.5,\n    ax=None,\n    figsize=None,\n    **kwargs,\n)\nPlot histogram of specific model and all observations.\nWraps pandas.DataFrame hist() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\nnumber of bins, by default 100\n100\n\n\ntitle\nstr\nplot title, default: observation name\nNone\n\n\ndensity\nbool\nIf True, draw and return a probability density, by default True\nTrue\n\n\nalpha\nfloat\nalpha transparency fraction, by default 0.5\n0.5\n\n\nax\nmatplotlib axes\naxes to plot on, by default None\nNone\n\n\nfigsize\ntuple\nwidth and height of the figure, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to df.hist()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.hist()\n&gt;&gt;&gt; cc.plot.hist(bins=100)\n\n\n\npandas.Series.hist matplotlib.axes.Axes.hist\n\n\n\n\ncomparison.ComparerCollectionPlotter.kde(\n    ax=None,\n    figsize=None,\n    title=None,\n    **kwargs,\n)\nPlot kernel density estimate of observation and model data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nAxes\nmatplotlib axes, by default None\nNone\n\n\nfigsize\ntuple\nwidth and height of the figure, by default None\nNone\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\n**kwargs\n\npassed to pandas.DataFrame.plot.kde()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxes\nmatplotlib axes\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.kde()\n&gt;&gt;&gt; cc.plot.kde(bw_method=0.5)\n&gt;&gt;&gt; cc.plot.kde(bw_method='silverman')\n\n\n\n\ncomparison.ComparerCollectionPlotter.qq(\n    quantiles=None,\n    *,\n    title=None,\n    ax=None,\n    figsize=None,\n    **kwargs,\n)\nMake quantile-quantile (q-q) plot of model data and observations.\nPrimarily used to compare multiple models.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\ntitle\nstr\nplot title, default: “Q-Q plot for [observation name]”\nNone\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.plot()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.qq()\n\n\n\n\ncomparison.ComparerCollectionPlotter.residual_hist(\n    bins=100,\n    title=None,\n    color=None,\n    figsize=None,\n    ax=None,\n    **kwargs,\n)\nplot histogram of residual values\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\nspecification of bins, by default 100\n100\n\n\ntitle\nstr\nplot title, default: Residuals, [name]\nNone\n\n\ncolor\nstr\nresidual color, by default “#8B8D8E”\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\nax\nAxes | list[Axes]\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.hist()\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxes | list[Axes]\n\n\n\n\n\n\n\n\ncomparison.ComparerCollectionPlotter.scatter(\n    bins=120,\n    quantiles=None,\n    fit_to_quantiles=False,\n    show_points=None,\n    show_hist=None,\n    show_density=None,\n    norm=None,\n    backend='matplotlib',\n    figsize=(8, 8),\n    xlim=None,\n    ylim=None,\n    reg_method='ols',\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    skill_table=None,\n    ax=None,\n    **kwargs,\n)\nScatter plot tailored for comparing model output with observations.\nOptionally, with density histogram.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint | float\nbins for the 2D histogram on the background. By default 120 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges\n120\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000); if int, this is the number of points; if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\nfit_to_quantiles\nbool\nby default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution, by default False\nFalse\n\n\nshow_points\n(bool, int, float)\nShould the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. e.g. 0.5 shows 50% of the points. int: if ‘n’ (int) given, then ‘n’ points will be displayed, randomly selected\nNone\n\n\nshow_hist\nbool\nshow the data density as a a 2d histogram, by default None\nNone\n\n\nshow_density\nOptional[bool]\nshow the data density as a colormap of the scatter, by default None. If both show_density and show_hist are None, then show_density is used by default. If number of points is less than 200, then show_density is False as default. For binning the data, the kword bins=Float is used.\nNone\n\n\nnorm\nmatplotlib.colors norm\ncolormap normalization. If None, defaults to matplotlib.colors.PowerNorm(vmin=1, gamma=0.5)\nNone\n\n\nbackend\nstr\nuse “plotly” (interactive) or “matplotlib” backend, by default “matplotlib”\n'matplotlib'\n\n\nfigsize\ntuple\nwidth and height of the figure, by default (8, 8)\n(8, 8)\n\n\nxlim\ntuple\nplot range for the observation (xmin, xmax), by default None\nNone\n\n\nylim\ntuple\nplot range for the model (ymin, ymax), by default None\nNone\n\n\nreg_method\nstr or bool\nmethod for determining the regression line “ols” : ordinary least squares regression “odr” : orthogonal distance regression, False : no regression line, by default “ols”\n'ols'\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\nxlabel\nstr\nx-label text on plot, by default None\nNone\n\n\nylabel\nstr\ny-label text on plot, by default None\nNone\n\n\nskill_table\nOptional[Union[str, List[str], Mapping[str, str], bool]]\nlist of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list. This kword adds a box at the right of the scatter plot. mapping can be used to rename the metrics in the table. by default False\nNone\n\n\nax\nmatplotlib axes\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to matplotlib.pyplot.scatter()\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.scatter()\n&gt;&gt;&gt; cc.plot.scatter(bins=0.2, backend='plotly')\n&gt;&gt;&gt; cc.plot.scatter(show_points=False, title='no points')\n&gt;&gt;&gt; cc.plot.scatter(xlabel='all observations', ylabel='my model')\n&gt;&gt;&gt; cc.sel(model='HKZN_v2').plot.scatter(figsize=(10, 10))\n&gt;&gt;&gt; cc.sel(observations=['c2','HKNA']).plot.scatter()\n\n\n\n\ncomparison.ComparerCollectionPlotter.spatial_overview(\n    ax=None,\n    figsize=None,\n    title=None,\n)\nPlot observation points on a map showing the model domain\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\n(float, float)\nfigure size, by default None\nNone\n\n\ntitle\nOptional[str]\nplot title, default empty\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\nThe matplotlib axes object\n\n\n\n\n\n\n\ncomparison.ComparerCollectionPlotter.taylor(\n    normalize_std=False,\n    aggregate_observations=True,\n    figsize=(7, 7),\n    marker='o',\n    marker_size=6.0,\n    title='Taylor diagram',\n)\nTaylor diagram for model skill comparison.\nTaylor diagram showing model std and correlation to observation in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnormalize_std\nbool\nplot model std normalized with observation std, default False\nFalse\n\n\naggregate_observations\nbool\nshould multiple observations be aggregated before plotting (or shown individually), default True\nTrue\n\n\nfigsize\ntuple\nwidth and height of the figure (should be square), by default (7, 7)\n(7, 7)\n\n\nmarker\nstr\nmarker type e.g. “x”, “*“, by default”o”\n'o'\n\n\nmarker_size\nfloat\nsize of the marker, by default 6\n6.0\n\n\ntitle\nstr\ntitle of the plot, by default “Taylor diagram”\n'Taylor diagram'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.figure.Figure\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc.plot.taylor()\n&gt;&gt;&gt; cc.sel(observation=\"c2\").plot.taylor()\n&gt;&gt;&gt; cc.plot.taylor(start=\"2017-10-28\", figsize=(5,5))\n\n\n\nCopin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin yannick.copin@laposte.net\n\n\n\n\ncomparison.ComparerCollectionPlotter.temporal_coverage(\n    limit_to_model_period=True,\n    marker='_',\n    ax=None,\n    figsize=None,\n    title=None,\n)\nPlot graph showing temporal coverage for all observations and models\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlimit_to_model_period\nbool\nShow temporal coverage only for period covered by the model, by default True\nTrue\n\n\nmarker\nstr\nplot marker for observations, by default “_”\n'_'\n\n\nax\nAny | None\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\nTuple(float, float)\nsize of figure, by default (7, 0.45*n_lines)\nNone\n\n\ntitle\nAny | None\nplot title, default empty\nNone",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollectionPlotter"
    ]
  },
  {
    "objectID": "api/plotting.scatter.html",
    "href": "api/plotting.scatter.html",
    "title": "plotting.scatter",
    "section": "",
    "text": "plotting.scatter(\n    x,\n    y,\n    *,\n    bins=120,\n    quantiles=None,\n    fit_to_quantiles=False,\n    show_points=None,\n    show_hist=None,\n    show_density=None,\n    norm=None,\n    backend='matplotlib',\n    figsize=(8, 8),\n    xlim=None,\n    ylim=None,\n    reg_method='ols',\n    title='',\n    xlabel='',\n    ylabel='',\n    skill_table=False,\n    skill_scores=None,\n    skill_score_unit='',\n    ax=None,\n    **kwargs,\n)\nScatter plot tailored for model skill comparison.\nScatter plot showing compared data: observation vs modelled Optionally, with density histogram or denisty color coding of points.\nNote: can be called directly but is often called through the plot accessor on a Comparer/CompararCollection cmp.plot.scatter()",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.scatter"
    ]
  },
  {
    "objectID": "api/plotting.scatter.html#parameters",
    "href": "api/plotting.scatter.html#parameters",
    "title": "plotting.scatter",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX values e.g model values, must be same length as y\nrequired\n\n\ny\nnp.ndarray\nY values e.g observation values, must be same length as x\nrequired\n\n\nbins\nint | float\nbins for the 2D histogram on the background. By default 120 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges\n120\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\nfit_to_quantiles\nbool\nby default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution, by default False\nFalse\n\n\nshow_points\n(bool, int, float)\nShould the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. eg 0.5 shows 50% of the points. int: if ‘n’ (int) given, then ‘n’ points will be displayed, randomly selected.\nNone\n\n\nshow_hist\nbool\nshow the data density as a 2d histogram, by default None\nNone\n\n\nshow_density\nOptional[bool]\nshow the data density as a colormap of the scatter, by default None. If both show_density and show_hist are None, then show_density is used by default. If number of points is less than 200, then show_density is False by default. For binning the data, the previous kword bins=Float is used\nNone\n\n\nnorm\nmatplotlib.colors.Normalize\ncolormap normalization If None, defaults to matplotlib.colors.PowerNorm(vmin=1,gamma=0.5)\nNone\n\n\nbackend\nstr\nuse “plotly” (interactive) or “matplotlib” backend, by default “matplotlib”\n'matplotlib'\n\n\nfigsize\ntuple\nwidth and height of the figure, by default (8, 8)\n(8, 8)\n\n\nxlim\ntuple\nplot range for the observation (xmin, xmax), by default None\nNone\n\n\nylim\ntuple\nplot range for the model (ymin, ymax), by default None\nNone\n\n\nreg_method\nstr or bool\nmethod for determining the regression line “ols” : ordinary least squares regression “odr” : orthogonal distance regression, False : no regression line by default “ols”\n'ols'\n\n\ntitle\nstr\nplot title, by default None\n''\n\n\nxlabel\nstr\nx-label text on plot, by default None\n''\n\n\nylabel\nstr\ny-label text on plot, by default None\n''\n\n\nskill_table\nOptional[str | Sequence[str] | Mapping[str, str] | bool]\ncalculate skill scores and show in box next to the plot, True will show default metrics, list of metrics will show these skill scores, by default False, mapping can be used to rename the metrics in the table. Note: cannot be used together with skill_scores argument\nFalse\n\n\nskill_scores\ndict[str, float]\ndictionary with skill scores to be shown in box next to the plot, by default None Note: cannot be used together with skill_table argument\nNone\n\n\nskill_score_unit\nstr\nunit for skill_scores, by default None\n''\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\n\n{}",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.scatter"
    ]
  },
  {
    "objectID": "api/plotting.scatter.html#returns",
    "href": "api/plotting.scatter.html#returns",
    "title": "plotting.scatter",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\nThe axes on which the scatter plot was drawn.",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.scatter"
    ]
  },
  {
    "objectID": "api/plotting.scatter.html#examples",
    "href": "api/plotting.scatter.html#examples",
    "title": "plotting.scatter",
    "section": "Examples",
    "text": "Examples\n\nimport numpy as np\nimport modelskill as ms\n\nx = np.linspace(0, 10, 1000)\ny = x + np.random.normal(size=1000)\n\nms.plotting.scatter(x, y, skill_table=True)\n\n\n\n\n\n\n\n\n\nms.plotting.scatter(x, y, show_hist=True, bins=20, cmap=\"OrRd\")\n\n\n\n\n\n\n\n\n\nms.plotting.scatter(x, y, quantiles=0, title=\"Hide quantiles\")\n\n\n\n\n\n\n\n\n\nms.plotting.scatter(x, y, xlim=(0,4), ylim=(0,4), show_density=False)",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.scatter"
    ]
  },
  {
    "objectID": "api/DummyModelResult.html",
    "href": "api/DummyModelResult.html",
    "title": "DummyModelResult",
    "section": "",
    "text": "DummyModelResult(self, name='dummy', data=None, strategy='constant')\nDummy model result that always returns the same value.\nSimilar in spirit to https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nfloat\nThe value to return if strategy is ‘constant’, by default None\nNone\n\n\nname\nstr\nThe name of the model result, by default ‘dummy’\n'dummy'\n\n\nstrategy\nstr\nThe strategy to use, ‘mean’ uses the mean of the observation, ‘constant’ uses the value given in data, by default ‘constant’\n'constant'\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; df = pd.DataFrame([0.0, 1.0], index=pd.date_range(\"2000\", freq=\"H\", periods=2))\n&gt;&gt;&gt; obs = ms.PointObservation(df, name=\"foo\")\n&gt;&gt;&gt; mr = ms.DummyModelResult(strategy='mean')\n&gt;&gt;&gt; pmr = mr.extract(obs)\n&gt;&gt;&gt; pmr.to_dataframe()\n                    dummy\ntime\n2000-01-01 00:00:00    0.5\n2000-01-01 01:00:00    0.5",
    "crumbs": [
      "API Reference",
      "Model Result",
      "DummyModelResult"
    ]
  },
  {
    "objectID": "api/DummyModelResult.html#parameters",
    "href": "api/DummyModelResult.html#parameters",
    "title": "DummyModelResult",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\nfloat\nThe value to return if strategy is ‘constant’, by default None\nNone\n\n\nname\nstr\nThe name of the model result, by default ‘dummy’\n'dummy'\n\n\nstrategy\nstr\nThe strategy to use, ‘mean’ uses the mean of the observation, ‘constant’ uses the value given in data, by default ‘constant’\n'constant'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "DummyModelResult"
    ]
  },
  {
    "objectID": "api/DummyModelResult.html#examples",
    "href": "api/DummyModelResult.html#examples",
    "title": "DummyModelResult",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; df = pd.DataFrame([0.0, 1.0], index=pd.date_range(\"2000\", freq=\"H\", periods=2))\n&gt;&gt;&gt; obs = ms.PointObservation(df, name=\"foo\")\n&gt;&gt;&gt; mr = ms.DummyModelResult(strategy='mean')\n&gt;&gt;&gt; pmr = mr.extract(obs)\n&gt;&gt;&gt; pmr.to_dataframe()\n                    dummy\ntime\n2000-01-01 00:00:00    0.5\n2000-01-01 01:00:00    0.5",
    "crumbs": [
      "API Reference",
      "Model Result",
      "DummyModelResult"
    ]
  },
  {
    "objectID": "api/DfsuModelResult.html",
    "href": "api/DfsuModelResult.html",
    "title": "DfsuModelResult",
    "section": "",
    "text": "DfsuModelResult(\n    self,\n    data,\n    *,\n    name=None,\n    item=None,\n    quantity=None,\n    aux_items=None,\n)\nConstruct a DfsuModelResult from a dfsu file or mikeio.Dataset/DataArray.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\ntypes.UnstructuredType\nthe input data or file path\nrequired\n\n\nname\nOptional[str]\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nitem\nstr | int | None\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nextract\nExtract ModelResult at observation positions\n\n\n\n\n\nDfsuModelResult.extract(observation, spatial_method=None)\nExtract ModelResult at observation positions\nNote: this method is typically not called directly, but by the match() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobservation\n or \npositions (and times) at which modelresult should be extracted\nrequired\n\n\nspatial_method\nOptional[str]\nspatial selection/interpolation method, ‘contained’ (=isel), ‘nearest’, ‘inverse_distance’ (with 5 nearest points), by default None = ‘inverse_distance’\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPointModelResult or TrackModelResult\nextracted modelresult with the same geometry as the observation",
    "crumbs": [
      "API Reference",
      "Model Result",
      "DfsuModelResult"
    ]
  },
  {
    "objectID": "api/DfsuModelResult.html#parameters",
    "href": "api/DfsuModelResult.html#parameters",
    "title": "DfsuModelResult",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\ntypes.UnstructuredType\nthe input data or file path\nrequired\n\n\nname\nOptional[str]\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nitem\nstr | int | None\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone",
    "crumbs": [
      "API Reference",
      "Model Result",
      "DfsuModelResult"
    ]
  },
  {
    "objectID": "api/DfsuModelResult.html#methods",
    "href": "api/DfsuModelResult.html#methods",
    "title": "DfsuModelResult",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nextract\nExtract ModelResult at observation positions\n\n\n\n\n\nDfsuModelResult.extract(observation, spatial_method=None)\nExtract ModelResult at observation positions\nNote: this method is typically not called directly, but by the match() method.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobservation\n or \npositions (and times) at which modelresult should be extracted\nrequired\n\n\nspatial_method\nOptional[str]\nspatial selection/interpolation method, ‘contained’ (=isel), ‘nearest’, ‘inverse_distance’ (with 5 nearest points), by default None = ‘inverse_distance’\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPointModelResult or TrackModelResult\nextracted modelresult with the same geometry as the observation",
    "crumbs": [
      "API Reference",
      "Model Result",
      "DfsuModelResult"
    ]
  },
  {
    "objectID": "api/plotting.html",
    "href": "api/plotting.html",
    "title": "plotting",
    "section": "",
    "text": "plotting\nplotting\nPlotting functions independent of the comparison module.\n\nscatter is a function that can be used to plot a scatter suitable for skill assessment, with a 1:1 line and a linear regression line.\nwind_rose is a function that can be used to plot a dual wind rose to compare two datasets of magnitudes and directions.\nspatial_overview is a function that can be used to plot a spatial overview of two datasets.\ntemporal_coverage is a function that can be used to plot the temporal coverage of two datasets.",
    "crumbs": [
      "API Reference",
      "Plotting"
    ]
  },
  {
    "objectID": "api/PointModelResult.html",
    "href": "api/PointModelResult.html",
    "title": "PointModelResult",
    "section": "",
    "text": "PointModelResult(\n    self,\n    data,\n    *,\n    name=None,\n    x=None,\n    y=None,\n    z=None,\n    item=None,\n    quantity=None,\n    aux_items=None,\n)\nModel result for a single point location.\nConstruct a PointModelResult from a 0d data source: dfs0 file, mikeio.Dataset/DataArray, pandas.DataFrame/Series or xarray.Dataset/DataArray\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n(str, Path, mikeio.Dataset, mikeio.DataArray, pd.DataFrame, pd.Series, xr.Dataset or xr.DataArray)\nfilename (.dfs0 or .nc) or object with the data\nrequired\n\n\nname\nOptional[str]\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nx\nfloat\nfirst coordinate of point position, inferred from data if not given, else None\nNone\n\n\ny\nfloat\nsecond coordinate of point position, inferred from data if not given, else None\nNone\n\n\nz\nfloat\nthird coordinate of point position, inferred from data if not given, else None\nNone\n\n\nitem\nstr | int | None\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\ninterp_time\nInterpolate model result to the time of the observation\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nPointModelResult.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nPointModelResult.interp_time(observation, **kwargs)\nInterpolate model result to the time of the observation\nwrapper around xarray.Dataset.interp()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobservation\nObservation\nThe observation to interpolate to\nrequired\n\n\n**kwargs\nAny\nAdditional keyword arguments passed to xarray.interp\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPointModelResult\nInterpolated model result\n\n\n\n\n\n\n\nPointModelResult.sel(**kwargs)\nSelect data by label\n\n\n\nPointModelResult.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nPointModelResult.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "PointModelResult"
    ]
  },
  {
    "objectID": "api/PointModelResult.html#parameters",
    "href": "api/PointModelResult.html#parameters",
    "title": "PointModelResult",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\n(str, Path, mikeio.Dataset, mikeio.DataArray, pd.DataFrame, pd.Series, xr.Dataset or xr.DataArray)\nfilename (.dfs0 or .nc) or object with the data\nrequired\n\n\nname\nOptional[str]\nThe name of the model result, by default None (will be set to file name or item name)\nNone\n\n\nx\nfloat\nfirst coordinate of point position, inferred from data if not given, else None\nNone\n\n\ny\nfloat\nsecond coordinate of point position, inferred from data if not given, else None\nNone\n\n\nz\nfloat\nthird coordinate of point position, inferred from data if not given, else None\nNone\n\n\nitem\nstr | int | None\nIf multiple items/arrays are present in the input an item must be given (as either an index or a string), by default None\nNone\n\n\nquantity\nQuantity\nModel quantity, for MIKE files this is inferred from the EUM information\nNone\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone",
    "crumbs": [
      "API Reference",
      "Model Result",
      "PointModelResult"
    ]
  },
  {
    "objectID": "api/PointModelResult.html#attributes",
    "href": "api/PointModelResult.html#attributes",
    "title": "PointModelResult",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate",
    "crumbs": [
      "API Reference",
      "Model Result",
      "PointModelResult"
    ]
  },
  {
    "objectID": "api/PointModelResult.html#methods",
    "href": "api/PointModelResult.html#methods",
    "title": "PointModelResult",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\ninterp_time\nInterpolate model result to the time of the observation\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nPointModelResult.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nPointModelResult.interp_time(observation, **kwargs)\nInterpolate model result to the time of the observation\nwrapper around xarray.Dataset.interp()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobservation\nObservation\nThe observation to interpolate to\nrequired\n\n\n**kwargs\nAny\nAdditional keyword arguments passed to xarray.interp\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPointModelResult\nInterpolated model result\n\n\n\n\n\n\n\nPointModelResult.sel(**kwargs)\nSelect data by label\n\n\n\nPointModelResult.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nPointModelResult.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "PointModelResult"
    ]
  },
  {
    "objectID": "api/plotting.temporal_coverage.html",
    "href": "api/plotting.temporal_coverage.html",
    "title": "plotting.temporal_coverage",
    "section": "",
    "text": "plotting.temporal_coverage(\n    obs=None,\n    mod=None,\n    *,\n    limit_to_model_period=True,\n    marker='_',\n    ax=None,\n    figsize=None,\n    title=None,\n)\nPlot graph showing temporal coverage for all observations and models",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.temporal_coverage"
    ]
  },
  {
    "objectID": "api/plotting.temporal_coverage.html#parameters",
    "href": "api/plotting.temporal_coverage.html#parameters",
    "title": "plotting.temporal_coverage",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nList[Observation]\nShow observation(s) as separate lines on plot\nNone\n\n\nmod\nList[ModelResult]\nShow model(s) as separate lines on plot, by default None\nNone\n\n\nlimit_to_model_period\nbool\nShow temporal coverage only for period covered by the model, by default True\nTrue\n\n\nmarker\nstr\nplot marker for observations, by default “_”\n'_'\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\nTuple(float, float)\nsize of figure, by default (7, 0.45*n_lines)\nNone\n\n\ntitle\n\nplot title, default empty\nNone",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.temporal_coverage"
    ]
  },
  {
    "objectID": "api/plotting.temporal_coverage.html#see-also",
    "href": "api/plotting.temporal_coverage.html#see-also",
    "title": "plotting.temporal_coverage",
    "section": "See Also",
    "text": "See Also\nspatial_overview",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.temporal_coverage"
    ]
  },
  {
    "objectID": "api/plotting.temporal_coverage.html#returns",
    "href": "api/plotting.temporal_coverage.html#returns",
    "title": "plotting.temporal_coverage",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\nThe matplotlib axes object",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.temporal_coverage"
    ]
  },
  {
    "objectID": "api/plotting.temporal_coverage.html#examples",
    "href": "api/plotting.temporal_coverage.html#examples",
    "title": "plotting.temporal_coverage",
    "section": "Examples",
    "text": "Examples\n\nimport modelskill as ms\nfrom pathlib import Path\np = Path(\"../data/SW\")\no1 = ms.PointObservation(p/'HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\no2 = ms.TrackObservation(p/\"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\nmr1 = ms.DfsuModelResult(p/'HKZN_local_2017_DutchCoast.dfsu', name='SW_1', item=0)\nmr2 = ms.DfsuModelResult(p/'HKZN_local_2017_DutchCoast_v2.dfsu', name='SW_2', item=0)\nms.plotting.temporal_coverage([o1, o2], [mr1, mr2])\n\n\n\n\n\n\n\n\n\nms.plotting.temporal_coverage([o1, o2], mr2, limit_to_model_period=False)\n\n\n\n\n\n\n\n\n\nms.plotting.temporal_coverage(o2, [mr1, mr2], marker=\".\")\n\n\n\n\n\n\n\n\n\nms.plotting.temporal_coverage(mod=[mr1, mr2], figsize=(5,3))",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.temporal_coverage"
    ]
  },
  {
    "objectID": "api/from_matched.html",
    "href": "api/from_matched.html",
    "title": "from_matched",
    "section": "",
    "text": "from_matched(\n    data,\n    *,\n    obs_item=0,\n    mod_items=None,\n    aux_items=None,\n    quantity=None,\n    name=None,\n    weight=1.0,\n    x=None,\n    y=None,\n    z=None,\n    x_item=None,\n    y_item=None,\n)\nCreate a Comparer from data that is already matched (aligned).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n[pd.DataFrame, str, Path, mikeio.Dfs0, mikeio.Dataset]\nDataFrame (or object that can be converted to a DataFrame e.g. dfs0) with columns obs_item, mod_items, aux_items\nrequired\n\n\nobs_item\n[str, int]\nName or index of observation item, by default first item\n0\n\n\nmod_items\nIterable[str, int]\nNames or indicies of model items, if None all remaining columns are model items, by default None\nNone\n\n\naux_items\nIterable[str, int]\nNames or indicies of auxiliary items, by default None\nNone\n\n\nquantity\nQuantity\nQuantity of the observation and model results, by default Quantity(name=“Undefined”, unit=“Undefined”)\nNone\n\n\nname\nstr\nName of the comparer, by default None (will be set to obs_item)\nNone\n\n\nx\nfloat\nx-coordinate of observation, by default None\nNone\n\n\ny\nfloat\ny-coordinate of observation, by default None\nNone\n\n\nz\nfloat\nz-coordinate of observation, by default None\nNone\n\n\nx_item\nstr | int | None\nName of x item, only relevant for track data\nNone\n\n\ny_item\nstr | int | None\nName of y item, only relevant for track data\nNone\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1]}, index=pd.date_range('2010-01-01', periods=3))\n&gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a') # remaining columns are model results\n&gt;&gt;&gt; cmp\n&lt;Comparer&gt;\nQuantity: Undefined [Undefined]\nObservation: stn_a, n_points=3\n Model: local, rmse=0.100\n&gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1], 'global': [1.2,2.2,3.2], 'nonsense':[1,2,3]}, index=pd.date_range('2010-01-01', periods=3))\n&gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a', mod_items=['local', 'global'])\n&gt;&gt;&gt; cmp\n&lt;Comparer&gt;\nQuantity: Undefined [Undefined]\nObservation: stn_a, n_points=3\n    Model: local, rmse=0.100\n    Model: global, rmse=0.200",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_matched"
    ]
  },
  {
    "objectID": "api/from_matched.html#parameters",
    "href": "api/from_matched.html#parameters",
    "title": "from_matched",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\n[pd.DataFrame, str, Path, mikeio.Dfs0, mikeio.Dataset]\nDataFrame (or object that can be converted to a DataFrame e.g. dfs0) with columns obs_item, mod_items, aux_items\nrequired\n\n\nobs_item\n[str, int]\nName or index of observation item, by default first item\n0\n\n\nmod_items\nIterable[str, int]\nNames or indicies of model items, if None all remaining columns are model items, by default None\nNone\n\n\naux_items\nIterable[str, int]\nNames or indicies of auxiliary items, by default None\nNone\n\n\nquantity\nQuantity\nQuantity of the observation and model results, by default Quantity(name=“Undefined”, unit=“Undefined”)\nNone\n\n\nname\nstr\nName of the comparer, by default None (will be set to obs_item)\nNone\n\n\nx\nfloat\nx-coordinate of observation, by default None\nNone\n\n\ny\nfloat\ny-coordinate of observation, by default None\nNone\n\n\nz\nfloat\nz-coordinate of observation, by default None\nNone\n\n\nx_item\nstr | int | None\nName of x item, only relevant for track data\nNone\n\n\ny_item\nstr | int | None\nName of y item, only relevant for track data\nNone",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_matched"
    ]
  },
  {
    "objectID": "api/from_matched.html#examples",
    "href": "api/from_matched.html#examples",
    "title": "from_matched",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1]}, index=pd.date_range('2010-01-01', periods=3))\n&gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a') # remaining columns are model results\n&gt;&gt;&gt; cmp\n&lt;Comparer&gt;\nQuantity: Undefined [Undefined]\nObservation: stn_a, n_points=3\n Model: local, rmse=0.100\n&gt;&gt;&gt; df = pd.DataFrame({'stn_a': [1,2,3], 'local': [1.1,2.1,3.1], 'global': [1.2,2.2,3.2], 'nonsense':[1,2,3]}, index=pd.date_range('2010-01-01', periods=3))\n&gt;&gt;&gt; cmp = ms.from_matched(df, obs_item='stn_a', mod_items=['local', 'global'])\n&gt;&gt;&gt; cmp\n&lt;Comparer&gt;\nQuantity: Undefined [Undefined]\nObservation: stn_a, n_points=3\n    Model: local, rmse=0.100\n    Model: global, rmse=0.200",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_matched"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API Reference",
    "section": "",
    "text": "Obtain a comparer object in one of the following ways:\n\nFrom matched data with from_matched()\nAfter defining observations and model results using the match() function.\nFrom a config file with from_config()\n\nDo analysis and plotting with the returned Comparer (a single observation) or ComparerCollection (multiple observations):\n\nskill() - returns a SkillTable with the skill scores\nplot using the various plot methods of the comparer objects\n\nplot.scatter()\nplot.timeseries()\nplot.kde()\nplot.qq()\nplot.hist()",
    "crumbs": [
      "API Reference"
    ]
  },
  {
    "objectID": "api/TrackObservation.html",
    "href": "api/TrackObservation.html",
    "title": "TrackObservation",
    "section": "",
    "text": "TrackObservation(\n    self,\n    data,\n    *,\n    item=None,\n    name=None,\n    weight=1.0,\n    x_item=0,\n    y_item=1,\n    keep_duplicates='first',\n    quantity=None,\n    aux_items=None,\n    attrs=None,\n)\nClass for observation with locations moving in space, e.g. satellite altimetry\nThe data needs in addition to the datetime of each single observation point also, x and y coordinates.\nCreate TrackObservation from dfs0 or DataFrame\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n(str, Path, mikeio.Dataset, pd.DataFrame, xr.Dataset)\npath to dfs0 file or object with track data\nrequired\n\n\nitem\n(str, int)\nitem name or index of values, by default None if data contains more than one item, item must be given\nNone\n\n\nname\nstr\nuser-defined name for easy identification in plots etc, by default file basename\nNone\n\n\nx_item\n(str, int)\nitem name or index of x-coordinate, by default 0\n0\n\n\ny_item\n(str, int)\nitem name or index of y-coordinate, by default 1\n1\n\n\nkeep_duplicates\n(str, bool)\nstrategy for handling duplicate timestamps (xarray.Dataset.drop_duplicates): “first” to keep first occurrence, “last” to keep last occurrence, False to drop all duplicates, “offset” to add milliseconds to consecutive duplicates, by default “first”\n'first'\n\n\nquantity\nQuantity\nThe quantity of the observation, for validation with model results For MIKE dfs files this is inferred from the EUM information\nNone\n\n\naux_items\nlist\nlist of names or indices of auxiliary items, by default None\nNone\n\n\nattrs\ndict\nadditional attributes to be added to the data, by default None\nNone\n\n\nweight\nfloat\nweighting factor for skill scores, by default 1.0\n1.0\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=2, name=\"c2\")\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=\"wind_speed\", name=\"c2\")\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track_wl.dfs0\", item=\"wl\", x_item=\"lon\", y_item=\"lat\")\n&gt;&gt;&gt; df = pd.DataFrame(\n...         {\n...             \"t\": pd.date_range(\"2010-01-01\", freq=\"10s\", periods=n),\n...             \"x\": np.linspace(0, 10, n),\n...             \"y\": np.linspace(45000, 45100, n),\n...             \"swh\": [0.1, 0.3, 0.4, 0.5, 0.3],\n...         }\n... )\n&gt;&gt;&gt; df = df.set_index(\"t\")\n&gt;&gt;&gt; df\n                    x        y  swh\nt\n2010-01-01 00:00:00   0.0  45000.0  0.1\n2010-01-01 00:00:10   2.5  45025.0  0.3\n2010-01-01 00:00:20   5.0  45050.0  0.4\n2010-01-01 00:00:30   7.5  45075.0  0.5\n2010-01-01 00:00:40  10.0  45100.0  0.3\n&gt;&gt;&gt; t1 = TrackObservation(df, name=\"fake\")\n&gt;&gt;&gt; t1.n_points\n5\n&gt;&gt;&gt; t1.values\narray([0.1, 0.3, 0.4, 0.5, 0.3])\n&gt;&gt;&gt; t1.time\nDatetimeIndex(['2010-01-01 00:00:00', '2010-01-01 00:00:10',\n           '2010-01-01 00:00:20', '2010-01-01 00:00:30',\n           '2010-01-01 00:00:40'],\n          dtype='datetime64[ns]', name='t', freq=None)\n&gt;&gt;&gt; t1.x\narray([ 0. ,  2.5,  5. ,  7.5, 10. ])\n&gt;&gt;&gt; t1.y\narray([45000., 45025., 45050., 45075., 45100.])\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nattrs\nAttributes of the observation\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nweight\nWeighting factor for skill scores\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nTrackObservation.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nTrackObservation.sel(**kwargs)\nSelect data by label\n\n\n\nTrackObservation.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nTrackObservation.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Observations",
      "TrackObservation"
    ]
  },
  {
    "objectID": "api/TrackObservation.html#parameters",
    "href": "api/TrackObservation.html#parameters",
    "title": "TrackObservation",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\n(str, Path, mikeio.Dataset, pd.DataFrame, xr.Dataset)\npath to dfs0 file or object with track data\nrequired\n\n\nitem\n(str, int)\nitem name or index of values, by default None if data contains more than one item, item must be given\nNone\n\n\nname\nstr\nuser-defined name for easy identification in plots etc, by default file basename\nNone\n\n\nx_item\n(str, int)\nitem name or index of x-coordinate, by default 0\n0\n\n\ny_item\n(str, int)\nitem name or index of y-coordinate, by default 1\n1\n\n\nkeep_duplicates\n(str, bool)\nstrategy for handling duplicate timestamps (xarray.Dataset.drop_duplicates): “first” to keep first occurrence, “last” to keep last occurrence, False to drop all duplicates, “offset” to add milliseconds to consecutive duplicates, by default “first”\n'first'\n\n\nquantity\nQuantity\nThe quantity of the observation, for validation with model results For MIKE dfs files this is inferred from the EUM information\nNone\n\n\naux_items\nlist\nlist of names or indices of auxiliary items, by default None\nNone\n\n\nattrs\ndict\nadditional attributes to be added to the data, by default None\nNone\n\n\nweight\nfloat\nweighting factor for skill scores, by default 1.0\n1.0",
    "crumbs": [
      "API Reference",
      "Observations",
      "TrackObservation"
    ]
  },
  {
    "objectID": "api/TrackObservation.html#examples",
    "href": "api/TrackObservation.html#examples",
    "title": "TrackObservation",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=2, name=\"c2\")\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track.dfs0\", item=\"wind_speed\", name=\"c2\")\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"lon_after_lat.dfs0\", item=\"wl\", x_item=1, y_item=0)\n&gt;&gt;&gt; o1 = ms.TrackObservation(\"track_wl.dfs0\", item=\"wl\", x_item=\"lon\", y_item=\"lat\")\n&gt;&gt;&gt; df = pd.DataFrame(\n...         {\n...             \"t\": pd.date_range(\"2010-01-01\", freq=\"10s\", periods=n),\n...             \"x\": np.linspace(0, 10, n),\n...             \"y\": np.linspace(45000, 45100, n),\n...             \"swh\": [0.1, 0.3, 0.4, 0.5, 0.3],\n...         }\n... )\n&gt;&gt;&gt; df = df.set_index(\"t\")\n&gt;&gt;&gt; df\n                    x        y  swh\nt\n2010-01-01 00:00:00   0.0  45000.0  0.1\n2010-01-01 00:00:10   2.5  45025.0  0.3\n2010-01-01 00:00:20   5.0  45050.0  0.4\n2010-01-01 00:00:30   7.5  45075.0  0.5\n2010-01-01 00:00:40  10.0  45100.0  0.3\n&gt;&gt;&gt; t1 = TrackObservation(df, name=\"fake\")\n&gt;&gt;&gt; t1.n_points\n5\n&gt;&gt;&gt; t1.values\narray([0.1, 0.3, 0.4, 0.5, 0.3])\n&gt;&gt;&gt; t1.time\nDatetimeIndex(['2010-01-01 00:00:00', '2010-01-01 00:00:10',\n           '2010-01-01 00:00:20', '2010-01-01 00:00:30',\n           '2010-01-01 00:00:40'],\n          dtype='datetime64[ns]', name='t', freq=None)\n&gt;&gt;&gt; t1.x\narray([ 0. ,  2.5,  5. ,  7.5, 10. ])\n&gt;&gt;&gt; t1.y\narray([45000., 45025., 45050., 45075., 45100.])",
    "crumbs": [
      "API Reference",
      "Observations",
      "TrackObservation"
    ]
  },
  {
    "objectID": "api/TrackObservation.html#attributes",
    "href": "api/TrackObservation.html#attributes",
    "title": "TrackObservation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nattrs\nAttributes of the observation\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nweight\nWeighting factor for skill scores\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate",
    "crumbs": [
      "API Reference",
      "Observations",
      "TrackObservation"
    ]
  },
  {
    "objectID": "api/TrackObservation.html#methods",
    "href": "api/TrackObservation.html#methods",
    "title": "TrackObservation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nTrackObservation.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nTrackObservation.sel(**kwargs)\nSelect data by label\n\n\n\nTrackObservation.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nTrackObservation.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'",
    "crumbs": [
      "API Reference",
      "Observations",
      "TrackObservation"
    ]
  },
  {
    "objectID": "api/SkillTable.html",
    "href": "api/SkillTable.html",
    "title": "SkillTable",
    "section": "",
    "text": "SkillTable(self, data)\nVisualize skill metrics.\nSkillTable object for visualization and analysis returned by the comparer’s skill method. The object wraps the pd.DataFrame class which can be accessed from the attribute data.\nThe columns are assumed to be metrics and data for a single metric can be accessed by e.g. s.rmse or s[\"rmse\"]. The resulting object can be used for plotting.\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.mod_names\n['SW_1', 'SW_2']\n&gt;&gt;&gt; sk.style()\n&gt;&gt;&gt; sk.sel(model='SW_1').style()\n&gt;&gt;&gt; sk.rmse.plot.bar()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nmetrics\nList of metrics (columns) in the SkillTable\n\n\nmod_names\nList of model names (in index)\n\n\nobs_names\nList of observation names (in index)\n\n\nquantity_names\nList of quantity names (in index)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery\nSelect a subset of the SkillTable by a query string\n\n\nround\nRound all values in SkillTable\n\n\nsel\nFilter (select) specific models or observations.\n\n\nsort_index\nSort by index (level) e.g. sorting by observation\n\n\nsort_values\nSort by values e.g. sorting by rmse values\n\n\nstyle\nStyle SkillTable with colors using pandas style\n\n\nswaplevel\nSwap the levels of the MultiIndex e.g. swapping ‘model’ and ‘observation’\n\n\nto_dataframe\nConvert SkillTable to pd.DataFrame\n\n\nto_geodataframe\nConvert SkillTable to geopandas.GeoDataFrame\n\n\n\n\n\nSkillTable.query(query)\nSelect a subset of the SkillTable by a query string\nwrapping pd.DataFrame.query()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery\nstr\nstring supported by pd.DataFrame.query()\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA subset of the original SkillTable\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk_above_0p3 = sk.query(\"rmse&gt;0.3\")\n\n\n\n\nSkillTable.round(decimals=3)\nRound all values in SkillTable\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndecimals\nint\nNumber of decimal places to round to (default: 3). If decimals is negative, it specifies the number of positions to the left of the decimal point.\n3\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with rounded values\n\n\n\n\n\n\n\nSkillTable.sel(query=None, reduce_index=True, **kwargs)\nFilter (select) specific models or observations.\nSelect a subset of the SkillTable by a query, (part of) the index, or specific columns\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nreduce_index\nbool\nShould unnecessary levels of the index be removed after subsetting? Removed levels will stay as columns. By default True\nTrue\n\n\n**kwargs\nAny\nConcrete keys depend on the index names of the SkillTable (from the “by” argument in cc.skill() method) “model”=… to select specific models, “observation”=… to select specific observations\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA subset of the original SkillTable\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk_SW1 = sk.sel(model = \"SW_1\")\n&gt;&gt;&gt; sk2 = sk.sel(observation = [\"EPL\", \"HKNA\"])\n\n\n\n\nSkillTable.sort_index(*args, **kwargs)\nSort by index (level) e.g. sorting by observation\nWrapping pd.DataFrame.sort_index()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with sorted index\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.sort_index()\n&gt;&gt;&gt; sk.sort_index(level=\"observation\")\n\n\n\n\nSkillTable.sort_values(*args, **kwargs)\nSort by values e.g. sorting by rmse values\nWrapping pd.DataFrame.sort_values()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with sorted values\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.sort_values(\"rmse\")\n&gt;&gt;&gt; sk.sort_values(\"rmse\", ascending=False)\n&gt;&gt;&gt; sk.sort_values([\"n\", \"rmse\"])\n\n\n\n\nSkillTable.style(\n    decimals=3,\n    metrics=None,\n    cmap='OrRd',\n    show_best=True,\n    **kwargs,\n)\nStyle SkillTable with colors using pandas style\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndecimals\nint\nNumber of decimal places to round to (default: 3).\n3\n\n\nmetrics\nstr or List[str]\napply background gradient color to these columns, by default all; if columns is [] then no background gradient will be applied.\nNone\n\n\ncmap\nstr\ncolormap of background gradient, by default “OrRd”, except “bias” column which will always be “coolwarm”\n'OrRd'\n\n\nshow_best\nbool\nindicate best of each column by underline, by default True\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.Styler\nReturns a pandas Styler object.\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.style()\n&gt;&gt;&gt; sk.style(precision=1, metrics=\"rmse\")\n&gt;&gt;&gt; sk.style(cmap=\"Blues\", show_best=False)\n\n\n\n\nSkillTable.swaplevel(*args, **kwargs)\nSwap the levels of the MultiIndex e.g. swapping ‘model’ and ‘observation’\nWrapping pd.DataFrame.swaplevel()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with swapped levels\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.swaplevel().sort_index(level=\"observation\")\n&gt;&gt;&gt; sk.swaplevel(\"model\", \"observation\")\n&gt;&gt;&gt; sk.swaplevel(0, 1)\n\n\n\n\nSkillTable.to_dataframe(drop_xy=True)\nConvert SkillTable to pd.DataFrame\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndrop_xy\nbool\nDrop the x, y coordinates?, by default True\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nSkill data as pd.DataFrame\n\n\n\n\n\n\n\nSkillTable.to_geodataframe(crs='EPSG:4326')\nConvert SkillTable to geopandas.GeoDataFrame\nNote: requires geopandas to be installed\nNote: requires x and y columns to be present\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system identifier passed to the GeoDataFrame constructor, by default “EPSG:4326”\n'EPSG:4326'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ngpd.GeoDataFrame\nSkill data as GeoDataFrame",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillTable"
    ]
  },
  {
    "objectID": "api/SkillTable.html#examples",
    "href": "api/SkillTable.html#examples",
    "title": "SkillTable",
    "section": "",
    "text": "&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.mod_names\n['SW_1', 'SW_2']\n&gt;&gt;&gt; sk.style()\n&gt;&gt;&gt; sk.sel(model='SW_1').style()\n&gt;&gt;&gt; sk.rmse.plot.bar()",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillTable"
    ]
  },
  {
    "objectID": "api/SkillTable.html#attributes",
    "href": "api/SkillTable.html#attributes",
    "title": "SkillTable",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nmetrics\nList of metrics (columns) in the SkillTable\n\n\nmod_names\nList of model names (in index)\n\n\nobs_names\nList of observation names (in index)\n\n\nquantity_names\nList of quantity names (in index)",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillTable"
    ]
  },
  {
    "objectID": "api/SkillTable.html#methods",
    "href": "api/SkillTable.html#methods",
    "title": "SkillTable",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nquery\nSelect a subset of the SkillTable by a query string\n\n\nround\nRound all values in SkillTable\n\n\nsel\nFilter (select) specific models or observations.\n\n\nsort_index\nSort by index (level) e.g. sorting by observation\n\n\nsort_values\nSort by values e.g. sorting by rmse values\n\n\nstyle\nStyle SkillTable with colors using pandas style\n\n\nswaplevel\nSwap the levels of the MultiIndex e.g. swapping ‘model’ and ‘observation’\n\n\nto_dataframe\nConvert SkillTable to pd.DataFrame\n\n\nto_geodataframe\nConvert SkillTable to geopandas.GeoDataFrame\n\n\n\n\n\nSkillTable.query(query)\nSelect a subset of the SkillTable by a query string\nwrapping pd.DataFrame.query()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery\nstr\nstring supported by pd.DataFrame.query()\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA subset of the original SkillTable\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk_above_0p3 = sk.query(\"rmse&gt;0.3\")\n\n\n\n\nSkillTable.round(decimals=3)\nRound all values in SkillTable\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndecimals\nint\nNumber of decimal places to round to (default: 3). If decimals is negative, it specifies the number of positions to the left of the decimal point.\n3\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with rounded values\n\n\n\n\n\n\n\nSkillTable.sel(query=None, reduce_index=True, **kwargs)\nFilter (select) specific models or observations.\nSelect a subset of the SkillTable by a query, (part of) the index, or specific columns\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nreduce_index\nbool\nShould unnecessary levels of the index be removed after subsetting? Removed levels will stay as columns. By default True\nTrue\n\n\n**kwargs\nAny\nConcrete keys depend on the index names of the SkillTable (from the “by” argument in cc.skill() method) “model”=… to select specific models, “observation”=… to select specific observations\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA subset of the original SkillTable\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk_SW1 = sk.sel(model = \"SW_1\")\n&gt;&gt;&gt; sk2 = sk.sel(observation = [\"EPL\", \"HKNA\"])\n\n\n\n\nSkillTable.sort_index(*args, **kwargs)\nSort by index (level) e.g. sorting by observation\nWrapping pd.DataFrame.sort_index()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with sorted index\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.sort_index()\n&gt;&gt;&gt; sk.sort_index(level=\"observation\")\n\n\n\n\nSkillTable.sort_values(*args, **kwargs)\nSort by values e.g. sorting by rmse values\nWrapping pd.DataFrame.sort_values()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with sorted values\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.sort_values(\"rmse\")\n&gt;&gt;&gt; sk.sort_values(\"rmse\", ascending=False)\n&gt;&gt;&gt; sk.sort_values([\"n\", \"rmse\"])\n\n\n\n\nSkillTable.style(\n    decimals=3,\n    metrics=None,\n    cmap='OrRd',\n    show_best=True,\n    **kwargs,\n)\nStyle SkillTable with colors using pandas style\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndecimals\nint\nNumber of decimal places to round to (default: 3).\n3\n\n\nmetrics\nstr or List[str]\napply background gradient color to these columns, by default all; if columns is [] then no background gradient will be applied.\nNone\n\n\ncmap\nstr\ncolormap of background gradient, by default “OrRd”, except “bias” column which will always be “coolwarm”\n'OrRd'\n\n\nshow_best\nbool\nindicate best of each column by underline, by default True\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.Styler\nReturns a pandas Styler object.\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.style()\n&gt;&gt;&gt; sk.style(precision=1, metrics=\"rmse\")\n&gt;&gt;&gt; sk.style(cmap=\"Blues\", show_best=False)\n\n\n\n\nSkillTable.swaplevel(*args, **kwargs)\nSwap the levels of the MultiIndex e.g. swapping ‘model’ and ‘observation’\nWrapping pd.DataFrame.swaplevel()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nA new SkillTable with swapped levels\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()\n&gt;&gt;&gt; sk.swaplevel().sort_index(level=\"observation\")\n&gt;&gt;&gt; sk.swaplevel(\"model\", \"observation\")\n&gt;&gt;&gt; sk.swaplevel(0, 1)\n\n\n\n\nSkillTable.to_dataframe(drop_xy=True)\nConvert SkillTable to pd.DataFrame\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndrop_xy\nbool\nDrop the x, y coordinates?, by default True\nTrue\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nSkill data as pd.DataFrame\n\n\n\n\n\n\n\nSkillTable.to_geodataframe(crs='EPSG:4326')\nConvert SkillTable to geopandas.GeoDataFrame\nNote: requires geopandas to be installed\nNote: requires x and y columns to be present\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system identifier passed to the GeoDataFrame constructor, by default “EPSG:4326”\n'EPSG:4326'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ngpd.GeoDataFrame\nSkill data as GeoDataFrame",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillTable"
    ]
  },
  {
    "objectID": "api/obs.html",
    "href": "api/obs.html",
    "title": "obs",
    "section": "",
    "text": "obs\nobs\n\n\nObservations\nModelSkill supports two types of observations:\n\nPointObservation - a point timeseries from a dfs0/nc file or a DataFrame\nTrackObservation - a track (moving point) timeseries from a dfs0/nc file or a DataFrame\n\nAn observation can be created by explicitly invoking one of the above classes or using the observation() function which will return the appropriate type based on the input data (if possible).",
    "crumbs": [
      "API Reference",
      "Observations"
    ]
  },
  {
    "objectID": "index.html#set-up-in-5-minutes",
    "href": "index.html#set-up-in-5-minutes",
    "title": "ModelSkill: Assess the skill of your simulations",
    "section": " Set up in 5 minutes",
    "text": "Set up in 5 minutes\nInstall ModelSkill with pip and get up and running in minutes\nGetting started"
  },
  {
    "objectID": "index.html#its-just-python",
    "href": "index.html#its-just-python",
    "title": "ModelSkill: Assess the skill of your simulations",
    "section": " It’s just Python",
    "text": "It’s just Python\nSpend more time modeling and less time worrying about validation\nAPI Reference"
  },
  {
    "objectID": "index.html#made-to-measure",
    "href": "index.html#made-to-measure",
    "title": "ModelSkill: Assess the skill of your simulations",
    "section": " Made to measure",
    "text": "Made to measure\nChoose amongst different skill metrics, tables and visualizations\nMetrics"
  },
  {
    "objectID": "index.html#open-source-mit",
    "href": "index.html#open-source-mit",
    "title": "ModelSkill: Assess the skill of your simulations",
    "section": " Open Source, MIT",
    "text": "Open Source, MIT\nModelSkill is licensed under MIT and the source code is available on GitHub\nLicense"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "ModelSkill",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024 DHI\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "api/plotting.wind_rose.html",
    "href": "api/plotting.wind_rose.html",
    "title": "plotting.wind_rose",
    "section": "",
    "text": "plotting.wind_rose(\n    data,\n    *,\n    labels=('Measurement', 'Model'),\n    mag_step=None,\n    n_sectors=16,\n    calm_threshold=None,\n    calm_size=None,\n    calm_text='Calm',\n    r_step=0.1,\n    r_max=None,\n    legend=True,\n    cmap1='viridis',\n    cmap2='Greys',\n    mag_bins=None,\n    max_bin=None,\n    n_dir_labels=None,\n    secondary_dir_step_factor=2.0,\n    figsize=(8, 8),\n    ax=None,\n    title=None,\n)\nPlots a (dual) wind (wave or current) roses with calms.\nThe size of the calm is determined by the primary (measurement) data.",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.wind_rose"
    ]
  },
  {
    "objectID": "api/plotting.wind_rose.html#parameters",
    "href": "api/plotting.wind_rose.html#parameters",
    "title": "plotting.wind_rose",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n\narray with 2 or 4 columns (magnitude, direction, magnitude2, direction2)\nrequired\n\n\nlabels\ntuple[str, str]\nlabels for the legend(s)\n('Measurement', 'Model')\n\n\nmag_step\nfloat | None\ndiscretization for magnitude (delta_r, in radial direction )\nNone\n\n\nn_sectors\nint\nnumber of directional sectors\n16\n\n\ncalm_threshold\nfloat | None\nminimum value for data being counted as valid (i.e. below this is calm)\nNone\n\n\ncalm_text\nstr\ntext to display in calm.\n'Calm'\n\n\nr_step\nfloat\nradial axis discretization. By default 0.1 i.e. every 10%.\n0.1\n\n\nr_max\nfloat | None\nmaximum radius (%) of plot, e.g. if 50% wanted then r_max=0.5\nNone\n\n\nmax_bin\nfloat | None\nmax value to truncate the data, e.g., max_bin=1.0 if hm0=1m is the desired final bin.\nNone\n\n\nmag_bins\narray of floats (optional) Default = None\nforce bins to array of values, e.g. when specifying non-equidistant bins.\nNone\n\n\nlegend\nbool\nshow legend\nTrue\n\n\ncmap1\nstring. Default= 'viridis'\ncolormap for main axis\n'viridis'\n\n\ncmap2\nstring. Default= 'Greys'\ncolormap for secondary axis\n'Greys'\n\n\nn_dir_labels\nint. Default= 4\nnumber of labels in the polar plot, choose between 4, 8 or 16, default is to use the same as n_sectors\nNone\n\n\nsecondary_dir_step_factor\nfloat. Default= 2.0\nreduce width of secondary axis by this factor\n2.0\n\n\nfigsize\ntuple[float, float]\nfigure size\n(8, 8)\n\n\nax\n\nMatplotlib axis to plot on defined as polar, it can be done using “subplot_kw = dict(projection = ‘polar’)”. Default = None, new axis created.\nNone\n\n\ntitle\n\ntitle of the plot\nNone",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.wind_rose"
    ]
  },
  {
    "objectID": "api/plotting.wind_rose.html#returns",
    "href": "api/plotting.wind_rose.html#returns",
    "title": "plotting.wind_rose",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\nMatplotlib axis with the plot",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.wind_rose"
    ]
  },
  {
    "objectID": "api/plotting.wind_rose.html#examples",
    "href": "api/plotting.wind_rose.html#examples",
    "title": "plotting.wind_rose",
    "section": "Examples",
    "text": "Examples\n\nimport mikeio\nimport modelskill as ms\nds = mikeio.read(\"../data/wave_dir.dfs0\")\ndf = ds[[0, 2, 1, 3]].to_dataframe()\nms.plotting.wind_rose(df)",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.wind_rose"
    ]
  },
  {
    "objectID": "api/model.html",
    "href": "api/model.html",
    "title": "model",
    "section": "",
    "text": "model\nmodel\n\n\nModel Result\nA model result can either be a simple point/track, or spatial field (e.g. 2d dfsu file) from which data can be extracted at the observation positions by spatial interpolation. The following types are available:\n\nTimeseries\n\nPointModelResult - a point result from a dfs0/nc file or a DataFrame\nTrackModelResult - a track (moving point) result from a dfs0/nc file or a DataFrame\n\nSpatialField (extractable)\n\nGridModelResult - a spatial field from a dfs2/nc file or a Xarray Dataset\nDfsuModelResult - a spatial field from a dfsu file\n\n\nA model result can be created by explicitly invoking one of the above classes or using the model_result() function which will return the appropriate type based on the input data (if possible).",
    "crumbs": [
      "API Reference",
      "Model Result"
    ]
  },
  {
    "objectID": "api/data.html",
    "href": "api/data.html",
    "title": "data",
    "section": "",
    "text": "data\nToy datasets for testing and demonstration purposes",
    "crumbs": [
      "API Reference",
      "Data"
    ]
  },
  {
    "objectID": "api/data.html#examples",
    "href": "api/data.html#examples",
    "title": "data",
    "section": "Examples",
    "text": "Examples\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.data.vistula()\n&gt;&gt;&gt; cc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: Tczew - Discharge [m3/s]\n1: Krasnystaw - Discharge [m3/s]\n2: Sandomierz - Discharge [m3/s]\n3: Szczucin - Discharge [m3/s]\n4: Nowy Sacz - Discharge [m3/s]\n5: Tryncza - Discharge [m3/s]\n6: Ptaki - Discharge [m3/s]\n7: Suraz - Discharge [m3/s]\n\n\n\n&gt;&gt;&gt; cc = ms.data.oresund()\n&gt;&gt;&gt; cc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: Drogden - Surface Elevation [meter]\n1: Barseback - Surface Elevation [meter]\n2: Helsingborg - Surface Elevation [meter]\n3: Kobenhavn - Surface Elevation [meter]\n4: Koege - Surface Elevation [meter]\n5: MalmoHamn - Surface Elevation [meter]\n6: Vedbaek - Surface Elevation [meter]",
    "crumbs": [
      "API Reference",
      "Data"
    ]
  },
  {
    "objectID": "api/data.html#functions",
    "href": "api/data.html#functions",
    "title": "data",
    "section": "Functions",
    "text": "Functions\n\n\n\nName\nDescription\n\n\n\n\noresund\nOresund water level data for Jan-June 2022 compared with MIKE21 model\n\n\nvistula\n5-year daily discharge data for Vistula catchment, Poland\n\n\n\n\noresund\ndata.oresund()\nOresund water level data for Jan-June 2022 compared with MIKE21 model\nContains water level data for 7 stations along the Oresund strait with metadata about the country in the attrs dictionary.\nThe dataset contains additional ERA5 wind-components U10 and V10 aux data.\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\n\n\n\n\n\n\n\nvistula\ndata.vistula()\n5-year daily discharge data for Vistula catchment, Poland\nContains discharge data for 8 stations along the Vistula river compared with two hydrological models “sim1” and “sim2”.\nThe dataset additionally contains precipitation data as aux data and metadata about the river and the catchment area in the attrs dictionary.\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection",
    "crumbs": [
      "API Reference",
      "Data"
    ]
  },
  {
    "objectID": "api/plotting.taylor_diagram.html",
    "href": "api/plotting.taylor_diagram.html",
    "title": "plotting.taylor_diagram",
    "section": "",
    "text": "plotting.taylor_diagram(\n    obs_std,\n    points,\n    figsize=(7, 7),\n    obs_text='Observations',\n    normalize_std=False,\n    ax=None,\n    title='Taylor diagram',\n)\nPlot a Taylor diagram using the given observations and points.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs_std\nfloat\nStandard deviation of the observations.\nrequired\n\n\npoints\nlist of TaylorPoint objects or a single TaylorPoint object\nPoints to plot on the Taylor diagram.\nrequired\n\n\nfigsize\ntuple\nFigure size in inches. Default is (7, 7).\n(7, 7)\n\n\nobs_text\nstr\nLabel for the observations. Default is “Observations”.\n'Observations'\n\n\nnormalize_std\nbool\nWhether to normalize the standard deviation of the points by the standard deviation of the observations. Default is False.\nFalse\n\n\ntitle\nstr\nTitle of the plot. Default is “Taylor diagram”.\n'Taylor diagram'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.figure.Figure\nThe matplotlib figure object",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.taylor_diagram"
    ]
  },
  {
    "objectID": "api/plotting.taylor_diagram.html#parameters",
    "href": "api/plotting.taylor_diagram.html#parameters",
    "title": "plotting.taylor_diagram",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nobs_std\nfloat\nStandard deviation of the observations.\nrequired\n\n\npoints\nlist of TaylorPoint objects or a single TaylorPoint object\nPoints to plot on the Taylor diagram.\nrequired\n\n\nfigsize\ntuple\nFigure size in inches. Default is (7, 7).\n(7, 7)\n\n\nobs_text\nstr\nLabel for the observations. Default is “Observations”.\n'Observations'\n\n\nnormalize_std\nbool\nWhether to normalize the standard deviation of the points by the standard deviation of the observations. Default is False.\nFalse\n\n\ntitle\nstr\nTitle of the plot. Default is “Taylor diagram”.\n'Taylor diagram'",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.taylor_diagram"
    ]
  },
  {
    "objectID": "api/plotting.taylor_diagram.html#returns",
    "href": "api/plotting.taylor_diagram.html#returns",
    "title": "plotting.taylor_diagram",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nmatplotlib.figure.Figure\nThe matplotlib figure object",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.taylor_diagram"
    ]
  },
  {
    "objectID": "api/comparison.html",
    "href": "api/comparison.html",
    "title": "comparison",
    "section": "",
    "text": "comparison\ncomparison\nCompare model output with observations.\nThe comparison module contains different types of classes for single observation comparison (Comparer), and collections of Comparers (ComparerCollection).",
    "crumbs": [
      "API Reference",
      "Comparison"
    ]
  },
  {
    "objectID": "api/match.html",
    "href": "api/match.html",
    "title": "match",
    "section": "",
    "text": "match(\n    obs,\n    mod,\n    *,\n    obs_item=None,\n    mod_item=None,\n    gtype=None,\n    max_model_gap=None,\n    spatial_method=None,\n)\nMatch observation and model result data in space and time\nNOTE: In case of multiple model results with different time coverage, only the overlapping time period will be used! (intersection)\nNOTE: In case of multiple observations, multiple models can only be matched if they are all of SpatialField type, e.g. DfsuModelResult or GridModelResult.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\n(str, Path, pd.DataFrame, Observation, Sequence[Observation])\nObservation(s) to be compared\nrequired\n\n\nmod\n(str, Path, pd.DataFrame, ModelResult, Sequence[ModelResult])\nModel result(s) to be compared\nrequired\n\n\nobs_item\nint or str\nobservation item if obs is a file/dataframe, by default None\nNone\n\n\nmod_item\n(int, str)\nmodel item if mod is a file/dataframe, by default None\nNone\n\n\ngtype\n(str, optional)\nGeometry type of the model result (if mod is a file/dataframe). If not specified, it will be guessed.\nNone\n\n\nmax_model_gap\n(float, optional)\nMaximum time gap (s) in the model result (e.g. for event-based model results), by default None\nNone\n\n\nspatial_method\nstr\nFor Dfsu- and GridModelResult, spatial interpolation/selection method. - For DfsuModelResult, one of: ‘contained’ (=isel), ‘nearest’, ‘inverse_distance’ (with 5 nearest points), by default “inverse_distance”. - For GridModelResult, passed to xarray.interp() as method argument, by default ‘linear’.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nIn case of a single observation\n\n\n\nComparerCollection\nIn case of multiple observations\n\n\n\n\n\n\nfrom_matched - Create a Comparer from observation and model results that are already matched",
    "crumbs": [
      "API Reference",
      "Matching",
      "match"
    ]
  },
  {
    "objectID": "api/match.html#parameters",
    "href": "api/match.html#parameters",
    "title": "match",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nobs\n(str, Path, pd.DataFrame, Observation, Sequence[Observation])\nObservation(s) to be compared\nrequired\n\n\nmod\n(str, Path, pd.DataFrame, ModelResult, Sequence[ModelResult])\nModel result(s) to be compared\nrequired\n\n\nobs_item\nint or str\nobservation item if obs is a file/dataframe, by default None\nNone\n\n\nmod_item\n(int, str)\nmodel item if mod is a file/dataframe, by default None\nNone\n\n\ngtype\n(str, optional)\nGeometry type of the model result (if mod is a file/dataframe). If not specified, it will be guessed.\nNone\n\n\nmax_model_gap\n(float, optional)\nMaximum time gap (s) in the model result (e.g. for event-based model results), by default None\nNone\n\n\nspatial_method\nstr\nFor Dfsu- and GridModelResult, spatial interpolation/selection method. - For DfsuModelResult, one of: ‘contained’ (=isel), ‘nearest’, ‘inverse_distance’ (with 5 nearest points), by default “inverse_distance”. - For GridModelResult, passed to xarray.interp() as method argument, by default ‘linear’.\nNone",
    "crumbs": [
      "API Reference",
      "Matching",
      "match"
    ]
  },
  {
    "objectID": "api/match.html#returns",
    "href": "api/match.html#returns",
    "title": "match",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nComparer\nIn case of a single observation\n\n\n\nComparerCollection\nIn case of multiple observations",
    "crumbs": [
      "API Reference",
      "Matching",
      "match"
    ]
  },
  {
    "objectID": "api/match.html#see-also",
    "href": "api/match.html#see-also",
    "title": "match",
    "section": "",
    "text": "from_matched - Create a Comparer from observation and model results that are already matched",
    "crumbs": [
      "API Reference",
      "Matching",
      "match"
    ]
  },
  {
    "objectID": "api/Comparer.html",
    "href": "api/Comparer.html",
    "title": "Comparer",
    "section": "",
    "text": "Comparer(self, matched_data, raw_mod_data=None)\nComparer class for comparing model and observation data.\nThe Comparer class is the main class of the ModelSkill package. It is returned by match(), from_matched() or as an element in a ComparerCollection. It holds the matched observation and model data for a single observation and has methods for plotting and skill assessment.\nMain functionality:\n\nselecting/filtering data\n\nsel()\nquery()\n\nskill assessment\n\nskill()\ngridded_skill() (for track observations)\n\nplotting\n\nplot.timeseries()\nplot.scatter()\nplot.kde()\nplot.qq()\nplot.hist()\nplot.box()\n\nload/save/export data\n\nload()\nsave()\nto_dataframe()\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmatched_data\nxr.Dataset\nMatched data\nrequired\n\n\nraw_mod_data\ndict of modelskill.PointModelResult\nRaw model data. If None, observation and modeldata must be provided.\nNone\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp1 = ms.match(observation, modeldata)\n&gt;&gt;&gt; cmp2 = ms.from_matched(matched_data)\n\n\n\nmodelskill.match, modelskill.from_matched\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nplot\nPlot using the ComparerPlotter\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nskill\nSkill assessment of model(s)\n\n\ngridded_skill\nAggregated spatial skill assessment of model(s) on a regular spatial grid.\n\n\nscore\nModel skill score\n\n\nrename\nRename observation, model or auxiliary data variables\n\n\nsel\nSelect data based on model, time and/or area.\n\n\nwhere\nReturn a new Comparer with values where cond is True\n\n\nquery\nReturn a new Comparer with values where query cond is True\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\nsave\nSave to netcdf file\n\n\nload\nLoad from netcdf file\n\n\n\n\n\nComparer.skill(by=None, metrics=None)\nSkill assessment of model(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nby\nstr or List[str]\ngroup by, by default [“model”] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data.\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nskill assessment object\n\n\n\n\n\n\nsel a method for filtering/selecting data\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match(c2, mod)\n&gt;&gt;&gt; cc['c2'].skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nc2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n&gt;&gt;&gt; cc['c2'].skill(by='freq:D').round(2)\n             n  bias  rmse  urmse   mae    cc    si    r2\n2017-10-27  72 -0.19  0.31   0.25  0.26  0.48  0.12  0.98\n2017-10-28   0   NaN   NaN    NaN   NaN   NaN   NaN   NaN\n2017-10-29  41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n\n\n\n\nComparer.gridded_skill(\n    bins=5,\n    binsize=None,\n    by=None,\n    metrics=None,\n    n_min=None,\n    **kwargs,\n)\nAggregated spatial skill assessment of model(s) on a regular spatial grid.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\ncriteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,[2,3,5])\n5\n\n\nbinsize\nfloat\nbin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y))\nNone\n\n\nby\n(str, List[str])\ngroup by column name or by temporal bin via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily by default [“model”,“observation”]\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\nn_min\nint\nminimum number of observations in a grid cell; cells with fewer observations get a score of np.nan\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillGrid\nskill assessment as a SkillGrid object\n\n\n\n\n\n\nskill a method for aggregated skill assessment\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.match(c2, mod)   # satellite altimeter vs. model\n&gt;&gt;&gt; cmp.gridded_skill(metrics='bias')\n&lt;xarray.Dataset&gt;\nDimensions:      (x: 5, y: 5)\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n* y            (y) float64 50.6 51.66 52.7 53.75 54.8\nData variables:\n    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n&gt;&gt;&gt; gs = cc.gridded_skill(binsize=0.5)\n&gt;&gt;&gt; gs.data.coords\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n\n\n\n\nComparer.score(metric=mtr.rmse, **kwargs)\nModel skill score\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmetric\nlist\na single metric from modelskill.metrics, by default rmse\nmtr.rmse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict[str, float]\nskill score as a single number (for each model)\n\n\n\n\n\n\nskill a method for skill assessment returning a pd.DataFrame\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.match(c2, mod)\n&gt;&gt;&gt; cmp.score()\n{'mod': 0.3517964910888918}\n&gt;&gt;&gt; cmp.score(metric=\"mape\")\n{'mod': 11.567399646108198}\n\n\n\n\nComparer.rename(mapping, errors='raise')\nRename observation, model or auxiliary data variables\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmapping\ndict\nmapping of old names to new names\nrequired\n\n\nerrors\n('raise', 'ignore')\nIf ‘raise’, raise a KeyError if any of the old names do not exist in the data. By default ‘raise’.\n'raise'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\n\n\n\n\n\n\n\n&gt;&gt;&gt; cmp = ms.match(observation, modeldata)\n&gt;&gt;&gt; cmp.mod_names\n['model1']\n&gt;&gt;&gt; cmp2 = cmp.rename({'model1': 'model2'})\n&gt;&gt;&gt; cmp2.mod_names\n['model2']\n\n\n\n\nComparer.sel(model=None, start=None, end=None, time=None, area=None)\nSelect data based on model, time and/or area.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr or int or list of str or list of int\nModel name or index. If None, all models are selected.\nNone\n\n\nstart\nstr or datetime\nStart time. If None, all times are selected.\nNone\n\n\nend\nstr or datetime\nEnd time. If None, all times are selected.\nNone\n\n\ntime\nstr or datetime\nTime. If None, all times are selected.\nNone\n\n\narea\nlist of float\nbbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nNew Comparer with selected data.\n\n\n\n\n\n\n\nComparer.where(cond)\nReturn a new Comparer with values where cond is True\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncond\n(bool, np.ndarray, xr.DataArray)\nThis selects the values to return.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nNew Comparer with values where cond is True and other otherwise.\n\n\n\n\n\n\n&gt;&gt;&gt; c2 = c.where(c.data.Observation &gt; 0)\n\n\n\n\nComparer.query(query)\nReturn a new Comparer with values where query cond is True\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery\nstr\nQuery string, see pandas.DataFrame.query\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nNew Comparer with values where cond is True and other otherwise.\n\n\n\n\n\n\n&gt;&gt;&gt; c2 = c.query(\"Observation &gt; 0\")\n\n\n\n\nComparer.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nComparer.save(filename)\nSave to netcdf file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nfilename\nrequired\n\n\n\n\n\n\n\nComparer.load(filename)\nLoad from netcdf file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nfilename\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer",
    "crumbs": [
      "API Reference",
      "Comparison",
      "Comparer"
    ]
  },
  {
    "objectID": "api/Comparer.html#parameters",
    "href": "api/Comparer.html#parameters",
    "title": "Comparer",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmatched_data\nxr.Dataset\nMatched data\nrequired\n\n\nraw_mod_data\ndict of modelskill.PointModelResult\nRaw model data. If None, observation and modeldata must be provided.\nNone",
    "crumbs": [
      "API Reference",
      "Comparison",
      "Comparer"
    ]
  },
  {
    "objectID": "api/Comparer.html#examples",
    "href": "api/Comparer.html#examples",
    "title": "Comparer",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp1 = ms.match(observation, modeldata)\n&gt;&gt;&gt; cmp2 = ms.from_matched(matched_data)",
    "crumbs": [
      "API Reference",
      "Comparison",
      "Comparer"
    ]
  },
  {
    "objectID": "api/Comparer.html#see-also",
    "href": "api/Comparer.html#see-also",
    "title": "Comparer",
    "section": "",
    "text": "modelskill.match, modelskill.from_matched",
    "crumbs": [
      "API Reference",
      "Comparison",
      "Comparer"
    ]
  },
  {
    "objectID": "api/Comparer.html#attributes",
    "href": "api/Comparer.html#attributes",
    "title": "Comparer",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nplot\nPlot using the ComparerPlotter",
    "crumbs": [
      "API Reference",
      "Comparison",
      "Comparer"
    ]
  },
  {
    "objectID": "api/Comparer.html#methods",
    "href": "api/Comparer.html#methods",
    "title": "Comparer",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nskill\nSkill assessment of model(s)\n\n\ngridded_skill\nAggregated spatial skill assessment of model(s) on a regular spatial grid.\n\n\nscore\nModel skill score\n\n\nrename\nRename observation, model or auxiliary data variables\n\n\nsel\nSelect data based on model, time and/or area.\n\n\nwhere\nReturn a new Comparer with values where cond is True\n\n\nquery\nReturn a new Comparer with values where query cond is True\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\nsave\nSave to netcdf file\n\n\nload\nLoad from netcdf file\n\n\n\n\n\nComparer.skill(by=None, metrics=None)\nSkill assessment of model(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nby\nstr or List[str]\ngroup by, by default [“model”] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data.\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nskill assessment object\n\n\n\n\n\n\nsel a method for filtering/selecting data\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match(c2, mod)\n&gt;&gt;&gt; cc['c2'].skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nc2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n&gt;&gt;&gt; cc['c2'].skill(by='freq:D').round(2)\n             n  bias  rmse  urmse   mae    cc    si    r2\n2017-10-27  72 -0.19  0.31   0.25  0.26  0.48  0.12  0.98\n2017-10-28   0   NaN   NaN    NaN   NaN   NaN   NaN   NaN\n2017-10-29  41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n\n\n\n\nComparer.gridded_skill(\n    bins=5,\n    binsize=None,\n    by=None,\n    metrics=None,\n    n_min=None,\n    **kwargs,\n)\nAggregated spatial skill assessment of model(s) on a regular spatial grid.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\ncriteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,[2,3,5])\n5\n\n\nbinsize\nfloat\nbin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y))\nNone\n\n\nby\n(str, List[str])\ngroup by column name or by temporal bin via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily by default [“model”,“observation”]\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\nn_min\nint\nminimum number of observations in a grid cell; cells with fewer observations get a score of np.nan\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillGrid\nskill assessment as a SkillGrid object\n\n\n\n\n\n\nskill a method for aggregated skill assessment\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.match(c2, mod)   # satellite altimeter vs. model\n&gt;&gt;&gt; cmp.gridded_skill(metrics='bias')\n&lt;xarray.Dataset&gt;\nDimensions:      (x: 5, y: 5)\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n* y            (y) float64 50.6 51.66 52.7 53.75 54.8\nData variables:\n    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n&gt;&gt;&gt; gs = cc.gridded_skill(binsize=0.5)\n&gt;&gt;&gt; gs.data.coords\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n\n\n\n\nComparer.score(metric=mtr.rmse, **kwargs)\nModel skill score\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmetric\nlist\na single metric from modelskill.metrics, by default rmse\nmtr.rmse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict[str, float]\nskill score as a single number (for each model)\n\n\n\n\n\n\nskill a method for skill assessment returning a pd.DataFrame\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cmp = ms.match(c2, mod)\n&gt;&gt;&gt; cmp.score()\n{'mod': 0.3517964910888918}\n&gt;&gt;&gt; cmp.score(metric=\"mape\")\n{'mod': 11.567399646108198}\n\n\n\n\nComparer.rename(mapping, errors='raise')\nRename observation, model or auxiliary data variables\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmapping\ndict\nmapping of old names to new names\nrequired\n\n\nerrors\n('raise', 'ignore')\nIf ‘raise’, raise a KeyError if any of the old names do not exist in the data. By default ‘raise’.\n'raise'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\n\n\n\n\n\n\n\n&gt;&gt;&gt; cmp = ms.match(observation, modeldata)\n&gt;&gt;&gt; cmp.mod_names\n['model1']\n&gt;&gt;&gt; cmp2 = cmp.rename({'model1': 'model2'})\n&gt;&gt;&gt; cmp2.mod_names\n['model2']\n\n\n\n\nComparer.sel(model=None, start=None, end=None, time=None, area=None)\nSelect data based on model, time and/or area.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr or int or list of str or list of int\nModel name or index. If None, all models are selected.\nNone\n\n\nstart\nstr or datetime\nStart time. If None, all times are selected.\nNone\n\n\nend\nstr or datetime\nEnd time. If None, all times are selected.\nNone\n\n\ntime\nstr or datetime\nTime. If None, all times are selected.\nNone\n\n\narea\nlist of float\nbbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nNew Comparer with selected data.\n\n\n\n\n\n\n\nComparer.where(cond)\nReturn a new Comparer with values where cond is True\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncond\n(bool, np.ndarray, xr.DataArray)\nThis selects the values to return.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nNew Comparer with values where cond is True and other otherwise.\n\n\n\n\n\n\n&gt;&gt;&gt; c2 = c.where(c.data.Observation &gt; 0)\n\n\n\n\nComparer.query(query)\nReturn a new Comparer with values where query cond is True\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery\nstr\nQuery string, see pandas.DataFrame.query\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer\nNew Comparer with values where cond is True and other otherwise.\n\n\n\n\n\n\n&gt;&gt;&gt; c2 = c.query(\"Observation &gt; 0\")\n\n\n\n\nComparer.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nComparer.save(filename)\nSave to netcdf file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nfilename\nrequired\n\n\n\n\n\n\n\nComparer.load(filename)\nLoad from netcdf file\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nfilename\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparer",
    "crumbs": [
      "API Reference",
      "Comparison",
      "Comparer"
    ]
  },
  {
    "objectID": "api/settings.html",
    "href": "api/settings.html",
    "title": "settings",
    "section": "",
    "text": "settings\nGlobal modelskill settings.\nThe settings module holds package-wide configurables and provides a uniform API for working with them.\nThis module is inspired by pandas config module.\n\n\nThis module supports the following requirements:\n\noptions are referenced using keys in dot.notation, e.g. “x.y.option - z”.\nkeys are case-insensitive.\nfunctions should accept partial/regex keys, when unambiguous.\noptions can be registered by modules at import time.\noptions have a default value, and (optionally) a description and validation function associated with them.\noptions can be reset to their default value.\nall option can be reset to their default value at once.\nall options in a certain sub - namespace can be reset at once.\nthe user can set / get / reset or ask for the description of an option.\na developer can register an option.\n\n\n\n\n\nData is stored using nested dictionaries, and should be accessed through the provided API.\n“Registered options” have metadata associated with them, which are stored in auxiliary dictionaries keyed on the fully-qualified key, e.g. “x.y.z.option”.\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.options\nmetrics.list : [&lt;function bias at 0x0000029D614A2DD0&gt;, (...)]\nplot.rcparams : {}\nplot.scatter.legend.bbox : {'facecolor': 'white', (...)}\nplot.scatter.legend.fontsize : 12\nplot.scatter.legend.kwargs : {}\nplot.scatter.oneone_line.color : blue\nplot.scatter.oneone_line.label : 1:1\nplot.scatter.points.alpha : 0.5\nplot.scatter.points.label :\nplot.scatter.points.size : 20\nplot.scatter.quantiles.color : darkturquoise\nplot.scatter.quantiles.kwargs : {}\nplot.scatter.quantiles.label : Q-Q\nplot.scatter.quantiles.marker : X\nplot.scatter.quantiles.markeredgecolor : (0, 0, 0, 0.4)\nplot.scatter.quantiles.markeredgewidth : 0.5\nplot.scatter.quantiles.markersize : 3.5\nplot.scatter.reg_line.kwargs : {'color': 'r'}\n&gt;&gt;&gt; ms.set_option(\"plot.scatter.points.size\", 4)\n&gt;&gt;&gt; plot.scatter.points.size\n4\n&gt;&gt;&gt; ms.get_option(\"plot.scatter.points.size\")\n4\n&gt;&gt;&gt; ms.options.plot.scatter.points.size = 10\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n10\n&gt;&gt;&gt; ms.reset_option(\"plot.scatter.points.size\")\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n20\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nOptionsContainer\nprovide attribute-style access to a nested dict of options\n\n\n\n\n\nsettings.OptionsContainer(self, d, prefix='')\nprovide attribute-style access to a nested dict of options\nAccessed by ms.options\n\n\n\n\n\nName\nDescription\n\n\n\n\nto_dict\nReturn options as dictionary with full-name keys\n\n\n\n\n\nsettings.OptionsContainer.to_dict()\nReturn options as dictionary with full-name keys\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_option\nGet value of a single option matching a pattern\n\n\nload_style\nLoad a number of options from a named style.\n\n\nregister_option\nRegister an option in the package-wide modelskill settingss object\n\n\nreset_option\nReset one or more options (matching a pattern) to the default value\n\n\nset_option\nSet the value of one or more options\n\n\n\n\n\nsettings.get_option(pat)\nGet value of a single option matching a pattern\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npat\nstr\npattern of seeked option\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAny\nvalue of matched option\n\n\n\n\n\n\n\nsettings.load_style(name)\nLoad a number of options from a named style.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of the predefined style to load. Available styles are: ‘MOOD’: Resembling the plots of the www.metocean-on-demand.com data portal.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nKeyError\nIf a named style is not found.\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.load_style('MOOD')\n\n\n\n\nsettings.register_option(key, defval, doc='', validator=None)\nRegister an option in the package-wide modelskill settingss object\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nkey\nstr\nFully-qualified key, e.g. “x.y.option - z”.\nrequired\n\n\ndefval\nobject\nDefault value of the option.\nrequired\n\n\ndoc\nstr\nDescription of the option.\n''\n\n\nvalidator\nCallable\nFunction of a single argument, should raise ValueError if called with a value which is not a legal value for the option.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nValueError if validator is specified and defval is not a valid value.\n\n\n\n\n\n\n\n\nsettings.reset_option(pat='', silent=False)\nReset one or more options (matching a pattern) to the default value\n\n\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n20\n&gt;&gt;&gt; ms.options.plot.scatter.points.size = 10\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n10\n&gt;&gt;&gt; ms.reset_option(\"plot.scatter.points.size\")\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n20\n\n\n\n\nsettings.set_option(*args, **kwargs)\nSet the value of one or more options\n\n\n&gt;&gt;&gt; ms.set_option(\"plot.scatter.points.size\", 4)\n&gt;&gt;&gt; ms.set_option({\"plot.scatter.points.size\": 4})\n&gt;&gt;&gt; ms.options.plot.scatter.points.size = 4",
    "crumbs": [
      "API Reference",
      "Settings"
    ]
  },
  {
    "objectID": "api/settings.html#overview",
    "href": "api/settings.html#overview",
    "title": "settings",
    "section": "",
    "text": "This module supports the following requirements:\n\noptions are referenced using keys in dot.notation, e.g. “x.y.option - z”.\nkeys are case-insensitive.\nfunctions should accept partial/regex keys, when unambiguous.\noptions can be registered by modules at import time.\noptions have a default value, and (optionally) a description and validation function associated with them.\noptions can be reset to their default value.\nall option can be reset to their default value at once.\nall options in a certain sub - namespace can be reset at once.\nthe user can set / get / reset or ask for the description of an option.\na developer can register an option.",
    "crumbs": [
      "API Reference",
      "Settings"
    ]
  },
  {
    "objectID": "api/settings.html#implementation",
    "href": "api/settings.html#implementation",
    "title": "settings",
    "section": "",
    "text": "Data is stored using nested dictionaries, and should be accessed through the provided API.\n“Registered options” have metadata associated with them, which are stored in auxiliary dictionaries keyed on the fully-qualified key, e.g. “x.y.z.option”.",
    "crumbs": [
      "API Reference",
      "Settings"
    ]
  },
  {
    "objectID": "api/settings.html#examples",
    "href": "api/settings.html#examples",
    "title": "settings",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.options\nmetrics.list : [&lt;function bias at 0x0000029D614A2DD0&gt;, (...)]\nplot.rcparams : {}\nplot.scatter.legend.bbox : {'facecolor': 'white', (...)}\nplot.scatter.legend.fontsize : 12\nplot.scatter.legend.kwargs : {}\nplot.scatter.oneone_line.color : blue\nplot.scatter.oneone_line.label : 1:1\nplot.scatter.points.alpha : 0.5\nplot.scatter.points.label :\nplot.scatter.points.size : 20\nplot.scatter.quantiles.color : darkturquoise\nplot.scatter.quantiles.kwargs : {}\nplot.scatter.quantiles.label : Q-Q\nplot.scatter.quantiles.marker : X\nplot.scatter.quantiles.markeredgecolor : (0, 0, 0, 0.4)\nplot.scatter.quantiles.markeredgewidth : 0.5\nplot.scatter.quantiles.markersize : 3.5\nplot.scatter.reg_line.kwargs : {'color': 'r'}\n&gt;&gt;&gt; ms.set_option(\"plot.scatter.points.size\", 4)\n&gt;&gt;&gt; plot.scatter.points.size\n4\n&gt;&gt;&gt; ms.get_option(\"plot.scatter.points.size\")\n4\n&gt;&gt;&gt; ms.options.plot.scatter.points.size = 10\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n10\n&gt;&gt;&gt; ms.reset_option(\"plot.scatter.points.size\")\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n20",
    "crumbs": [
      "API Reference",
      "Settings"
    ]
  },
  {
    "objectID": "api/settings.html#classes",
    "href": "api/settings.html#classes",
    "title": "settings",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nOptionsContainer\nprovide attribute-style access to a nested dict of options\n\n\n\n\n\nsettings.OptionsContainer(self, d, prefix='')\nprovide attribute-style access to a nested dict of options\nAccessed by ms.options\n\n\n\n\n\nName\nDescription\n\n\n\n\nto_dict\nReturn options as dictionary with full-name keys\n\n\n\n\n\nsettings.OptionsContainer.to_dict()\nReturn options as dictionary with full-name keys",
    "crumbs": [
      "API Reference",
      "Settings"
    ]
  },
  {
    "objectID": "api/settings.html#functions",
    "href": "api/settings.html#functions",
    "title": "settings",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_option\nGet value of a single option matching a pattern\n\n\nload_style\nLoad a number of options from a named style.\n\n\nregister_option\nRegister an option in the package-wide modelskill settingss object\n\n\nreset_option\nReset one or more options (matching a pattern) to the default value\n\n\nset_option\nSet the value of one or more options\n\n\n\n\n\nsettings.get_option(pat)\nGet value of a single option matching a pattern\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npat\nstr\npattern of seeked option\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAny\nvalue of matched option\n\n\n\n\n\n\n\nsettings.load_style(name)\nLoad a number of options from a named style.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nName of the predefined style to load. Available styles are: ‘MOOD’: Resembling the plots of the www.metocean-on-demand.com data portal.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nKeyError\nIf a named style is not found.\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.load_style('MOOD')\n\n\n\n\nsettings.register_option(key, defval, doc='', validator=None)\nRegister an option in the package-wide modelskill settingss object\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nkey\nstr\nFully-qualified key, e.g. “x.y.option - z”.\nrequired\n\n\ndefval\nobject\nDefault value of the option.\nrequired\n\n\ndoc\nstr\nDescription of the option.\n''\n\n\nvalidator\nCallable\nFunction of a single argument, should raise ValueError if called with a value which is not a legal value for the option.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nValueError if validator is specified and defval is not a valid value.\n\n\n\n\n\n\n\n\nsettings.reset_option(pat='', silent=False)\nReset one or more options (matching a pattern) to the default value\n\n\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n20\n&gt;&gt;&gt; ms.options.plot.scatter.points.size = 10\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n10\n&gt;&gt;&gt; ms.reset_option(\"plot.scatter.points.size\")\n&gt;&gt;&gt; ms.options.plot.scatter.points.size\n20\n\n\n\n\nsettings.set_option(*args, **kwargs)\nSet the value of one or more options\n\n\n&gt;&gt;&gt; ms.set_option(\"plot.scatter.points.size\", 4)\n&gt;&gt;&gt; ms.set_option({\"plot.scatter.points.size\": 4})\n&gt;&gt;&gt; ms.options.plot.scatter.points.size = 4",
    "crumbs": [
      "API Reference",
      "Settings"
    ]
  },
  {
    "objectID": "api/comparison.ComparerPlotter.html",
    "href": "api/comparison.ComparerPlotter.html",
    "title": "comparison.ComparerPlotter",
    "section": "",
    "text": "comparison.ComparerPlotter(self, comparer)\nPlotter class for Comparer",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerPlotter"
    ]
  },
  {
    "objectID": "api/comparison.ComparerPlotter.html#examples",
    "href": "api/comparison.ComparerPlotter.html#examples",
    "title": "comparison.ComparerPlotter",
    "section": "Examples",
    "text": "Examples\n&gt;&gt;&gt; cmp.plot.scatter()\n&gt;&gt;&gt; cmp.plot.timeseries()\n&gt;&gt;&gt; cmp.plot.hist()\n&gt;&gt;&gt; cmp.plot.kde()\n&gt;&gt;&gt; cmp.plot.qq()\n&gt;&gt;&gt; cmp.plot.box()",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerPlotter"
    ]
  },
  {
    "objectID": "api/comparison.ComparerPlotter.html#methods",
    "href": "api/comparison.ComparerPlotter.html#methods",
    "title": "comparison.ComparerPlotter",
    "section": "Methods",
    "text": "Methods\n\n\n\nName\nDescription\n\n\n\n\nbox\nMake a box plot of model data and observations.\n\n\nhist\nPlot histogram of model data and observations.\n\n\nkde\nPlot kde (kernel density estimates of distributions) of model data and observations.\n\n\nqq\nMake quantile-quantile (q-q) plot of model data and observations.\n\n\nresidual_hist\nplot histogram of residual values\n\n\nscatter\nScatter plot tailored for model-observation comparison.\n\n\ntaylor\nTaylor diagram for model skill comparison.\n\n\ntimeseries\nTimeseries plot showing compared data: observation vs modelled\n\n\n\n\nbox\ncomparison.ComparerPlotter.box(ax=None, title=None, figsize=None, **kwargs)\nMake a box plot of model data and observations.\nWraps pandas.DataFrame boxplot() method.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\ntitle\nstr\nplot title, default: [observation name]\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to df.boxplot()\n{}\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\nExamples\n&gt;&gt;&gt; cmp.plot.box()\n&gt;&gt;&gt; cmp.plot.box(showmeans=True)\n&gt;&gt;&gt; cmp.plot.box(ax=ax, title=\"Box plot\")\n\n\nSee also\npandas.DataFrame.boxplot matplotlib.pyplot.boxplot\n\n\n\nhist\ncomparison.ComparerPlotter.hist(\n    bins=100,\n    *,\n    title=None,\n    ax=None,\n    figsize=None,\n    density=True,\n    alpha=0.5,\n    **kwargs,\n)\nPlot histogram of model data and observations.\nWraps pandas.DataFrame hist() method.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\nnumber of bins, by default 100\n100\n\n\ntitle\nstr\nplot title, default: [model name] vs [observation name]\nNone\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\ndensity\nbool\nIf True, draw and return a probability density\nTrue\n\n\nalpha\nfloat\nalpha transparency fraction, by default 0.5\n0.5\n\n\n**kwargs\n\nother keyword arguments to df.plot.hist()\n{}\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\nSee also\npandas.Series.plot.hist matplotlib.axes.Axes.hist\n\n\n\nkde\ncomparison.ComparerPlotter.kde(ax=None, title=None, figsize=None, **kwargs)\nPlot kde (kernel density estimates of distributions) of model data and observations.\nWraps pandas.DataFrame kde() method.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\ntitle\nstr\nplot title, default: “KDE plot for [observation name]”\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to df.plot.kde()\n{}\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\n\n\n\n\n\n\nExamples\n&gt;&gt;&gt; cmp.plot.kde()\n&gt;&gt;&gt; cmp.plot.kde(bw_method=0.3)\n&gt;&gt;&gt; cmp.plot.kde(ax=ax, bw_method='silverman')\n&gt;&gt;&gt; cmp.plot.kde(xlim=[0,None], title=\"Density plot\");\n\n\nSee also\npandas.Series.plot.kde\n\n\n\nqq\ncomparison.ComparerPlotter.qq(\n    quantiles=None,\n    *,\n    title=None,\n    ax=None,\n    figsize=None,\n    **kwargs,\n)\nMake quantile-quantile (q-q) plot of model data and observations.\nPrimarily used to compare multiple models.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000) if int, this is the number of points if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\ntitle\nstr\nplot title, default: “Q-Q plot for [observation name]”\nNone\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.plot()\n{}\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib axes\n\n\n\n\n\n\nExamples\n&gt;&gt;&gt; cmp.plot.qq()\n\n\n\nresidual_hist\ncomparison.ComparerPlotter.residual_hist(\n    bins=100,\n    title=None,\n    color=None,\n    figsize=None,\n    ax=None,\n    **kwargs,\n)\nplot histogram of residual values\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\nspecification of bins, by default 100\n100\n\n\ntitle\nstr\nplot title, default: Residuals, [name]\nNone\n\n\ncolor\nstr\nresidual color, by default “#8B8D8E”\nNone\n\n\nfigsize\ntuple\nfigure size, by default None\nNone\n\n\nax\nmatplotlib.axes.Axes | list[matplotlib.axes.Axes]\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.hist()\n{}\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes | list[matplotlib.axes.Axes]\n\n\n\n\n\n\n\nscatter\ncomparison.ComparerPlotter.scatter(\n    model=None,\n    bins=120,\n    quantiles=None,\n    fit_to_quantiles=False,\n    show_points=None,\n    show_hist=None,\n    show_density=None,\n    norm=None,\n    backend='matplotlib',\n    figsize=(8, 8),\n    xlim=None,\n    ylim=None,\n    reg_method='ols',\n    title=None,\n    xlabel=None,\n    ylabel=None,\n    skill_table=None,\n    ax=None,\n    **kwargs,\n)\nScatter plot tailored for model-observation comparison.\nOptionally, with density histogram.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint | float\nbins for the 2D histogram on the background. By default 120 bins. if int, represents the number of bins of 2D if float, represents the bin size if sequence (list of int or float), represents the bin edges\n120\n\n\nquantiles\nint | Sequence[float] | None\nnumber of quantiles for QQ-plot, by default None and will depend on the scatter data length (10, 100 or 1000); if int, this is the number of points; if sequence (list of floats), represents the desired quantiles (from 0 to 1)\nNone\n\n\nfit_to_quantiles\nbool\nby default the regression line is fitted to all data, if True, it is fitted to the quantiles which can be useful to represent the extremes of the distribution, by default False\nFalse\n\n\nshow_points\n(bool, int, float)\nShould the scatter points be displayed? None means: show all points if fewer than 1e4, otherwise show 1e4 sample points, by default None. float: fraction of points to show on plot from 0 to 1. e.g. 0.5 shows 50% of the points. int: if ‘n’ (int) given, then ‘n’ points will be displayed, randomly selected\nNone\n\n\nshow_hist\nbool\nshow the data density as a a 2d histogram, by default None\nNone\n\n\nshow_density\nOptional[bool]\nshow the data density as a colormap of the scatter, by default None. If both show_density and show_hist are None, then show_density is used by default. If number of points is less than 200, then show_density is False as default. For binning the data, the kword bins=Float is used.\nNone\n\n\nnorm\nmatplotlib.colors norm\ncolormap normalization. If None, defaults to matplotlib.colors.PowerNorm(vmin=1, gamma=0.5)\nNone\n\n\nbackend\nstr\nuse “plotly” (interactive) or “matplotlib” backend, by default “matplotlib”\n'matplotlib'\n\n\nfigsize\ntuple\nwidth and height of the figure, by default (8, 8)\n(8, 8)\n\n\nxlim\ntuple\nplot range for the observation (xmin, xmax), by default None\nNone\n\n\nylim\ntuple\nplot range for the model (ymin, ymax), by default None\nNone\n\n\nreg_method\nstr or bool\nmethod for determining the regression line “ols” : ordinary least squares regression “odr” : orthogonal distance regression, False : no regression line by default “ols”\n'ols'\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\nxlabel\nstr\nx-label text on plot, by default None\nNone\n\n\nylabel\nstr\ny-label text on plot, by default None\nNone\n\n\nskill_table\n(str, List[str], dict[str, str], bool)\nlist of modelskill.metrics or boolean, if True then by default modelskill.options.metrics.list. This kword adds a box at the right of the scatter plot, by default False mapping can be used to rename the metrics in the table.\nNone\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\n**kwargs\n\nother keyword arguments to plt.scatter()\n{}\n\n\n\n\n\nExamples\n&gt;&gt;&gt; cmp.plot.scatter()\n&gt;&gt;&gt; cmp.plot.scatter(bins=0.2, backend='plotly')\n&gt;&gt;&gt; cmp.plot.scatter(show_points=False, title='no points')\n&gt;&gt;&gt; cmp.plot.scatter(xlabel='all observations', ylabel='my model')\n&gt;&gt;&gt; cmp.sel(model='HKZN_v2').plot.scatter(figsize=(10, 10))\n\n\n\ntaylor\ncomparison.ComparerPlotter.taylor(\n    normalize_std=False,\n    figsize=(7, 7),\n    marker='o',\n    marker_size=6.0,\n    title='Taylor diagram',\n)\nTaylor diagram for model skill comparison.\nTaylor diagram showing model std and correlation to observation in a single-quadrant polar plot, with r=std and theta=arccos(cc).\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnormalize_std\nbool\nplot model std normalized with observation std, default False\nFalse\n\n\nfigsize\ntuple\nwidth and height of the figure (should be square), by default (7, 7)\n(7, 7)\n\n\nmarker\nstr\nmarker type e.g. “x”, “*“, by default”o”\n'o'\n\n\nmarker_size\nfloat\nsize of the marker, by default 6\n6.0\n\n\ntitle\nstr\ntitle of the plot, by default “Taylor diagram”\n'Taylor diagram'\n\n\n\n\n\nReturns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.figure.Figure\n\n\n\n\n\n\nExamples\n\ncmp.plot.taylor();\n\n\n\nNotes\nCopin, Y. (2018). https://gist.github.com/ycopin/3342888, Yannick Copin yannick.copin@laposte.net\n\n\n\ntimeseries\ncomparison.ComparerPlotter.timeseries(\n    title=None,\n    ylim=None,\n    ax=None,\n    figsize=None,\n    backend='matplotlib',\n    **kwargs,\n)\nTimeseries plot showing compared data: observation vs modelled\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntitle\nstr\nplot title, by default None\nNone\n\n\nylim\n(float, float)\nplot range for the model (ymin, ymax), by default None\nNone\n\n\nax\nmatplotlib.axes.Axes\naxes to plot on, by default None\nNone\n\n\nfigsize\n(float, float)\nfigure size, by default None\nNone\n\n\nbackend\nstr\nuse “plotly” (interactive) or “matplotlib” backend, by default “matplotlib”\n'matplotlib'\n\n\n**kwargs\n\nother keyword arguments to fig.update_layout (plotly backend)\n{}\n\n\n\n\n\nReturns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes or plotly.graph_objects.Figure",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerPlotter"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGridArray.html",
    "href": "api/skill_grid.SkillGridArray.html",
    "title": "skill_grid.SkillGridArray",
    "section": "",
    "text": "skill_grid.SkillGridArray(self, data)\nA SkillGridArray is a single metric-SkillGrid, corresponding to a “column” in a SkillGrid\nTypically created by indexing a SkillGrid object, e.g. ss[\"bias\"].\n\n\n&gt;&gt;&gt; gs = cc.gridded_skill()\n&gt;&gt;&gt; gs[\"bias\"].plot()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncoords\nCoordinates (same as xr.DataSet.coords)\n\n\nmod_names\nList of model names\n\n\nobs_names\nList of observation names\n\n\nx\nx-coordinate values\n\n\ny\ny-coordinate values\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nplot\nwrapper for xArray DataArray plot function\n\n\n\n\n\nskill_grid.SkillGridArray.plot(**kwargs)\nwrapper for xArray DataArray plot function\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n**kwargs\nAny\nkeyword arguments passed to xr.DataArray plot() e.g. figsize\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; gs = cc.gridded_skill()\n&gt;&gt;&gt; gs[\"bias\"].plot()\n&gt;&gt;&gt; gs.sel(model='SW_1').rmse.plot()\n&gt;&gt;&gt; gs.r2.plot(cmap='YlOrRd', figsize=(10,10))",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGridArray"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGridArray.html#examples",
    "href": "api/skill_grid.SkillGridArray.html#examples",
    "title": "skill_grid.SkillGridArray",
    "section": "",
    "text": "&gt;&gt;&gt; gs = cc.gridded_skill()\n&gt;&gt;&gt; gs[\"bias\"].plot()",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGridArray"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGridArray.html#attributes",
    "href": "api/skill_grid.SkillGridArray.html#attributes",
    "title": "skill_grid.SkillGridArray",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncoords\nCoordinates (same as xr.DataSet.coords)\n\n\nmod_names\nList of model names\n\n\nobs_names\nList of observation names\n\n\nx\nx-coordinate values\n\n\ny\ny-coordinate values",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGridArray"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGridArray.html#methods",
    "href": "api/skill_grid.SkillGridArray.html#methods",
    "title": "skill_grid.SkillGridArray",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nplot\nwrapper for xArray DataArray plot function\n\n\n\n\n\nskill_grid.SkillGridArray.plot(**kwargs)\nwrapper for xArray DataArray plot function\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n**kwargs\nAny\nkeyword arguments passed to xr.DataArray plot() e.g. figsize\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; gs = cc.gridded_skill()\n&gt;&gt;&gt; gs[\"bias\"].plot()\n&gt;&gt;&gt; gs.sel(model='SW_1').rmse.plot()\n&gt;&gt;&gt; gs.r2.plot(cmap='YlOrRd', figsize=(10,10))",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGridArray"
    ]
  },
  {
    "objectID": "api/metrics.html",
    "href": "api/metrics.html",
    "title": "metrics",
    "section": "",
    "text": "metrics\nMetrics for evaluating the difference between a model and an observation.\n\n\n\n\n\nName\nDescription\n\n\n\n\nr2\nCoefficient of determination (R2)\n\n\nrmse\nalias for root_mean_squared_error\n\n\nroot_mean_squared_error\nRoot Mean Squared Error (RMSE)\n\n\nc_rmse\nalias for circular root mean squared error\n\n\nc_root_mean_squared_error\nCircular root mean squared error\n\n\nurmse\nUnbiased Root Mean Squared Error (uRMSE)\n\n\nc_urmse\nalias for circular unbiased root mean squared error\n\n\nc_unbiased_root_mean_squared_error\nCircular unbiased root mean squared error\n\n\nbias\nBias (mean error)\n\n\nc_bias\nCircular bias (mean error)\n\n\nmae\nalias for mean_absolute_error\n\n\nmean_absolute_error\nMean Absolute Error (MAE)\n\n\nc_mae\nalias for circular mean absolute error\n\n\nc_mean_absolute_error\nCircular mean absolute error\n\n\nmape\nalias for mean_absolute_percentage_error\n\n\ncc\nalias for corrcoef\n\n\ncorrcoef\nPearson’s Correlation coefficient (CC)\n\n\nrho\nalias for spearmanr\n\n\nspearmanr\nSpearman rank correlation coefficient\n\n\nev\nalias for explained_variance\n\n\nexplained_variance\nEV: Explained variance\n\n\nnse\nalias for nash_sutcliffe_efficiency\n\n\nnash_sutcliffe_efficiency\nNash-Sutcliffe Efficiency (NSE)\n\n\nkge\nalias for kling_gupta_efficiency\n\n\nkling_gupta_efficiency\nKling-Gupta Efficiency (KGE)\n\n\nmax_error\nMax (absolute) error\n\n\nc_max_error\nCircular max error\n\n\nmef\nalias for model_efficiency_factor\n\n\nmodel_efficiency_factor\nModel Efficiency Factor (MEF)\n\n\nsi\nalias for scatter_index\n\n\nscatter_index\nScatter index (SI)\n\n\npr\nalias for peak_ratio\n\n\npeak_ratio\nPeak Ratio\n\n\nwillmott\nWillmott’s Index of Agreement\n\n\nhit_ratio\nFraction within obs ± acceptable deviation\n\n\nlin_slope\nSlope of the regression line.\n\n\n\n\n\nmetrics.r2(obs, model)\nCoefficient of determination (R2)\nPronounced ‘R-squared’; the proportion of the variation in the dependent variable that is predictable from the independent variable(s), i.e. the proportion of explained variance.\n\\[\nR^2 = 1 - \\frac{\\sum_{i=1}^n (model_i - obs_i)^2}\n                {\\sum_{i=1}^n (obs_i - \\overline {obs})^2}\n\\]\nRange: \\((-\\infty, 1]\\); Best: 1\n\n\nr2 = nash_sutcliffe_efficiency(nse)\n\n\n\n&gt;&gt;&gt; obs = np.array([1.0,1.1,1.2,1.3,1.4])\n&gt;&gt;&gt; model = np.array([1.09, 1.16, 1.3 , 1.38, 1.49])\n&gt;&gt;&gt; r2(obs,model)\nnp.float64(0.6379999999999998)\n\n\n\n\nmetrics.rmse(obs, model, weights=None, unbiased=False)\nalias for root_mean_squared_error\n\n\n\nmetrics.root_mean_squared_error(obs, model, weights=None, unbiased=False)\nRoot Mean Squared Error (RMSE)\n\\[\nres_i = model_i - obs_i\n\\]\n\\[\nRMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_i^2}\n\\]\nUnbiased version:\n\\[\nres_{u,i} = res_i - \\overline {res}\n\\]\n\\[\nuRMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2}\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.c_rmse(obs, model, weights=None)\nalias for circular root mean squared error\n\n\n\nmetrics.c_root_mean_squared_error(obs, model, weights=None)\nCircular root mean squared error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\nweights\nArrayLike\nWeights, by default None\nNone\n\n\n\n\n\n\nRange: [0, 180]; Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular root mean squared error\n\n\n\n\n\n\n\nmetrics.urmse(obs, model, weights=None)\nUnbiased Root Mean Squared Error (uRMSE)\n\\[\nres_i = model_i - obs_i\n\\]\n\\[\nres_{u,i} = res_i - \\overline {res}\n\\]\n\\[\nuRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2}\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\nroot_mean_squared_error\n\n\n\n\nmetrics.c_urmse(obs, model, weights=None)\nalias for circular unbiased root mean squared error\n\n\n\nmetrics.c_unbiased_root_mean_squared_error(obs, model, weights=None)\nCircular unbiased root mean squared error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\nweights\nArrayLike\nWeights, by default None\nNone\n\n\n\n\n\n\nRange: [0, 180]; Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular unbiased root mean squared error\n\n\n\n\n\n\n\nmetrics.bias(obs, model)\nBias (mean error)\n\\[\nbias=\\frac{1}{n}\\sum_{i=1}^n (model_i - obs_i)\n\\]\nRange: \\((-\\infty, \\infty)\\); Best: 0\n\n\n\nmetrics.c_bias(obs, model)\nCircular bias (mean error)\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\n\n\n\n\nRange: \\([-180., 180.]\\); Best: 0.\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular bias\n\n\n\n\n\n\n&gt;&gt;&gt; obs = np.array([10., 355., 170.])\n&gt;&gt;&gt; mod = np.array([20., 5., -180.])\n&gt;&gt;&gt; c_bias(obs, mod)\nnp.float64(10.0)\n\n\n\n\nmetrics.mae(obs, model, weights=None)\nalias for mean_absolute_error\n\n\n\nmetrics.mean_absolute_error(obs, model, weights=None)\nMean Absolute Error (MAE)\n\\[\nMAE=\\frac{1}{n}\\sum_{i=1}^n|model_i - obs_i|\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.c_mae(obs, model, weights=None)\nalias for circular mean absolute error\n\n\n\nmetrics.c_mean_absolute_error(obs, model, weights=None)\nCircular mean absolute error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\nweights\nArrayLike\nWeights, by default None\nNone\n\n\n\n\n\n\nRange: [0, 180]; Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular mean absolute error\n\n\n\n\n\n\n\nmetrics.mape(obs, model)\nalias for mean_absolute_percentage_error\n\n\n\nmetrics.cc(obs, model, weights=None)\nalias for corrcoef\n\n\n\nmetrics.corrcoef(obs, model, weights=None)\nPearson’s Correlation coefficient (CC)\n\\[\nCC = \\frac{\\sum_{i=1}^n (model_i - \\overline{model})(obs_i - \\overline{obs}) }\n               {\\sqrt{\\sum_{i=1}^n (model_i - \\overline{model})^2}\n                \\sqrt{\\sum_{i=1}^n (obs_i - \\overline{obs})^2} }\n\\]\nRange: [-1, 1]; Best: 1\n\n\nspearmanr np.corrcoef\n\n\n\n\nmetrics.rho(obs, model)\nalias for spearmanr\n\n\n\nmetrics.spearmanr(obs, model)\nSpearman rank correlation coefficient\nThe rank correlation coefficient is similar to the Pearson correlation coefficient but applied to ranked quantities and is useful to quantify a monotonous relationship\n\\[\n\\rho = \\frac{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})(robs_i - \\overline{robs}) }\n                {\\sqrt{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})^2}\n                \\sqrt{\\sum_{i=1}^n (robs_i - \\overline{robs})^2} }\n\\]\nRange: [-1, 1]; Best: 1\n\n\n&gt;&gt;&gt; obs = np.linspace(-20, 20, 100)\n&gt;&gt;&gt; mod = np.tanh(obs)\n&gt;&gt;&gt; rho(obs, mod)\nnp.float64(0.9999759973116955)\n&gt;&gt;&gt; spearmanr(obs, mod)\nnp.float64(0.9999759973116955)\n\n\n\ncorrcoef\n\n\n\n\nmetrics.ev(obs, model)\nalias for explained_variance\n\n\n\nmetrics.explained_variance(obs, model)\nEV: Explained variance\nEV is the explained variance and measures the proportion [0 - 1] to which the model accounts for the variation (dispersion) of the observations.\nIn cases with no bias, EV is equal to r2\n\\[\n\\frac{ \\sum_{i=1}^n (obs_i - \\overline{obs})^2 -\n\\sum_{i=1}^n \\left( (obs_i - \\overline{obs}) -\n(model_i - \\overline{model}) \\right)^2}{\\sum_{i=1}^n\n(obs_i - \\overline{obs})^2}\n\\]\nRange: [0, 1]; Best: 1\n\n\nr2\n\n\n\n\nmetrics.nse(obs, model)\nalias for nash_sutcliffe_efficiency\n\n\n\nmetrics.nash_sutcliffe_efficiency(obs, model)\nNash-Sutcliffe Efficiency (NSE)\n\\[\nNSE = 1 - \\frac {\\sum _{i=1}^{n}\\left(model_{i} - obs_{i}\\right)^{2}}\n                {\\sum_{i=1}^{n}\\left(obs_{i} - {\\overline{obs}}\\right)^{2}}\n\\]\nRange: \\((-\\infty, 1]\\); Best: 1\n\n\nr2 = nash_sutcliffe_efficiency(nse)\nNash, J. E.; Sutcliffe, J. V. (1970). “River flow forecasting through conceptual models part I — A discussion of principles”. Journal of Hydrology. 10 (3): 282–290. https://doi.org/10.1016/0022-1694(70)90255-6\n\n\n\n\nmetrics.kge(obs, model)\nalias for kling_gupta_efficiency\n\n\n\nmetrics.kling_gupta_efficiency(obs, model)\nKling-Gupta Efficiency (KGE)\n\\[\nKGE = 1 - \\sqrt{(r-1)^2 + \\left(\\frac{\\sigma_{mod}}{\\sigma_{obs}} - 1\\right)^2 +\n                            \\left(\\frac{\\mu_{mod}}{\\mu_{obs}} - 1\\right)^2 }\n\\]\nwhere \\(r\\) is the pearson correlation coefficient, \\(\\mu_{obs},\\mu_{mod}\\) and \\(\\sigma_{obs},\\sigma_{mod}\\) is the mean and standard deviation of observations and model.\nRange: \\((-\\infty, 1]\\); Best: 1\n\n\nGupta, H. V., Kling, H., Yilmaz, K. K. and Martinez, G. F., (2009), Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling, J. Hydrol., 377(1-2), 80-91 https://doi.org/10.1016/j.jhydrol.2009.08.003\nKnoben, W. J. M., Freer, J. E., and Woods, R. A. (2019) Technical note: Inherent benchmark or not? Comparing Nash–Sutcliffe and Kling–Gupta efficiency scores, Hydrol. Earth Syst. Sci., 23, 4323-4331 https://doi.org/10.5194/hess-23-4323-2019\n\n\n\n\nmetrics.max_error(obs, model)\nMax (absolute) error\n\\[\nmax_{error} = max(|model_i - obs_i|)\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.c_max_error(obs, model)\nCircular max error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\n\n\n\n\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular max error\n\n\n\n\n\n\n&gt;&gt;&gt; obs = np.array([10., 350., 10.])\n&gt;&gt;&gt; mod = np.array([20., 10., 350.])\n&gt;&gt;&gt; c_max_error(obs, mod)\nnp.float64(20.0)\n\n\n\n\nmetrics.mef(obs, model)\nalias for model_efficiency_factor\n\n\n\nmetrics.model_efficiency_factor(obs, model)\nModel Efficiency Factor (MEF)\nScale independent RMSE, standardized by Stdev of observations\n\\[\nMEF = \\frac{RMSE}{STDEV}=\\frac{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}}\n                                {\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(obs_i - \\overline{obs})^2}}=\\sqrt{1-NSE}\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\nnash_sutcliffe_efficiency root_mean_squared_error\n\n\n\n\nmetrics.si(obs, model)\nalias for scatter_index\n\n\n\nmetrics.scatter_index(obs, model)\nScatter index (SI)\nWhich is the same as the unbiased-RMSE normalized by the absolute mean of the observations.\n\\[\n\\frac{ \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left( (model_i - \\overline {model}) - (obs_i - \\overline {obs}) \\right)^2} }\n{\\frac{1}{n} \\sum_{i=1}^n | obs_i | }\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.pr(obs, model, inter_event_level=0.7, AAP=2, inter_event_time='36h')\nalias for peak_ratio\n\n\n\nmetrics.peak_ratio(\n    obs,\n    model,\n    inter_event_level=0.7,\n    AAP=2,\n    inter_event_time='36h',\n)\nPeak Ratio\nPR is the mean of the largest-N individual ratios of identified peaks in the model / identified peaks in the measurements (N number of events defined by AAP). PR is calculated only for the joint-events, ie, events that ocurr simulateneously within a window +/- 0.5*inter_event_time.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninter_event_level\nfloat\nInter-event level threshold (default: 0.7).\n0.7\n\n\nAAP\nUnion[int, float]\nAverage Annual Peaks (ie, Number of peaks per year, on average). (default: 2)\n2\n\n\ninter_event_time\nstr\nMaximum time interval between peaks (default: 36 hours).\n'36h'\n\n\n\n\n\n\n\\(\\frac{\\sum_{i=1}^{N_{joint-peaks}} (\\frac{Peak_{model_i}}{Peak_{obs_i}} )}{N_{joint-peaks}}\\)\nRange: \\([0, \\infty)\\); Best: 1.0\n\n\n\n\nmetrics.willmott(obs, model)\nWillmott’s Index of Agreement\nA scaled representation of the predictive accuracy of the model against observations. A value of 1 indicates a perfect match, and 0 indicates no agreement at all.\n\\[\nwillmott = 1 - \\frac{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}\n                    {\\frac{1}{n} \\sum_{i=1}^n(|model_i - \\overline{obs}| + |obs_i - \\overline{obs}|)^2}\n\\]\nRange: [0, 1]; Best: 1\n\n\n&gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n&gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n&gt;&gt;&gt; willmott(obs, model)\nnp.float64(0.9501403174479723)\n\n\n\nWillmott, C. J. 1981. “On the validation of models”. Physical Geography, 2, 184–194.\n\n\n\n\nmetrics.hit_ratio(obs, model, a=0.1)\nFraction within obs ± acceptable deviation\n\\[\nHR = \\frac{1}{n}\\sum_{i=1}^n I_{|(model_i - obs_i)|} &lt; a\n\\]\nRange: [0, 1]; Best: 1\n\n\n&gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n&gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.05)\nnp.float64(0.2857142857142857)\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.1)\nnp.float64(0.8571428571428571)\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.15)\nnp.float64(1.0)\n\n\n\n\nmetrics.lin_slope(obs, model, reg_method='ols')\nSlope of the regression line.\n\\[\nslope = \\frac{\\sum_{i=1}^n (model_i - \\overline {model})(obs_i - \\overline {obs})}\n                {\\sum_{i=1}^n (obs_i - \\overline {obs})^2}\n\\]\nRange: \\((-\\infty, \\infty )\\); Best: 1",
    "crumbs": [
      "API Reference",
      "Metrics"
    ]
  },
  {
    "objectID": "api/metrics.html#functions",
    "href": "api/metrics.html#functions",
    "title": "metrics",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nr2\nCoefficient of determination (R2)\n\n\nrmse\nalias for root_mean_squared_error\n\n\nroot_mean_squared_error\nRoot Mean Squared Error (RMSE)\n\n\nc_rmse\nalias for circular root mean squared error\n\n\nc_root_mean_squared_error\nCircular root mean squared error\n\n\nurmse\nUnbiased Root Mean Squared Error (uRMSE)\n\n\nc_urmse\nalias for circular unbiased root mean squared error\n\n\nc_unbiased_root_mean_squared_error\nCircular unbiased root mean squared error\n\n\nbias\nBias (mean error)\n\n\nc_bias\nCircular bias (mean error)\n\n\nmae\nalias for mean_absolute_error\n\n\nmean_absolute_error\nMean Absolute Error (MAE)\n\n\nc_mae\nalias for circular mean absolute error\n\n\nc_mean_absolute_error\nCircular mean absolute error\n\n\nmape\nalias for mean_absolute_percentage_error\n\n\ncc\nalias for corrcoef\n\n\ncorrcoef\nPearson’s Correlation coefficient (CC)\n\n\nrho\nalias for spearmanr\n\n\nspearmanr\nSpearman rank correlation coefficient\n\n\nev\nalias for explained_variance\n\n\nexplained_variance\nEV: Explained variance\n\n\nnse\nalias for nash_sutcliffe_efficiency\n\n\nnash_sutcliffe_efficiency\nNash-Sutcliffe Efficiency (NSE)\n\n\nkge\nalias for kling_gupta_efficiency\n\n\nkling_gupta_efficiency\nKling-Gupta Efficiency (KGE)\n\n\nmax_error\nMax (absolute) error\n\n\nc_max_error\nCircular max error\n\n\nmef\nalias for model_efficiency_factor\n\n\nmodel_efficiency_factor\nModel Efficiency Factor (MEF)\n\n\nsi\nalias for scatter_index\n\n\nscatter_index\nScatter index (SI)\n\n\npr\nalias for peak_ratio\n\n\npeak_ratio\nPeak Ratio\n\n\nwillmott\nWillmott’s Index of Agreement\n\n\nhit_ratio\nFraction within obs ± acceptable deviation\n\n\nlin_slope\nSlope of the regression line.\n\n\n\n\n\nmetrics.r2(obs, model)\nCoefficient of determination (R2)\nPronounced ‘R-squared’; the proportion of the variation in the dependent variable that is predictable from the independent variable(s), i.e. the proportion of explained variance.\n\\[\nR^2 = 1 - \\frac{\\sum_{i=1}^n (model_i - obs_i)^2}\n                {\\sum_{i=1}^n (obs_i - \\overline {obs})^2}\n\\]\nRange: \\((-\\infty, 1]\\); Best: 1\n\n\nr2 = nash_sutcliffe_efficiency(nse)\n\n\n\n&gt;&gt;&gt; obs = np.array([1.0,1.1,1.2,1.3,1.4])\n&gt;&gt;&gt; model = np.array([1.09, 1.16, 1.3 , 1.38, 1.49])\n&gt;&gt;&gt; r2(obs,model)\nnp.float64(0.6379999999999998)\n\n\n\n\nmetrics.rmse(obs, model, weights=None, unbiased=False)\nalias for root_mean_squared_error\n\n\n\nmetrics.root_mean_squared_error(obs, model, weights=None, unbiased=False)\nRoot Mean Squared Error (RMSE)\n\\[\nres_i = model_i - obs_i\n\\]\n\\[\nRMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_i^2}\n\\]\nUnbiased version:\n\\[\nres_{u,i} = res_i - \\overline {res}\n\\]\n\\[\nuRMSE=\\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2}\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.c_rmse(obs, model, weights=None)\nalias for circular root mean squared error\n\n\n\nmetrics.c_root_mean_squared_error(obs, model, weights=None)\nCircular root mean squared error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\nweights\nArrayLike\nWeights, by default None\nNone\n\n\n\n\n\n\nRange: [0, 180]; Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular root mean squared error\n\n\n\n\n\n\n\nmetrics.urmse(obs, model, weights=None)\nUnbiased Root Mean Squared Error (uRMSE)\n\\[\nres_i = model_i - obs_i\n\\]\n\\[\nres_{u,i} = res_i - \\overline {res}\n\\]\n\\[\nuRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n res_{u,i}^2}\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\nroot_mean_squared_error\n\n\n\n\nmetrics.c_urmse(obs, model, weights=None)\nalias for circular unbiased root mean squared error\n\n\n\nmetrics.c_unbiased_root_mean_squared_error(obs, model, weights=None)\nCircular unbiased root mean squared error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\nweights\nArrayLike\nWeights, by default None\nNone\n\n\n\n\n\n\nRange: [0, 180]; Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular unbiased root mean squared error\n\n\n\n\n\n\n\nmetrics.bias(obs, model)\nBias (mean error)\n\\[\nbias=\\frac{1}{n}\\sum_{i=1}^n (model_i - obs_i)\n\\]\nRange: \\((-\\infty, \\infty)\\); Best: 0\n\n\n\nmetrics.c_bias(obs, model)\nCircular bias (mean error)\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\n\n\n\n\nRange: \\([-180., 180.]\\); Best: 0.\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular bias\n\n\n\n\n\n\n&gt;&gt;&gt; obs = np.array([10., 355., 170.])\n&gt;&gt;&gt; mod = np.array([20., 5., -180.])\n&gt;&gt;&gt; c_bias(obs, mod)\nnp.float64(10.0)\n\n\n\n\nmetrics.mae(obs, model, weights=None)\nalias for mean_absolute_error\n\n\n\nmetrics.mean_absolute_error(obs, model, weights=None)\nMean Absolute Error (MAE)\n\\[\nMAE=\\frac{1}{n}\\sum_{i=1}^n|model_i - obs_i|\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.c_mae(obs, model, weights=None)\nalias for circular mean absolute error\n\n\n\nmetrics.c_mean_absolute_error(obs, model, weights=None)\nCircular mean absolute error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\nweights\nArrayLike\nWeights, by default None\nNone\n\n\n\n\n\n\nRange: [0, 180]; Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular mean absolute error\n\n\n\n\n\n\n\nmetrics.mape(obs, model)\nalias for mean_absolute_percentage_error\n\n\n\nmetrics.cc(obs, model, weights=None)\nalias for corrcoef\n\n\n\nmetrics.corrcoef(obs, model, weights=None)\nPearson’s Correlation coefficient (CC)\n\\[\nCC = \\frac{\\sum_{i=1}^n (model_i - \\overline{model})(obs_i - \\overline{obs}) }\n               {\\sqrt{\\sum_{i=1}^n (model_i - \\overline{model})^2}\n                \\sqrt{\\sum_{i=1}^n (obs_i - \\overline{obs})^2} }\n\\]\nRange: [-1, 1]; Best: 1\n\n\nspearmanr np.corrcoef\n\n\n\n\nmetrics.rho(obs, model)\nalias for spearmanr\n\n\n\nmetrics.spearmanr(obs, model)\nSpearman rank correlation coefficient\nThe rank correlation coefficient is similar to the Pearson correlation coefficient but applied to ranked quantities and is useful to quantify a monotonous relationship\n\\[\n\\rho = \\frac{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})(robs_i - \\overline{robs}) }\n                {\\sqrt{\\sum_{i=1}^n (rmodel_i - \\overline{rmodel})^2}\n                \\sqrt{\\sum_{i=1}^n (robs_i - \\overline{robs})^2} }\n\\]\nRange: [-1, 1]; Best: 1\n\n\n&gt;&gt;&gt; obs = np.linspace(-20, 20, 100)\n&gt;&gt;&gt; mod = np.tanh(obs)\n&gt;&gt;&gt; rho(obs, mod)\nnp.float64(0.9999759973116955)\n&gt;&gt;&gt; spearmanr(obs, mod)\nnp.float64(0.9999759973116955)\n\n\n\ncorrcoef\n\n\n\n\nmetrics.ev(obs, model)\nalias for explained_variance\n\n\n\nmetrics.explained_variance(obs, model)\nEV: Explained variance\nEV is the explained variance and measures the proportion [0 - 1] to which the model accounts for the variation (dispersion) of the observations.\nIn cases with no bias, EV is equal to r2\n\\[\n\\frac{ \\sum_{i=1}^n (obs_i - \\overline{obs})^2 -\n\\sum_{i=1}^n \\left( (obs_i - \\overline{obs}) -\n(model_i - \\overline{model}) \\right)^2}{\\sum_{i=1}^n\n(obs_i - \\overline{obs})^2}\n\\]\nRange: [0, 1]; Best: 1\n\n\nr2\n\n\n\n\nmetrics.nse(obs, model)\nalias for nash_sutcliffe_efficiency\n\n\n\nmetrics.nash_sutcliffe_efficiency(obs, model)\nNash-Sutcliffe Efficiency (NSE)\n\\[\nNSE = 1 - \\frac {\\sum _{i=1}^{n}\\left(model_{i} - obs_{i}\\right)^{2}}\n                {\\sum_{i=1}^{n}\\left(obs_{i} - {\\overline{obs}}\\right)^{2}}\n\\]\nRange: \\((-\\infty, 1]\\); Best: 1\n\n\nr2 = nash_sutcliffe_efficiency(nse)\nNash, J. E.; Sutcliffe, J. V. (1970). “River flow forecasting through conceptual models part I — A discussion of principles”. Journal of Hydrology. 10 (3): 282–290. https://doi.org/10.1016/0022-1694(70)90255-6\n\n\n\n\nmetrics.kge(obs, model)\nalias for kling_gupta_efficiency\n\n\n\nmetrics.kling_gupta_efficiency(obs, model)\nKling-Gupta Efficiency (KGE)\n\\[\nKGE = 1 - \\sqrt{(r-1)^2 + \\left(\\frac{\\sigma_{mod}}{\\sigma_{obs}} - 1\\right)^2 +\n                            \\left(\\frac{\\mu_{mod}}{\\mu_{obs}} - 1\\right)^2 }\n\\]\nwhere \\(r\\) is the pearson correlation coefficient, \\(\\mu_{obs},\\mu_{mod}\\) and \\(\\sigma_{obs},\\sigma_{mod}\\) is the mean and standard deviation of observations and model.\nRange: \\((-\\infty, 1]\\); Best: 1\n\n\nGupta, H. V., Kling, H., Yilmaz, K. K. and Martinez, G. F., (2009), Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling, J. Hydrol., 377(1-2), 80-91 https://doi.org/10.1016/j.jhydrol.2009.08.003\nKnoben, W. J. M., Freer, J. E., and Woods, R. A. (2019) Technical note: Inherent benchmark or not? Comparing Nash–Sutcliffe and Kling–Gupta efficiency scores, Hydrol. Earth Syst. Sci., 23, 4323-4331 https://doi.org/10.5194/hess-23-4323-2019\n\n\n\n\nmetrics.max_error(obs, model)\nMax (absolute) error\n\\[\nmax_{error} = max(|model_i - obs_i|)\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.c_max_error(obs, model)\nCircular max error\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nArrayLike\nObservation in degrees (0, 360)\nrequired\n\n\nmodel\nArrayLike\nModel in degrees (0, 360)\nrequired\n\n\n\n\n\n\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nfloat\nCircular max error\n\n\n\n\n\n\n&gt;&gt;&gt; obs = np.array([10., 350., 10.])\n&gt;&gt;&gt; mod = np.array([20., 10., 350.])\n&gt;&gt;&gt; c_max_error(obs, mod)\nnp.float64(20.0)\n\n\n\n\nmetrics.mef(obs, model)\nalias for model_efficiency_factor\n\n\n\nmetrics.model_efficiency_factor(obs, model)\nModel Efficiency Factor (MEF)\nScale independent RMSE, standardized by Stdev of observations\n\\[\nMEF = \\frac{RMSE}{STDEV}=\\frac{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}}\n                                {\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(obs_i - \\overline{obs})^2}}=\\sqrt{1-NSE}\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\nnash_sutcliffe_efficiency root_mean_squared_error\n\n\n\n\nmetrics.si(obs, model)\nalias for scatter_index\n\n\n\nmetrics.scatter_index(obs, model)\nScatter index (SI)\nWhich is the same as the unbiased-RMSE normalized by the absolute mean of the observations.\n\\[\n\\frac{ \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left( (model_i - \\overline {model}) - (obs_i - \\overline {obs}) \\right)^2} }\n{\\frac{1}{n} \\sum_{i=1}^n | obs_i | }\n\\]\nRange: \\([0, \\infty)\\); Best: 0\n\n\n\nmetrics.pr(obs, model, inter_event_level=0.7, AAP=2, inter_event_time='36h')\nalias for peak_ratio\n\n\n\nmetrics.peak_ratio(\n    obs,\n    model,\n    inter_event_level=0.7,\n    AAP=2,\n    inter_event_time='36h',\n)\nPeak Ratio\nPR is the mean of the largest-N individual ratios of identified peaks in the model / identified peaks in the measurements (N number of events defined by AAP). PR is calculated only for the joint-events, ie, events that ocurr simulateneously within a window +/- 0.5*inter_event_time.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninter_event_level\nfloat\nInter-event level threshold (default: 0.7).\n0.7\n\n\nAAP\nUnion[int, float]\nAverage Annual Peaks (ie, Number of peaks per year, on average). (default: 2)\n2\n\n\ninter_event_time\nstr\nMaximum time interval between peaks (default: 36 hours).\n'36h'\n\n\n\n\n\n\n\\(\\frac{\\sum_{i=1}^{N_{joint-peaks}} (\\frac{Peak_{model_i}}{Peak_{obs_i}} )}{N_{joint-peaks}}\\)\nRange: \\([0, \\infty)\\); Best: 1.0\n\n\n\n\nmetrics.willmott(obs, model)\nWillmott’s Index of Agreement\nA scaled representation of the predictive accuracy of the model against observations. A value of 1 indicates a perfect match, and 0 indicates no agreement at all.\n\\[\nwillmott = 1 - \\frac{\\frac{1}{n} \\sum_{i=1}^n(model_i - obs_i)^2}\n                    {\\frac{1}{n} \\sum_{i=1}^n(|model_i - \\overline{obs}| + |obs_i - \\overline{obs}|)^2}\n\\]\nRange: [0, 1]; Best: 1\n\n\n&gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n&gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n&gt;&gt;&gt; willmott(obs, model)\nnp.float64(0.9501403174479723)\n\n\n\nWillmott, C. J. 1981. “On the validation of models”. Physical Geography, 2, 184–194.\n\n\n\n\nmetrics.hit_ratio(obs, model, a=0.1)\nFraction within obs ± acceptable deviation\n\\[\nHR = \\frac{1}{n}\\sum_{i=1}^n I_{|(model_i - obs_i)|} &lt; a\n\\]\nRange: [0, 1]; Best: 1\n\n\n&gt;&gt;&gt; obs = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3])\n&gt;&gt;&gt; model = np.array([1.02, 1.16, 1.3, 1.38, 1.49, 1.45, 1.32])\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.05)\nnp.float64(0.2857142857142857)\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.1)\nnp.float64(0.8571428571428571)\n&gt;&gt;&gt; hit_ratio(obs, model, a=0.15)\nnp.float64(1.0)\n\n\n\n\nmetrics.lin_slope(obs, model, reg_method='ols')\nSlope of the regression line.\n\\[\nslope = \\frac{\\sum_{i=1}^n (model_i - \\overline {model})(obs_i - \\overline {obs})}\n                {\\sum_{i=1}^n (obs_i - \\overline {obs})^2}\n\\]\nRange: \\((-\\infty, \\infty )\\); Best: 1",
    "crumbs": [
      "API Reference",
      "Metrics"
    ]
  },
  {
    "objectID": "api/skill.SkillArrayPlotter.html",
    "href": "api/skill.SkillArrayPlotter.html",
    "title": "skill.SkillArrayPlotter",
    "section": "",
    "text": "skill.SkillArrayPlotter(self, skillarray)\nSkillArrayPlotter object for visualization of a single metric (SkillArray)\n\nplot.line() : line plot\nplot.bar() : bar chart\nplot.barh() : horizontal bar chart\nplot.grid() : colored grid\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nbar\nPlot statistic as bar chart using pd.DataFrame.plot.bar()\n\n\nbarh\nPlot statistic as horizontal bar chart using pd.DataFrame.plot.barh()\n\n\ngrid\nPlot statistic as a colored grid, optionally with values in the cells.\n\n\nline\nPlot statistic as a lines using pd.DataFrame.plot.line()\n\n\n\n\n\nskill.SkillArrayPlotter.bar(level=0, **kwargs)\nPlot statistic as bar chart using pd.DataFrame.plot.bar()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint or str\nlevel to unstack, by default 0\n0\n\n\n**kwargs\nAny\nkey word arguments to be pased to pd.DataFrame.plot.bar() e.g. color, title, figsize, …\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxesSubplot\n\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.bar()\n&gt;&gt;&gt; sk.plot.bar(level=\"observation\")\n&gt;&gt;&gt; sk.plot.bar(title=\"Root Mean Squared Error\")\n&gt;&gt;&gt; sk.plot.bar(color=[\"red\",\"blue\"])\n\n\n\n\nskill.SkillArrayPlotter.barh(level=0, **kwargs)\nPlot statistic as horizontal bar chart using pd.DataFrame.plot.barh()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint or str\nlevel to unstack, by default 0\n0\n\n\n**kwargs\nAny\nkey word arguments to be passed to pd.DataFrame.plot.barh() e.g. color, title, figsize, …\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxesSubplot\n\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.barh()\n&gt;&gt;&gt; sk.plot.barh(level=\"observation\")\n&gt;&gt;&gt; sk.plot.barh(title=\"Root Mean Squared Error\")\n\n\n\n\nskill.SkillArrayPlotter.grid(\n    show_numbers=True,\n    precision=3,\n    fmt=None,\n    ax=None,\n    figsize=None,\n    title=None,\n    cmap=None,\n)\nPlot statistic as a colored grid, optionally with values in the cells.\nPrimarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nshow_numbers\nbool\nshould values of the static be shown in the cells?, by default True if False, a colorbar will be displayed instead\nTrue\n\n\nprecision\nint\nnumber of decimals if show_numbers, by default 3\n3\n\n\nfmt\nstr\nformat string, e.g. “.0%” to show value as percentage\nNone\n\n\nax\nAxes\nmatplotlib axes, by default None\nNone\n\n\nfigsize\nTuple(float, float)\nfigure size, by default None\nNone\n\n\ntitle\nstr\nplot title, by default name of statistic\nNone\n\n\ncmap\nstr\ncolormap, by default “OrRd” (“coolwarm” if bias)\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxesSubplot\n\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.grid()\n&gt;&gt;&gt; sk.plot.grid(show_numbers=False, cmap=\"magma\")\n&gt;&gt;&gt; sk.plot.grid(precision=1)\n&gt;&gt;&gt; sk.plot.grid(fmt=\".0%\", title=\"Root Mean Squared Error\")\n\n\n\n\nskill.SkillArrayPlotter.line(level=0, **kwargs)\nPlot statistic as a lines using pd.DataFrame.plot.line()\nPrimarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint or str\nlevel to unstack, by default 0\n0\n\n\n**kwargs\nAny\nkey word arguments to be pased to pd.DataFrame.plot.line() e.g. marker, title, figsize, …\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.line()\n&gt;&gt;&gt; sk.plot.line(marker=\"o\", linestyle=':')\n&gt;&gt;&gt; sk.plot.line(color=['0.2', '0.4', '0.6'])",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillArrayPlotter"
    ]
  },
  {
    "objectID": "api/skill.SkillArrayPlotter.html#methods",
    "href": "api/skill.SkillArrayPlotter.html#methods",
    "title": "skill.SkillArrayPlotter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbar\nPlot statistic as bar chart using pd.DataFrame.plot.bar()\n\n\nbarh\nPlot statistic as horizontal bar chart using pd.DataFrame.plot.barh()\n\n\ngrid\nPlot statistic as a colored grid, optionally with values in the cells.\n\n\nline\nPlot statistic as a lines using pd.DataFrame.plot.line()\n\n\n\n\n\nskill.SkillArrayPlotter.bar(level=0, **kwargs)\nPlot statistic as bar chart using pd.DataFrame.plot.bar()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint or str\nlevel to unstack, by default 0\n0\n\n\n**kwargs\nAny\nkey word arguments to be pased to pd.DataFrame.plot.bar() e.g. color, title, figsize, …\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxesSubplot\n\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.bar()\n&gt;&gt;&gt; sk.plot.bar(level=\"observation\")\n&gt;&gt;&gt; sk.plot.bar(title=\"Root Mean Squared Error\")\n&gt;&gt;&gt; sk.plot.bar(color=[\"red\",\"blue\"])\n\n\n\n\nskill.SkillArrayPlotter.barh(level=0, **kwargs)\nPlot statistic as horizontal bar chart using pd.DataFrame.plot.barh()\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint or str\nlevel to unstack, by default 0\n0\n\n\n**kwargs\nAny\nkey word arguments to be passed to pd.DataFrame.plot.barh() e.g. color, title, figsize, …\n{}\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxesSubplot\n\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.barh()\n&gt;&gt;&gt; sk.plot.barh(level=\"observation\")\n&gt;&gt;&gt; sk.plot.barh(title=\"Root Mean Squared Error\")\n\n\n\n\nskill.SkillArrayPlotter.grid(\n    show_numbers=True,\n    precision=3,\n    fmt=None,\n    ax=None,\n    figsize=None,\n    title=None,\n    cmap=None,\n)\nPlot statistic as a colored grid, optionally with values in the cells.\nPrimarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nshow_numbers\nbool\nshould values of the static be shown in the cells?, by default True if False, a colorbar will be displayed instead\nTrue\n\n\nprecision\nint\nnumber of decimals if show_numbers, by default 3\n3\n\n\nfmt\nstr\nformat string, e.g. “.0%” to show value as percentage\nNone\n\n\nax\nAxes\nmatplotlib axes, by default None\nNone\n\n\nfigsize\nTuple(float, float)\nfigure size, by default None\nNone\n\n\ntitle\nstr\nplot title, by default name of statistic\nNone\n\n\ncmap\nstr\ncolormap, by default “OrRd” (“coolwarm” if bias)\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAxesSubplot\n\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.grid()\n&gt;&gt;&gt; sk.plot.grid(show_numbers=False, cmap=\"magma\")\n&gt;&gt;&gt; sk.plot.grid(precision=1)\n&gt;&gt;&gt; sk.plot.grid(fmt=\".0%\", title=\"Root Mean Squared Error\")\n\n\n\n\nskill.SkillArrayPlotter.line(level=0, **kwargs)\nPlot statistic as a lines using pd.DataFrame.plot.line()\nPrimarily for MultiIndex skill objects, e.g. multiple models and multiple observations\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlevel\nint or str\nlevel to unstack, by default 0\n0\n\n\n**kwargs\nAny\nkey word arguments to be pased to pd.DataFrame.plot.line() e.g. marker, title, figsize, …\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; sk = cc.skill()[\"rmse\"]\n&gt;&gt;&gt; sk.plot.line()\n&gt;&gt;&gt; sk.plot.line(marker=\"o\", linestyle=':')\n&gt;&gt;&gt; sk.plot.line(color=['0.2', '0.4', '0.6'])",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillArrayPlotter"
    ]
  },
  {
    "objectID": "api/plotting.spatial_overview.html",
    "href": "api/plotting.spatial_overview.html",
    "title": "plotting.spatial_overview",
    "section": "",
    "text": "plotting.spatial_overview(obs, mod=None, ax=None, figsize=None, title=None)\nPlot observation points on a map showing the model domain",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.spatial_overview"
    ]
  },
  {
    "objectID": "api/plotting.spatial_overview.html#parameters",
    "href": "api/plotting.spatial_overview.html#parameters",
    "title": "plotting.spatial_overview",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobs\nObservation | Iterable[Observation]\nList of observations to be shown on map\nrequired\n\n\nmod\nDfsuModelResult\nModel domain to be shown as outline\nNone\n\n\nax\n\nAdding to existing axis, instead of creating new fig\nNone\n\n\nfigsize\n(float, float)\nfigure size, by default None\nNone\n\n\ntitle\nOptional[str]\nplot title, default empty\nNone",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.spatial_overview"
    ]
  },
  {
    "objectID": "api/plotting.spatial_overview.html#see-also",
    "href": "api/plotting.spatial_overview.html#see-also",
    "title": "plotting.spatial_overview",
    "section": "See Also",
    "text": "See Also\ntemporal_coverage",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.spatial_overview"
    ]
  },
  {
    "objectID": "api/plotting.spatial_overview.html#returns",
    "href": "api/plotting.spatial_overview.html#returns",
    "title": "plotting.spatial_overview",
    "section": "Returns",
    "text": "Returns\n\n\n\nName\nType\nDescription\n\n\n\n\n\nmatplotlib.axes.Axes\nThe matplotlib axes object",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.spatial_overview"
    ]
  },
  {
    "objectID": "api/plotting.spatial_overview.html#examples",
    "href": "api/plotting.spatial_overview.html#examples",
    "title": "plotting.spatial_overview",
    "section": "Examples",
    "text": "Examples\n\nimport modelskill as ms\nfrom pathlib import Path\np = Path(\"../data/SW\")\n\no1 = ms.PointObservation(p / \"HKNA_Hm0.dfs0\", item=0, x=4.2420, y=52.6887, name=\"HKNA\")\no2 = ms.TrackObservation(p / \"Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\nmr = ms.DfsuModelResult(p / \"HKZN_local_2017_DutchCoast.dfsu\", name='SW_1', item=0)\nms.plotting.spatial_overview([o1, o2], mr)",
    "crumbs": [
      "API Reference",
      "Plotting",
      "plotting.spatial_overview"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGrid.html",
    "href": "api/skill_grid.SkillGrid.html",
    "title": "skill_grid.SkillGrid",
    "section": "",
    "text": "skill_grid.SkillGrid(self, data)\nSpatially gridded skill data.\nGridded skill object for analysis and visualization of spatially gridded skill data. The object wraps the xr.DataSet class which can be accessed from the attribute data.\nThe object contains one or more “arrays” of skill metrics, each corresponding to a single metric (e.g. bias, rmse, r2). The arrays are indexed by the metric name, e.g. ss[\"bias\"] or ss.bias.\n\n\n&gt;&gt;&gt; gs = cc.gridded_skill()\n&gt;&gt;&gt; gs.metrics\n['n', 'bias', 'rmse', 'urmse', 'mae', 'cc', 'si', 'r2']\n&gt;&gt;&gt; gs.mod_names\n['SW_1', 'SW_2']\n&gt;&gt;&gt; gs.sel(model='SW_1').rmse.plot()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncoords\nCoordinates (same as xr.DataSet.coords)\n\n\nmetrics\nList of metrics (=data vars)\n\n\nmod_names\nList of model names\n\n\nobs_names\nList of observation names\n\n\nx\nx-coordinate values\n\n\ny\ny-coordinate values\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsel\nSelect a model from the SkillGrid\n\n\nto_dataframe\nConvert gridded skill data to pandas DataFrame\n\n\n\n\n\nskill_grid.SkillGrid.sel(model)\nSelect a model from the SkillGrid\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr\nName of model to select\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillGrid\nSkillGrid with only the selected model\n\n\n\n\n\n\n\nskill_grid.SkillGrid.to_dataframe()\nConvert gridded skill data to pandas DataFrame\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGrid"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGrid.html#examples",
    "href": "api/skill_grid.SkillGrid.html#examples",
    "title": "skill_grid.SkillGrid",
    "section": "",
    "text": "&gt;&gt;&gt; gs = cc.gridded_skill()\n&gt;&gt;&gt; gs.metrics\n['n', 'bias', 'rmse', 'urmse', 'mae', 'cc', 'si', 'r2']\n&gt;&gt;&gt; gs.mod_names\n['SW_1', 'SW_2']\n&gt;&gt;&gt; gs.sel(model='SW_1').rmse.plot()",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGrid"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGrid.html#attributes",
    "href": "api/skill_grid.SkillGrid.html#attributes",
    "title": "skill_grid.SkillGrid",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncoords\nCoordinates (same as xr.DataSet.coords)\n\n\nmetrics\nList of metrics (=data vars)\n\n\nmod_names\nList of model names\n\n\nobs_names\nList of observation names\n\n\nx\nx-coordinate values\n\n\ny\ny-coordinate values",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGrid"
    ]
  },
  {
    "objectID": "api/skill_grid.SkillGrid.html#methods",
    "href": "api/skill_grid.SkillGrid.html#methods",
    "title": "skill_grid.SkillGrid",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsel\nSelect a model from the SkillGrid\n\n\nto_dataframe\nConvert gridded skill data to pandas DataFrame\n\n\n\n\n\nskill_grid.SkillGrid.sel(model)\nSelect a model from the SkillGrid\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr\nName of model to select\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillGrid\nSkillGrid with only the selected model\n\n\n\n\n\n\n\nskill_grid.SkillGrid.to_dataframe()\nConvert gridded skill data to pandas DataFrame\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame",
    "crumbs": [
      "API Reference",
      "Skill",
      "SkillGrid"
    ]
  },
  {
    "objectID": "api/from_config.html",
    "href": "api/from_config.html",
    "title": "from_config",
    "section": "",
    "text": "from_config(conf, *, relative_path=True)\nLoad ComparerCollection from a config file (or dict)",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_config"
    ]
  },
  {
    "objectID": "api/from_config.html#parameters",
    "href": "api/from_config.html#parameters",
    "title": "from_config",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nconf\nUnion[str, Path, dict]\npath to config file or dict with configuration\nrequired\n\n\nrelative_path\n\nTrue: file paths are relative to configuration file, False: file paths are absolute (relative to the current directory), by default True\nTrue",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_config"
    ]
  },
  {
    "objectID": "api/from_config.html#returns",
    "href": "api/from_config.html#returns",
    "title": "from_config",
    "section": "Returns",
    "text": "Returns\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nA ComparerCollection object from the given configuration",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_config"
    ]
  },
  {
    "objectID": "api/from_config.html#examples",
    "href": "api/from_config.html#examples",
    "title": "from_config",
    "section": "Examples",
    "text": "Examples\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.from_config('../data/conf.yml')\n&gt;&gt;&gt; cc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: Klagshamn - Water Level [m]\n1: Drogden - Water Level [m]",
    "crumbs": [
      "API Reference",
      "Matching",
      "from_config"
    ]
  },
  {
    "objectID": "api/ComparerCollection.html",
    "href": "api/ComparerCollection.html",
    "title": "ComparerCollection",
    "section": "",
    "text": "ComparerCollection(self, comparers)\nCollection of comparers.\nThe ComparerCollection is one of the main objects of the modelskill package. It is a collection of Comparer objects and created either by the match() function, by passing a list of Comparers to the ComparerCollection constructor, or by reading a config file using the from_config() function.\nNOTE: In case of multiple model results with different time coverage, only the overlapping time period will be used! (intersection)\nMain functionality:\n\nselecting/filtering data\n\n__get_item__() - get a single Comparer, e.g., cc[0] or cc['obs1']\nsel()\nquery()\n\nskill assessment\n\nskill()\nmean_skill()\ngridded_skill() (for track observations)\n\nplotting\n\nplot.scatter()\nplot.kde()\nplot.hist()\n\nload/save/export data\n\nload()\nsave()\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncomparers\nlist of Comparer\nlist of comparers\nrequired\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; mr = ms.DfsuModelResult(\"Oresund2D.dfsu\", item=0)\n&gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o2 = ms.PointObservation(\"drogden.dfs0\", item=0, x=355568.0, y=6156863.0)\n&gt;&gt;&gt; cmp1 = ms.match(o1, mr)  # Comparer\n&gt;&gt;&gt; cmp2 = ms.match(o2, mr)  # Comparer\n&gt;&gt;&gt; ccA = ms.ComparerCollection([cmp1, cmp2])\n&gt;&gt;&gt; ccB = ms.match(obs=[o1, o2], mod=mr)\n&gt;&gt;&gt; sk = ccB.skill()\n&gt;&gt;&gt; ccB[\"Klagshamn\"].plot.timeseries()\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nplot\nPlot using the ComparerCollectionPlotter\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nskill\nAggregated skill assessment of model(s)\n\n\nmean_skill\nWeighted mean of skills\n\n\ngridded_skill\nSkill assessment of model(s) on a regular spatial grid.\n\n\nscore\nWeighted mean score of model(s) over all observations\n\n\nrename\nRename observation, model or auxiliary data variables\n\n\nsel\nSelect data based on model, time and/or area.\n\n\nquery\nSelect data based on a query.\n\n\nsave\nSave the ComparerCollection to a zip file.\n\n\nload\nLoad a ComparerCollection from a zip file.\n\n\n\n\n\nComparerCollection.skill(by=None, metrics=None, observed=False)\nAggregated skill assessment of model(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nby\nstr or List[str]\ngroup by, by default [“model”, “observation”] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data. - by attributes, stored in the cc.data.attrs container, e.g.: ‘attrs:obs_provider’ = group by observation provider or ‘attrs:gtype’ = group by geometry type (track or point)\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics (or str), by default modelskill.options.metrics.list\nNone\n\n\nobserved\nbool\nThis only applies if any of the groupers are Categoricals. - True: only show observed values for categorical groupers. - False: show all values for categorical groupers.\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nskill assessment as a SkillTable object\n\n\n\n\n\n\nsel a method for filtering/selecting data\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)\n&gt;&gt;&gt; cc.skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nHKNA         385 -0.20  0.35   0.29  0.25  0.97  0.09  0.99\nEPL           66 -0.08  0.22   0.20  0.18  0.97  0.07  0.99\nc2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n&gt;&gt;&gt; cc.sel(observation='c2', start='2017-10-28').skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nc2            41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n&gt;&gt;&gt; cc.skill(by='freq:D').round(2)\n              n  bias  rmse  urmse   mae    cc    si    r2\n2017-10-27  239 -0.15  0.25   0.21  0.20  0.72  0.10  0.98\n2017-10-28  162 -0.07  0.19   0.18  0.16  0.96  0.06  1.00\n2017-10-29  163 -0.21  0.52   0.47  0.42  0.79  0.11  0.99\n\n\n\n\nComparerCollection.mean_skill(weights=None, metrics=None, **kwargs)\nWeighted mean of skills\nFirst, the skill is calculated per observation, the weighted mean of the skills is then found.\nWarning: This method is NOT the mean skill of all observational points! (mean_skill_points)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nweights\nstr or List(float) or Dict(str, float)\nweighting of observations, by default None - None: use observations weight attribute (if assigned, else “equal”) - “equal”: giving all observations equal weight, - “points”: giving all points equal weight, - list of weights e.g. [0.3, 0.3, 0.4] per observation, - dictionary of observations with special weigths, others will be set to 1.0\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nmean skill assessment as a SkillTable object\n\n\n\n\n\n\nskill skill assessment per observation mean_skill_points skill assessment pooling all observation points together\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mod=HKZN_local)\n&gt;&gt;&gt; cc.mean_skill().round(2)\n              n  bias  rmse  urmse   mae    cc    si    r2\nHKZN_local  564 -0.09  0.31   0.28  0.24  0.97  0.09  0.99\n&gt;&gt;&gt; sk = cc.mean_skill(weights=\"equal\")\n&gt;&gt;&gt; sk = cc.mean_skill(weights=\"points\")\n&gt;&gt;&gt; sk = cc.mean_skill(weights={\"EPL\": 2.0}) # more weight on EPL, others=1.0\n\n\n\n\nComparerCollection.gridded_skill(\n    bins=5,\n    binsize=None,\n    by=None,\n    metrics=None,\n    n_min=None,\n    **kwargs,\n)\nSkill assessment of model(s) on a regular spatial grid.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\ncriteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,[2,3,5])\n5\n\n\nbinsize\nfloat\nbin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y))\nNone\n\n\nby\n(str, List[str])\ngroup by, by default [“model”, “observation”] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data.\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\nn_min\nint\nminimum number of observations in a grid cell; cells with fewer observations get a score of np.nan\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillGrid\nskill assessment as a SkillGrid object\n\n\n\n\n\n\nskill a method for aggregated skill assessment\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)  # with satellite track measurements\n&gt;&gt;&gt; gs = cc.gridded_skill(metrics='bias')\n&gt;&gt;&gt; gs.data\n&lt;xarray.Dataset&gt;\nDimensions:      (x: 5, y: 5)\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n* y            (y) float64 50.6 51.66 52.7 53.75 54.8\nData variables:\n    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n&gt;&gt;&gt; gs = cc.gridded_skill(binsize=0.5)\n&gt;&gt;&gt; gs.data.coords\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n\n\n\n\nComparerCollection.score(metric=mtr.rmse, weights=None, **kwargs)\nWeighted mean score of model(s) over all observations\nWrapping mean_skill() with a single metric.\nNOTE: will take simple mean over different quantities!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nweights\nstr or List(float) or Dict(str, float)\nweighting of observations, by default None - None: use observations weight attribute (if assigned, else “equal”) - “equal”: giving all observations equal weight, - “points”: giving all points equal weight, - list of weights e.g. [0.3, 0.3, 0.4] per observation, - dictionary of observations with special weigths, others will be set to 1.0\nNone\n\n\nmetric\nlist\na single metric from modelskill.metrics, by default rmse\nmtr.rmse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nDict[str, float]\nmean of skills score as a single number (for each model)\n\n\n\n\n\n\nskill skill assessment per observation mean_skill weighted mean of skills assessment mean_skill_points skill assessment pooling all observation points together\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([o1, o2], mod)\n&gt;&gt;&gt; cc.score()\n{'mod': 0.30681206}\n&gt;&gt;&gt; cc.score(weights=[0.1,0.1,0.8])\n{'mod': 0.3383011631797379}\n&gt;&gt;&gt; cc.score(weights='points', metric=\"mape\")\n{'mod': 8.414442957854142}\n\n\n\n\nComparerCollection.rename(mapping)\nRename observation, model or auxiliary data variables\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmapping\ndict\nmapping of old names to new names\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc = ms.match([o1, o2], [mr1, mr2])\n&gt;&gt;&gt; cc.mod_names\n['mr1', 'mr2']\n&gt;&gt;&gt; cc2 = cc.rename({'mr1': 'model1'})\n&gt;&gt;&gt; cc2.mod_names\n['model1', 'mr2']\n\n\n\n\nComparerCollection.sel(\n    model=None,\n    observation=None,\n    quantity=None,\n    start=None,\n    end=None,\n    time=None,\n    area=None,\n    **kwargs,\n)\nSelect data based on model, time and/or area.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr or int or list of str or list of int\nModel name or index. If None, all models are selected.\nNone\n\n\nobservation\nstr or int or list of str or list of int\nObservation name or index. If None, all observations are selected.\nNone\n\n\nquantity\nstr or int or list of str or list of int\nQuantity name or index. If None, all quantities are selected.\nNone\n\n\nstart\nstr or datetime\nStart time. If None, all times are selected.\nNone\n\n\nend\nstr or datetime\nEnd time. If None, all times are selected.\nNone\n\n\ntime\nstr or datetime\nTime. If None, all times are selected.\nNone\n\n\narea\nlist of float\nbbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\nNone\n\n\n**kwargs\nAny\nFiltering by comparer attrs similar to xarray.Dataset.filter_by_attrs e.g. sel(gtype='track') or sel(obs_provider='CMEMS') if at least one comparer has an entry obs_provider with value CMEMS in its attrs container. Multiple kwargs are combined with logical AND.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nNew ComparerCollection with selected data.\n\n\n\n\n\n\n\nComparerCollection.query(query)\nSelect data based on a query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery\nstr\nQuery string. See pandas.DataFrame.query() for details.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nNew ComparerCollection with selected data.\n\n\n\n\n\n\n\nComparerCollection.save(filename)\nSave the ComparerCollection to a zip file.\nEach comparer is stored as a netcdf file in the zip file.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nFilename of the zip file.\nrequired\n\n\n\n\n\n\n&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n\n\n\n\nComparerCollection.load(filename)\nLoad a ComparerCollection from a zip file.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nFilename of the zip file.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nThe loaded ComparerCollection.\n\n\n\n\n\n\n&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n&gt;&gt;&gt; cc2 = ms.ComparerCollection.load(\"my_comparer_collection.msk\")",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollection"
    ]
  },
  {
    "objectID": "api/ComparerCollection.html#parameters",
    "href": "api/ComparerCollection.html#parameters",
    "title": "ComparerCollection",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ncomparers\nlist of Comparer\nlist of comparers\nrequired",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollection"
    ]
  },
  {
    "objectID": "api/ComparerCollection.html#examples",
    "href": "api/ComparerCollection.html#examples",
    "title": "ComparerCollection",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; mr = ms.DfsuModelResult(\"Oresund2D.dfsu\", item=0)\n&gt;&gt;&gt; o1 = ms.PointObservation(\"klagshamn.dfs0\", item=0, x=366844, y=6154291, name=\"Klagshamn\")\n&gt;&gt;&gt; o2 = ms.PointObservation(\"drogden.dfs0\", item=0, x=355568.0, y=6156863.0)\n&gt;&gt;&gt; cmp1 = ms.match(o1, mr)  # Comparer\n&gt;&gt;&gt; cmp2 = ms.match(o2, mr)  # Comparer\n&gt;&gt;&gt; ccA = ms.ComparerCollection([cmp1, cmp2])\n&gt;&gt;&gt; ccB = ms.match(obs=[o1, o2], mod=mr)\n&gt;&gt;&gt; sk = ccB.skill()\n&gt;&gt;&gt; ccB[\"Klagshamn\"].plot.timeseries()",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollection"
    ]
  },
  {
    "objectID": "api/ComparerCollection.html#attributes",
    "href": "api/ComparerCollection.html#attributes",
    "title": "ComparerCollection",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nplot\nPlot using the ComparerCollectionPlotter",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollection"
    ]
  },
  {
    "objectID": "api/ComparerCollection.html#methods",
    "href": "api/ComparerCollection.html#methods",
    "title": "ComparerCollection",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nskill\nAggregated skill assessment of model(s)\n\n\nmean_skill\nWeighted mean of skills\n\n\ngridded_skill\nSkill assessment of model(s) on a regular spatial grid.\n\n\nscore\nWeighted mean score of model(s) over all observations\n\n\nrename\nRename observation, model or auxiliary data variables\n\n\nsel\nSelect data based on model, time and/or area.\n\n\nquery\nSelect data based on a query.\n\n\nsave\nSave the ComparerCollection to a zip file.\n\n\nload\nLoad a ComparerCollection from a zip file.\n\n\n\n\n\nComparerCollection.skill(by=None, metrics=None, observed=False)\nAggregated skill assessment of model(s)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nby\nstr or List[str]\ngroup by, by default [“model”, “observation”] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data. - by attributes, stored in the cc.data.attrs container, e.g.: ‘attrs:obs_provider’ = group by observation provider or ‘attrs:gtype’ = group by geometry type (track or point)\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics (or str), by default modelskill.options.metrics.list\nNone\n\n\nobserved\nbool\nThis only applies if any of the groupers are Categoricals. - True: only show observed values for categorical groupers. - False: show all values for categorical groupers.\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nskill assessment as a SkillTable object\n\n\n\n\n\n\nsel a method for filtering/selecting data\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)\n&gt;&gt;&gt; cc.skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nHKNA         385 -0.20  0.35   0.29  0.25  0.97  0.09  0.99\nEPL           66 -0.08  0.22   0.20  0.18  0.97  0.07  0.99\nc2           113 -0.00  0.35   0.35  0.29  0.97  0.12  0.99\n&gt;&gt;&gt; cc.sel(observation='c2', start='2017-10-28').skill().round(2)\n               n  bias  rmse  urmse   mae    cc    si    r2\nobservation\nc2            41  0.33  0.41   0.25  0.36  0.96  0.06  0.99\n&gt;&gt;&gt; cc.skill(by='freq:D').round(2)\n              n  bias  rmse  urmse   mae    cc    si    r2\n2017-10-27  239 -0.15  0.25   0.21  0.20  0.72  0.10  0.98\n2017-10-28  162 -0.07  0.19   0.18  0.16  0.96  0.06  1.00\n2017-10-29  163 -0.21  0.52   0.47  0.42  0.79  0.11  0.99\n\n\n\n\nComparerCollection.mean_skill(weights=None, metrics=None, **kwargs)\nWeighted mean of skills\nFirst, the skill is calculated per observation, the weighted mean of the skills is then found.\nWarning: This method is NOT the mean skill of all observational points! (mean_skill_points)\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nweights\nstr or List(float) or Dict(str, float)\nweighting of observations, by default None - None: use observations weight attribute (if assigned, else “equal”) - “equal”: giving all observations equal weight, - “points”: giving all points equal weight, - list of weights e.g. [0.3, 0.3, 0.4] per observation, - dictionary of observations with special weigths, others will be set to 1.0\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillTable\nmean skill assessment as a SkillTable object\n\n\n\n\n\n\nskill skill assessment per observation mean_skill_points skill assessment pooling all observation points together\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mod=HKZN_local)\n&gt;&gt;&gt; cc.mean_skill().round(2)\n              n  bias  rmse  urmse   mae    cc    si    r2\nHKZN_local  564 -0.09  0.31   0.28  0.24  0.97  0.09  0.99\n&gt;&gt;&gt; sk = cc.mean_skill(weights=\"equal\")\n&gt;&gt;&gt; sk = cc.mean_skill(weights=\"points\")\n&gt;&gt;&gt; sk = cc.mean_skill(weights={\"EPL\": 2.0}) # more weight on EPL, others=1.0\n\n\n\n\nComparerCollection.gridded_skill(\n    bins=5,\n    binsize=None,\n    by=None,\n    metrics=None,\n    n_min=None,\n    **kwargs,\n)\nSkill assessment of model(s) on a regular spatial grid.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nbins\nint\ncriteria to bin x and y by, argument bins to pd.cut(), default 5 define different bins for x and y a tuple e.g.: bins = 5, bins = (5,[2,3,5])\n5\n\n\nbinsize\nfloat\nbin size for x and y dimension, overwrites bins creates bins with reference to round(mean(x)), round(mean(y))\nNone\n\n\nby\n(str, List[str])\ngroup by, by default [“model”, “observation”] - by column name - by temporal bin of the DateTimeIndex via the freq-argument (using pandas pd.Grouper(freq)), e.g.: ‘freq:M’ = monthly; ‘freq:D’ daily - by the dt accessor of the DateTimeIndex (e.g. ‘dt.month’) using the syntax ‘dt:month’. The dt-argument is different from the freq-argument in that it gives month-of-year rather than month-of-data.\nNone\n\n\nmetrics\nlist\nlist of modelskill.metrics, by default modelskill.options.metrics.list\nNone\n\n\nn_min\nint\nminimum number of observations in a grid cell; cells with fewer observations get a score of np.nan\nNone\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nSkillGrid\nskill assessment as a SkillGrid object\n\n\n\n\n\n\nskill a method for aggregated skill assessment\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([HKNA,EPL,c2], mr)  # with satellite track measurements\n&gt;&gt;&gt; gs = cc.gridded_skill(metrics='bias')\n&gt;&gt;&gt; gs.data\n&lt;xarray.Dataset&gt;\nDimensions:      (x: 5, y: 5)\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -0.436 1.543 3.517 5.492 7.466\n* y            (y) float64 50.6 51.66 52.7 53.75 54.8\nData variables:\n    n            (x, y) int32 3 0 0 14 37 17 50 36 72 ... 0 0 15 20 0 0 0 28 76\n    bias         (x, y) float64 -0.02626 nan nan ... nan 0.06785 -0.1143\n&gt;&gt;&gt; gs = cc.gridded_skill(binsize=0.5)\n&gt;&gt;&gt; gs.data.coords\nCoordinates:\n    observation   'alti'\n* x            (x) float64 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n* y            (y) float64 51.5 52.5 53.5 54.5 55.5 56.5\n\n\n\n\nComparerCollection.score(metric=mtr.rmse, weights=None, **kwargs)\nWeighted mean score of model(s) over all observations\nWrapping mean_skill() with a single metric.\nNOTE: will take simple mean over different quantities!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nweights\nstr or List(float) or Dict(str, float)\nweighting of observations, by default None - None: use observations weight attribute (if assigned, else “equal”) - “equal”: giving all observations equal weight, - “points”: giving all points equal weight, - list of weights e.g. [0.3, 0.3, 0.4] per observation, - dictionary of observations with special weigths, others will be set to 1.0\nNone\n\n\nmetric\nlist\na single metric from modelskill.metrics, by default rmse\nmtr.rmse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nDict[str, float]\nmean of skills score as a single number (for each model)\n\n\n\n\n\n\nskill skill assessment per observation mean_skill weighted mean of skills assessment mean_skill_points skill assessment pooling all observation points together\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; cc = ms.match([o1, o2], mod)\n&gt;&gt;&gt; cc.score()\n{'mod': 0.30681206}\n&gt;&gt;&gt; cc.score(weights=[0.1,0.1,0.8])\n{'mod': 0.3383011631797379}\n&gt;&gt;&gt; cc.score(weights='points', metric=\"mape\")\n{'mod': 8.414442957854142}\n\n\n\n\nComparerCollection.rename(mapping)\nRename observation, model or auxiliary data variables\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmapping\ndict\nmapping of old names to new names\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\n\n\n\n\n\n\n\n&gt;&gt;&gt; cc = ms.match([o1, o2], [mr1, mr2])\n&gt;&gt;&gt; cc.mod_names\n['mr1', 'mr2']\n&gt;&gt;&gt; cc2 = cc.rename({'mr1': 'model1'})\n&gt;&gt;&gt; cc2.mod_names\n['model1', 'mr2']\n\n\n\n\nComparerCollection.sel(\n    model=None,\n    observation=None,\n    quantity=None,\n    start=None,\n    end=None,\n    time=None,\n    area=None,\n    **kwargs,\n)\nSelect data based on model, time and/or area.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\nstr or int or list of str or list of int\nModel name or index. If None, all models are selected.\nNone\n\n\nobservation\nstr or int or list of str or list of int\nObservation name or index. If None, all observations are selected.\nNone\n\n\nquantity\nstr or int or list of str or list of int\nQuantity name or index. If None, all quantities are selected.\nNone\n\n\nstart\nstr or datetime\nStart time. If None, all times are selected.\nNone\n\n\nend\nstr or datetime\nEnd time. If None, all times are selected.\nNone\n\n\ntime\nstr or datetime\nTime. If None, all times are selected.\nNone\n\n\narea\nlist of float\nbbox: [x0, y0, x1, y1] or Polygon. If None, all areas are selected.\nNone\n\n\n**kwargs\nAny\nFiltering by comparer attrs similar to xarray.Dataset.filter_by_attrs e.g. sel(gtype='track') or sel(obs_provider='CMEMS') if at least one comparer has an entry obs_provider with value CMEMS in its attrs container. Multiple kwargs are combined with logical AND.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nNew ComparerCollection with selected data.\n\n\n\n\n\n\n\nComparerCollection.query(query)\nSelect data based on a query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery\nstr\nQuery string. See pandas.DataFrame.query() for details.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nNew ComparerCollection with selected data.\n\n\n\n\n\n\n\nComparerCollection.save(filename)\nSave the ComparerCollection to a zip file.\nEach comparer is stored as a netcdf file in the zip file.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nFilename of the zip file.\nrequired\n\n\n\n\n\n\n&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n\n\n\n\nComparerCollection.load(filename)\nLoad a ComparerCollection from a zip file.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilename\nstr or Path\nFilename of the zip file.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nComparerCollection\nThe loaded ComparerCollection.\n\n\n\n\n\n\n&gt;&gt;&gt; cc = ms.match(obs, mod)\n&gt;&gt;&gt; cc.save(\"my_comparer_collection.msk\")\n&gt;&gt;&gt; cc2 = ms.ComparerCollection.load(\"my_comparer_collection.msk\")",
    "crumbs": [
      "API Reference",
      "Comparison",
      "ComparerCollection"
    ]
  },
  {
    "objectID": "api/model_result.html",
    "href": "api/model_result.html",
    "title": "model_result",
    "section": "",
    "text": "model_result(data, *, aux_items=None, gtype=None, **kwargs)\nA factory function for creating an appropriate object based on the data input.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nDataInputType\nThe data to be used for creating the ModelResult object.\nrequired\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone\n\n\ngtype\nOptional[Literal['point', 'track', 'unstructured', 'grid']]\nThe geometry type of the data. If not specified, it will be guessed from the data.\nNone\n\n\n**kwargs\nAny\nAdditional keyword arguments to be passed to the ModelResult constructor.\n{}\n\n\n\n\n\n\n&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.model_result(\"Oresund2D.dfsu\", item=0)\n&lt;DfsuModelResult&gt; 'Oresund2D'\n&gt;&gt;&gt; ms.model_result(\"ERA5_DutchCoast.nc\", item=\"swh\", name=\"ERA5\")\n&lt;GridModelResult&gt; 'ERA5'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "model_result"
    ]
  },
  {
    "objectID": "api/model_result.html#parameters",
    "href": "api/model_result.html#parameters",
    "title": "model_result",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\nDataInputType\nThe data to be used for creating the ModelResult object.\nrequired\n\n\naux_items\nOptional[list[int | str]]\nAuxiliary items, by default None\nNone\n\n\ngtype\nOptional[Literal['point', 'track', 'unstructured', 'grid']]\nThe geometry type of the data. If not specified, it will be guessed from the data.\nNone\n\n\n**kwargs\nAny\nAdditional keyword arguments to be passed to the ModelResult constructor.\n{}",
    "crumbs": [
      "API Reference",
      "Model Result",
      "model_result"
    ]
  },
  {
    "objectID": "api/model_result.html#examples",
    "href": "api/model_result.html#examples",
    "title": "model_result",
    "section": "",
    "text": "&gt;&gt;&gt; import modelskill as ms\n&gt;&gt;&gt; ms.model_result(\"Oresund2D.dfsu\", item=0)\n&lt;DfsuModelResult&gt; 'Oresund2D'\n&gt;&gt;&gt; ms.model_result(\"ERA5_DutchCoast.nc\", item=\"swh\", name=\"ERA5\")\n&lt;GridModelResult&gt; 'ERA5'",
    "crumbs": [
      "API Reference",
      "Model Result",
      "model_result"
    ]
  },
  {
    "objectID": "api/TimeSeries.html",
    "href": "api/TimeSeries.html",
    "title": "TimeSeries",
    "section": "",
    "text": "TimeSeries(self, data)\nTime series data\n\n\n\n\n\nName\nDescription\n\n\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nTimeSeries.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nTimeSeries.sel(**kwargs)\nSelect data by label\n\n\n\nTimeSeries.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nTimeSeries.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'"
  },
  {
    "objectID": "api/TimeSeries.html#attributes",
    "href": "api/TimeSeries.html#attributes",
    "title": "TimeSeries",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ngtype\nGeometry type\n\n\nn_points\nNumber of data points\n\n\nname\nName of time series (value item name)\n\n\nplot\nPlot using the ComparerPlotter\n\n\nquantity\nQuantity of time series\n\n\ntime\nTime index\n\n\nvalues\nValues as numpy array\n\n\nx\nx-coordinate\n\n\ny\ny-coordinate"
  },
  {
    "objectID": "api/TimeSeries.html#methods",
    "href": "api/TimeSeries.html#methods",
    "title": "TimeSeries",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nequals\nCheck if two TimeSeries are equal\n\n\nsel\nSelect data by label\n\n\nto_dataframe\nConvert matched data to pandas DataFrame\n\n\ntrim\nTrim observation data to a given time interval\n\n\n\n\n\nTimeSeries.equals(other)\nCheck if two TimeSeries are equal\n\n\n\nTimeSeries.sel(**kwargs)\nSelect data by label\n\n\n\nTimeSeries.to_dataframe()\nConvert matched data to pandas DataFrame\nInclude x, y coordinates only if gtype=track\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\ndata as a pandas DataFrame\n\n\n\n\n\n\n\nTimeSeries.trim(start_time=None, end_time=None, buffer='1s')\nTrim observation data to a given time interval\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart_time\npd.Timestamp\nstart time\nNone\n\n\nend_time\npd.Timestamp\nend time\nNone\n\n\nbuffer\nstr\nbuffer time around start and end time, by default “1s”\n'1s'"
  },
  {
    "objectID": "user-guide/index.html",
    "href": "user-guide/index.html",
    "title": "User Guide",
    "section": "",
    "text": "User Guide\nModelSkill compares model results with observations. The workflow can be split in two phases:\n\nMatching - making sure that observations and model results are in the same space and time\nAnalysis - plots and statistics of the matched data\n\nIf the observations and model results are already matched (i.e. are stored in the same data source), the from_matched() function can be used to go directly to the analysis phase. If not, the match() function can be used to match the observations and model results in space and time.",
    "crumbs": [
      "User Guide"
    ]
  },
  {
    "objectID": "user-guide/metrics.html",
    "href": "user-guide/metrics.html",
    "title": "Metrics",
    "section": "",
    "text": "TODO Guide on what metrics are available and how to use them.\nCircular metrics (for directional data with units in degrees):\nThe names in parentheses are shorthand aliases for the different metrics."
  },
  {
    "objectID": "user-guide/metrics.html#examples",
    "href": "user-guide/metrics.html#examples",
    "title": "Metrics",
    "section": "Examples",
    "text": "Examples\n\n\n\nobs = np.array([0.3, 2.1, -1.0]) mod = np.array([0.0, 2.3, 1.0]) bias(obs, mod) np.float64(0.6333333333333332) max_error(obs, mod) np.float64(2.0) rmse(obs, mod) np.float64(1.173314393786536) urmse(obs, mod) np.float64(0.9877021593352702) mae(obs, mod) np.float64(0.8333333333333331) mape(obs, mod) np.float64(103.17460317460316) nse(obs, mod) np.float64(0.14786795048143053) r2(obs, mod) np.float64(0.14786795048143053) mef(obs, mod) np.float64(0.9231099877688299) si(obs, mod) np.float64(0.8715019052958266) spearmanr(obs, mod) np.float64(0.5) willmott(obs, mod) np.float64(0.7484604452865941) hit_ratio(obs, mod, a=0.5) np.float64(0.6666666666666666) ev(obs, mod) np.float64(0.39614855570839064)"
  },
  {
    "objectID": "user-guide/statistics.html",
    "href": "user-guide/statistics.html",
    "title": "Skill Statistics",
    "section": "",
    "text": "The Comparer and ComparerCollection objects in ModelSkill allow for detailed performance evaluation of models through skill metrics. These metrics are organized in a SkillTable object, which can be further filtered, analyzed, and visualized to gain insights into model accuracy and reliability.\nConstruct comparer from observation and model data\nimport modelskill as ms\no1 = ms.observation(\"../data/SW/HKNA_Hm0.dfs0\", item=0,\n                    x=4.2420, y=52.6887,\n                    name=\"HKNA\")\no2 = ms.observation(\"../data/SW/eur_Hm0.dfs0\", item=0,\n                    x=3.2760, y=51.9990, \n                    name=\"EPL\")\nm1 = ms.model_result(\"../data/SW/HKZN_local_2017_DutchCoast.dfsu\", \n                      item=\"Sign. Wave Height\",\n                      name=\"m1\")\nm2 = ms.model_result(\"../data/SW/CMEMS_DutchCoast_2017-10-28.nc\", \n                      item=\"VHM0\",\n                      name=\"m2\")\ncc = ms.match([o1, o2], [m1, m2])\ncc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: HKNA - Significant wave height [m]\n1: EPL - Significant wave height [m]",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#generating-a-skilltable",
    "href": "user-guide/statistics.html#generating-a-skilltable",
    "title": "Skill Statistics",
    "section": "Generating a SkillTable",
    "text": "Generating a SkillTable\nThe skill and mean_skill methods generate a SkillTable by comparing observations and model results using various skill metrics. It supports grouping and aggregation through the by parameter.\nSyntax: ComparerCollection.skill(by=None, metrics=None)\n\n\n\n\n\n\n\n\n\nParameter\nType\nDescription\nDefault\n\n\n\n\nby\nstr or list\nGroup by column names, temporal bins (e.g., freq:M for monthly), or attributes like attrs.\nNone\n\n\nmetrics\nlist\nList of metrics (e.g., rmse, bias). Default uses predefined metrics.\nNone\n\n\n\n\n\n\n\n\n\nExample 1: Generating a SkillTable\n\nsk = cc.skill(metrics=[\"bias\", \"rmse\", \"si\"])\nsk\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nHKNA\n120\n-0.076142\n0.190451\n0.060252\n\n\nEPL\n22\n-0.190022\n0.226535\n0.049538\n\n\nm2\nHKNA\n120\n-0.525915\n0.574975\n0.080212\n\n\nEPL\n22\n-0.428523\n0.457555\n0.064425\n\n\n\n\n\n\n\nThis generates a SkillTable containing metrics for all observations and models.\nExample 2: Grouping skill scores\n\nsk_by6hr = cc.skill(by=['model','freq:6h'], \n                    metrics=[\"bias\", \"mae\"]\n                    )\nsk_by6hr\n\n\n\n\n\n\n\n\n\nn\nbias\nmae\n\n\nmodel\ntime\n\n\n\n\n\n\n\nm1\n2017-10-28 00:00:00\n35\n-0.077149\n0.105698\n\n\n2017-10-28 06:00:00\n42\n-0.155072\n0.190004\n\n\n2017-10-28 12:00:00\n42\n-0.093342\n0.174382\n\n\n2017-10-28 18:00:00\n23\n-0.007996\n0.172298\n\n\nm2\n2017-10-28 00:00:00\n35\n-0.235906\n0.235906\n\n\n2017-10-28 06:00:00\n42\n-0.518031\n0.518031\n\n\n2017-10-28 12:00:00\n42\n-0.660042\n0.660042\n\n\n2017-10-28 18:00:00\n23\n-0.643544\n0.643544\n\n\n\n\n\n\n\nHere, skill scores are grouped by 6 hour (freq:6h), but it could also be by month or year, making it possible to analyze performance trends over time.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#filtering-a-skilltable",
    "href": "user-guide/statistics.html#filtering-a-skilltable",
    "title": "Skill Statistics",
    "section": "Filtering a SkillTable",
    "text": "Filtering a SkillTable\nThe SkillTable object supports several methods for filtering and refining data. The sel() method allows selection of specific models or observations, while the query() method enables flexible condition-based filtering.\nExample 3: Selecting a specific model\n\nsk_m1 = sk.sel(model='m1')\nsk_m1\n\n\n\n\n\n\n\n\nmodel\nn\nbias\nrmse\nsi\n\n\nobservation\n\n\n\n\n\n\n\n\n\nHKNA\nm1\n120\n-0.076142\n0.190451\n0.060252\n\n\nEPL\nm1\n22\n-0.190022\n0.226535\n0.049538\n\n\n\n\n\n\n\nThis filters the SkillTable to include results for the model named “m1”. See more about filtering on the Selecting data page.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#sorting-a-skilltable",
    "href": "user-guide/statistics.html#sorting-a-skilltable",
    "title": "Skill Statistics",
    "section": "Sorting a SkillTable",
    "text": "Sorting a SkillTable\nThe SkillTable supports sorting by index or values, and swapping levels in a MultiIndex to reorganize the data.\nExample 4: Sorting by index\n\nsk_sorted = sk.sort_index()\nsk_sorted\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nEPL\n22\n-0.190022\n0.226535\n0.049538\n\n\nHKNA\n120\n-0.076142\n0.190451\n0.060252\n\n\nm2\nEPL\n22\n-0.428523\n0.457555\n0.064425\n\n\nHKNA\n120\n-0.525915\n0.574975\n0.080212\n\n\n\n\n\n\n\nThis sorts the SkillTable by its index levels.\nExample 5: Sorting by a specific index level\n\nsk_sorted_obs = sk.sort_index(level=\"observation\")\nsk_sorted_obs\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nEPL\n22\n-0.190022\n0.226535\n0.049538\n\n\nm2\nEPL\n22\n-0.428523\n0.457555\n0.064425\n\n\nm1\nHKNA\n120\n-0.076142\n0.190451\n0.060252\n\n\nm2\nHKNA\n120\n-0.525915\n0.574975\n0.080212\n\n\n\n\n\n\n\nHere, the table is sorted specifically by the observation level in the index.\nExample 6: Sorting by values\n\nsk_sorted_values = sk.sort_values(\"rmse\")\nsk_sorted_values\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nHKNA\n120\n-0.076142\n0.190451\n0.060252\n\n\nEPL\n22\n-0.190022\n0.226535\n0.049538\n\n\nm2\nEPL\n22\n-0.428523\n0.457555\n0.064425\n\n\nHKNA\n120\n-0.525915\n0.574975\n0.080212\n\n\n\n\n\n\n\nThis sorts the table by the rmse column in ascending order.\nExample 7: Sorting by multiple values\n\nsk_sorted_multi = sk.sort_values([\"n\", \"rmse\"], ascending=[True, False])\nsk_sorted_multi\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm2\nEPL\n22\n-0.428523\n0.457555\n0.064425\n\n\nm1\nEPL\n22\n-0.190022\n0.226535\n0.049538\n\n\nm2\nHKNA\n120\n-0.525915\n0.574975\n0.080212\n\n\nm1\nHKNA\n120\n-0.076142\n0.190451\n0.060252\n\n\n\n\n\n\n\nHere, the table is sorted first by column n (ascending) and then by rmse (descending).\nExample 8: Swapping index levels\n\nsk_swapped = sk.swaplevel(\"model\", \"observation\").sort_index()\nsk_swapped\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nobservation\nmodel\n\n\n\n\n\n\n\n\nEPL\nm1\n22\n-0.190022\n0.226535\n0.049538\n\n\nm2\n22\n-0.428523\n0.457555\n0.064425\n\n\nHKNA\nm1\n120\n-0.076142\n0.190451\n0.060252\n\n\nm2\n120\n-0.525915\n0.574975\n0.080212\n\n\n\n\n\n\n\nThis swaps the model and observation levels in the MultiIndex and sorts the resulting table.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#rounding-and-formatting",
    "href": "user-guide/statistics.html#rounding-and-formatting",
    "title": "Skill Statistics",
    "section": "Rounding and Formatting",
    "text": "Rounding and Formatting\nThe round() method can be used to round all skill values to a specified number of decimal places, making the table more readable.\nExample 9: Rounding skill values\n\nsk.round(decimals=2)\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nHKNA\n120\n-0.08\n0.19\n0.06\n\n\nEPL\n22\n-0.19\n0.23\n0.05\n\n\nm2\nHKNA\n120\n-0.53\n0.57\n0.08\n\n\nEPL\n22\n-0.43\n0.46\n0.06\n\n\n\n\n\n\n\nThis rounds all values in the SkillTable to two decimal places.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#visualizing-skill-metrics",
    "href": "user-guide/statistics.html#visualizing-skill-metrics",
    "title": "Skill Statistics",
    "section": "Visualizing Skill Metrics",
    "text": "Visualizing Skill Metrics\nThe SkillTable integrates table styling and plotting capabilities, allowing you to quickly visualize skill metrics.\nExample 10: Styling the SkillTable\n\nsk.style()\n\n\n\n\n\n\n \n \nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n \n \n \n \n\n\n\n\nm1\nHKNA\n120\n-0.076\n0.190\n0.060\n\n\nEPL\n22\n-0.190\n0.227\n0.050\n\n\nm2\nHKNA\n120\n-0.526\n0.575\n0.080\n\n\nEPL\n22\n-0.429\n0.458\n0.064\n\n\n\n\n\nThe style() method applies color-based styling to the table, making it easier to identify high and low values.\nIndividual metrics can be accessed as columns and plotted using pandas-style plotting.\nExample 11: Plotting a bar chart for RMSE\n\nsk.rmse.plot.bar(figsize=(5,3))\n\n\n\n\n\n\n\n\nThis creates a bar chart showing RMSE values for each model-observation pair.\nExample 12: Line plot\n\nsk_by3hr = cc.skill(by=['model','freq:3h'])\nsk_by3hr.rmse.plot.line(title=\"RMSE in 3 hour groups\")\n\n\n\n\n\n\n\n\nThis generates a line plot showing RMSE values over the index.\nExample 13: Bar chart\n\nsk.rmse.plot.bar()\n\n\n\n\n\n\n\n\nThis creates a bar chart showing RMSE values for each model-observation pair.\nExample 14: Horizontal bar chart\n\nsk.rmse.plot.barh()\n\n\n\n\n\n\n\n\nThis generates a horizontal bar chart for RMSE values.\nExample 15: Colored grid\n\nsk.rmse.plot.grid()\n\n\n\n\n\n\n\n\nThis produces a colored grid representation of the skill metrics, which can help identify patterns.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#exporting-a-skilltable",
    "href": "user-guide/statistics.html#exporting-a-skilltable",
    "title": "Skill Statistics",
    "section": "Exporting a SkillTable",
    "text": "Exporting a SkillTable\nFor further analysis, the SkillTable can be converted to a standard pandas.DataFrame or a GeoDataFrame for spatial data.\nExample 16: Converting to DataFrame\n\ndf = sk.to_dataframe()\ndf\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nsi\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\nm1\nHKNA\n120\n-0.076142\n0.190451\n0.060252\n\n\nEPL\n22\n-0.190022\n0.226535\n0.049538\n\n\nm2\nHKNA\n120\n-0.525915\n0.574975\n0.080212\n\n\nEPL\n22\n-0.428523\n0.457555\n0.064425\n\n\n\n\n\n\n\nThis converts the SkillTable into a pandas.DataFrame for additional processing.\nExample 17: Converting to GeoDataFrame\ngdf = sk.to_geodataframe()\nThis converts the table to a GeoDataFrame, enabling spatial analysis of model performance.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/statistics.html#summary-of-key-methods",
    "href": "user-guide/statistics.html#summary-of-key-methods",
    "title": "Skill Statistics",
    "section": "Summary of Key Methods",
    "text": "Summary of Key Methods\nThe SkillTable object provides tools to filter, format, and visualize skill metrics efficiently:\n\nsel(): Select specific models or observations.\nquery(): Apply flexible condition-based filtering.\nsort_index(): Sort the table by index levels.\nsort_values(): Sort the table by specific metric values.\nswaplevel(): Swap levels in the MultiIndex for reorganization.\nround(): Round skill values to improve readability.\nplot.line(): Generate a line plot for skill metrics.\nplot.bar(): Visualize metrics as a bar chart.\nplot.barh(): Create a horizontal bar chart.\nplot.grid(): Display a colored grid of skill metrics.\nstyle(): Apply color-based formatting for easy interpretation.\nto_dataframe(): Export to pandas.DataFrame.\nto_geodataframe(): Export to GeoDataFrame for spatial analysis.\n\nBy combining these methods, you can analyze model performance in detail, identify trends, and communicate results effectively.",
    "crumbs": [
      "User Guide",
      "Skill Statistics"
    ]
  },
  {
    "objectID": "user-guide/matching.html",
    "href": "user-guide/matching.html",
    "title": "Matching",
    "section": "",
    "text": "Once observations and model results have been defined, the next step is to match them. This is done using the match function which handles the allignment of the observation and model result data in space and time. Note that if the data is already matched, the from_matched function can be used to create a Comparer directly from the matched data and the matching described here is not needed.\nThe matching process will be different depending on the geometry of observation and model result:",
    "crumbs": [
      "User Guide",
      "Matching"
    ]
  },
  {
    "objectID": "user-guide/matching.html#temporal-matching",
    "href": "user-guide/matching.html#temporal-matching",
    "title": "Matching",
    "section": "Temporal matching",
    "text": "Temporal matching\nTemporal matching is done by interpolating the model result data to the observation data time points; it is carried out after spatial matching when applicable. The interpolation is linear in time and done inside the match function.",
    "crumbs": [
      "User Guide",
      "Matching"
    ]
  },
  {
    "objectID": "user-guide/matching.html#matching-of-time-series",
    "href": "user-guide/matching.html#matching-of-time-series",
    "title": "Matching",
    "section": "Matching of time series",
    "text": "Matching of time series\nIf observation and model result are of the same geometry, the matching is done one observation at a time. Several model results can be matched to the same observation. The result of the matching process is a Comparer object which contains the matched data.\nIn the most simple cases, one observation to one model result, the match function can be used directly, without creating Observation and ModelResult objects first:\n\nimport modelskill as ms\ncmp = ms.match(\"../data/SW/HKNA_Hm0.dfs0\", \"../data/SW/HKNA_Hm0_Model.dfs0\", gtype='point')\ncmp\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA_Hm0, n_points=554\nModel(s):\n0: HKNA_Hm0_Model\n\n\nIn all other cases, the observations and model results needs to be defined first.",
    "crumbs": [
      "User Guide",
      "Matching"
    ]
  },
  {
    "objectID": "user-guide/matching.html#matching-with-dfsu-or-grid-model-result",
    "href": "user-guide/matching.html#matching-with-dfsu-or-grid-model-result",
    "title": "Matching",
    "section": "Matching with dfsu or grid model result",
    "text": "Matching with dfsu or grid model result\nIf the model result is a SpatialField, i.e., either a GridModelResult or a DfsuModelResult, and the observation is of lower dimension (e.g. point), then the model result needs to be extracted before matching can be done. This can be done “offline” before using ModelSkill, e.g., using MIKE tools or MIKE IO, or as part of the matching process using ModelSkill. We will here focus on the latter.\nIn this situation, multiple observations can be matched to the same model result, in which case the match function returns a ComparerCollection instead of a Comparer which is the returned object for single observation matching.\n\no1 = ms.observation(\"../data/SW/HKNA_Hm0.dfs0\", item=0,\n                    x=4.2420, y=52.6887,\n                    name=\"HKNA\")\nmr_dfsu = ms.model_result(\"../data/SW/HKZN_local_2017_DutchCoast.dfsu\", \n                      item=\"Sign. Wave Height\",\n                      name=\"HKZN_local\")\nmr_nc = ms.model_result(\"../data/SW/CMEMS_DutchCoast_2017-10-28.nc\", \n                      item=\"VHM0\",\n                      name=\"CMEMS\")\ncmp = ms.match(o1, [mr_dfsu, mr_nc])\ncmp\n\n&lt;Comparer&gt;\nQuantity: Significant wave height [m]\nObservation: HKNA, n_points=120\nModel(s):\n0: HKZN_local\n1: CMEMS\n\n\nIn most cases, several observations needs to matched with several model results. This can be done by constructing a list of Comparer objects and then combining them into a ComparerCollection:\n\no2 = ms.observation(\"../data/SW/eur_Hm0.dfs0\", item=0,\n                     x=3.2760, y=51.9990,\n                     name=\"EPL\")\n                     \nobservations = [o1, o2]\ncmps = []\nfor o in observations:\n     cmps.append(ms.match(o, [mr_dfsu, mr_nc]))\ncc = ms.ComparerCollection(cmps)\ncc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: HKNA - Significant wave height [m]\n1: EPL - Significant wave height [m]\n\n\nMatching PointObservation with SpatialField model results consists of two steps:\n\nExtracting data from the model result at the spatial position of the observation, which returns a PointModelResult\nMatching the extracted data with the observation data in time\n\nMatching TrackObservation with SpatialField model results is for technical reasons handled in one step, i.e., the data is extracted in both space and time.\nThe spatial matching method (selection or interpolation) can be specified using the spatial_method argument of the match function. The default method depends on the type of observation and model result as specified in the sections below.\n\nExtracting data from a DfsuModelResult\nExtracting data for a specific point position from the flexible mesh dfsu files can be done in several ways (specified by the spatial_method argument of the match function):\n\nSelection of the “contained” element\nSelection of the “nearest” element (often the same as the contained element, but not always)\nInterpolation with “inverse_distance” weighting (IDW) using the five nearest elements (default)\n\nThe default (inverse_distance) is not necessarily the best method in all cases. When the extracted position is close to the model boundary, “contained” may be a better choice.\n\ncc = ms.match([o1, o2], mr_dfsu, spatial_method='contained')   \n\n\n\n\n\n\n\nNote\n\n\n\n\nExtraction of track data does not currently support the “contained” method.\nExtraction of point data from 3D dfsu files is not yet fully supported. It is recommended to extract the data “offline” prior to using ModelSkill.\n\n\n\n\n\nExtracting data from a GridModelResult\nExtracting data from a GridModelResult is done through xarray’s interp() function. The spatial_method argument of the match function is passed on to the interp() function as the method argument. The default method is “linear” which is the recommended method for most cases. Close to land where the grid model result data is often missing, “nearest” may be a better choice.\n\ncc = ms.match([o1, o2], mr_nc, spatial_method='nearest')",
    "crumbs": [
      "User Guide",
      "Matching"
    ]
  },
  {
    "objectID": "user-guide/matching.html#event-based-matching-and-handling-of-gaps",
    "href": "user-guide/matching.html#event-based-matching-and-handling-of-gaps",
    "title": "Matching",
    "section": "Event-based matching and handling of gaps",
    "text": "Event-based matching and handling of gaps\nIf the model result data contains gaps either because only events are stored or because of missing data, the max_model_gap argument of the match function can be used to specify the maximum allowed gap (in seconds) in the model result data. This will avoid interpolating model data over long gaps in the model result data!",
    "crumbs": [
      "User Guide",
      "Matching"
    ]
  },
  {
    "objectID": "user-guide/matching.html#multiple-model-results-with-different-temporal-coverage",
    "href": "user-guide/matching.html#multiple-model-results-with-different-temporal-coverage",
    "title": "Matching",
    "section": "Multiple model results with different temporal coverage",
    "text": "Multiple model results with different temporal coverage\nIf the model results have different temporal coverage, the match function will only match the overlapping time period to ensure that the model results are comparable. The Comparer object will contain the matched data for the overlapping period only.",
    "crumbs": [
      "User Guide",
      "Matching"
    ]
  },
  {
    "objectID": "user-guide/overview.html",
    "href": "user-guide/overview.html",
    "title": "Overview",
    "section": "",
    "text": "ModelSkill compares model results with observations. The workflow can be split in two phases:\nIf the observations and model results are already matched (i.e. are stored in the same data source), the from_matched() function can be used to go directly to the analysis phase. If not, the match() function can be used to match the observations and model results in space and time.",
    "crumbs": [
      "User Guide",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/overview.html#matching",
    "href": "user-guide/overview.html#matching",
    "title": "Overview",
    "section": "Matching",
    "text": "Matching\nIf the observations and model results are not in the same data source (e.g. dfs0 file), they will need to be defined and then matched in space and time with the match() function. In simple cases, observations and model results can be defined directly in the match() function:\n\nimport modelskill as ms\ncmp = ms.match(\"../data/obs.dfs0\", \"../data/model.dfs0\",\n               obs_item=\"obs_WL\", mod_item=\"WL\",\n               gtype='point')\n\nBut in most cases, the observations and model results will need to be defined separately first.\n\nDefine observations\nThe observations can be defined as either a PointObservation or a TrackObservation (a moving point).\n\no1 = ms.PointObservation(\"../data/obs.dfs0\", item=\"obs_WL\",x=366844.15, y=6154291.6)\n\nThe item needs to be specified as either the item number or the item name if the input file contains multiple items. Several other parameters can be specified, such as the name of the observation, the x- and y-position, and the quantity type and unit of the observation.\n\n\nDefine model results\nA model result will either be a simple point/track like the observations, or spatial field (e.g. 2d dfsu file) from which the model results will be extracted at the observation positions. The following types are available:\n\nPointModelResult - a point result from a dfs0/nc file or a DataFrame\nTrackModelResult - a track result from a dfs0/nc file or a DataFrame\nGridModelResult - a spatial field from a dfs2/nc file or a Xarray Dataset\nDfsuModelResult - a spatial field from a dfsu file\n\n\nmr1 = ms.PointModelResult(\"../data/model.dfs0\", item=\"WL\")\n\n\n\nMatch observations and model results\nThe match() function will interpolate the model results to the time (and space) of the observations and return a collection of Comparer objects that can be used for analysis.\n\ncc = ms.match(o1, mr1)\ncc\n\n&lt;Comparer&gt;\nQuantity: Water Level [m]\nObservation: obs, n_points=167\nModel(s):\n0: model",
    "crumbs": [
      "User Guide",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/overview.html#analysis",
    "href": "user-guide/overview.html#analysis",
    "title": "Overview",
    "section": "Analysis",
    "text": "Analysis\nOnce the observations and model results are matched, the Comparer object can be used for analysis and plotting.",
    "crumbs": [
      "User Guide",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/workflow.html",
    "href": "user-guide/workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "A typical ModelSkill workflow consists of these four steps:",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "user-guide/workflow.html#define-observations",
    "href": "user-guide/workflow.html#define-observations",
    "title": "Workflow",
    "section": " Define Observations",
    "text": "Define Observations\nThe first step is to define the measurements to be used for the skill assessment. Two types of observation are available:\n\nPointObservation\nTrackObservation\n\nLet’s assume that we have one PointObservation and one TrackObservation (name is used to identify the observation, similar to the name of the model above).\n\nimport modelskill as ms\nhkna = ms.PointObservation(\"../data/SW/HKNA_Hm0.dfs0\", item=0,\n                            x=4.2420, y=52.6887,\n                            name=\"HKNA\")\n\nc2 = ms.TrackObservation(\"../data/SW/Alti_c2_Dutch.dfs0\", item=3,\n                          name=\"c2\")\n\nIn this case both observations are provided as .dfs0 files but pandas dataframes are also supported in case data are stored in another file format.\nBoth PointObservation and TrackObservation need the path of the data file, the item number (or item name) and a name. A PointObservation further needs to be initialized with it's x-, y-position.",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "user-guide/workflow.html#define-modelresults",
    "href": "user-guide/workflow.html#define-modelresults",
    "title": "Workflow",
    "section": " Define ModelResults",
    "text": "Define ModelResults\nThe result of a simulation is stored in one or more result files, e.g. dfsu, dfs0, nc, csv.\nThe name is used to identify the model result in the plots and tables.\n\nmr = ms.DfsuModelResult(\"../data/SW/HKZN_local_2017_DutchCoast.dfsu\", \n                         item=\"Sign. Wave Height\",\n                         name='HKZN_local')",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "user-guide/workflow.html#match-observations-and-modelresults",
    "href": "user-guide/workflow.html#match-observations-and-modelresults",
    "title": "Workflow",
    "section": " Match observations and ModelResults",
    "text": "Match observations and ModelResults\nThe match() function returns a Comparer (a single observation) or a ComparerCollection (multiple observations) for further analysis and plotting.\n\ncc = ms.match([hkna, c2], mr)\ncc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: HKNA - Significant wave height [m]\n1: c2 - Significant wave height [m]\n\n\nSee matching page for more information.",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "user-guide/workflow.html#do-analysis-plotting-etc-with-a-comparer",
    "href": "user-guide/workflow.html#do-analysis-plotting-etc-with-a-comparer",
    "title": "Workflow",
    "section": " Do analysis, plotting, etc with a Comparer",
    "text": "Do analysis, plotting, etc with a Comparer\nThe object returned by the match() function is a Comparer/ComparerCollection. It holds the matched observation and model data and has methods for plotting and skill assessment.\nThe primary comparer methods are:\n\nskill() which returns a SkillTable with the skill scores\nvarious plot methods of the comparer objects (e.g. plot.scatter(), plot.timeseries())\nsel() method for selecting data",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "user-guide/workflow.html#filtering",
    "href": "user-guide/workflow.html#filtering",
    "title": "Workflow",
    "section": " Filtering",
    "text": "Filtering\nIn order to select only a subset of the data for analysis, the comparer has a sel() method which returns a new comparer with the selected data.\nThis method allow filtering of the data in several ways:\n\non observation by specifying name or index of one or more observations\non model (if more than one is compared) by giving name or index\ntemporal using the time (or start and end) arguments\nspatial using the area argument given as a bounding box or a polygon",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "user-guide/workflow.html#save-load-the-comparercollection",
    "href": "user-guide/workflow.html#save-load-the-comparercollection",
    "title": "Workflow",
    "section": " Save / load the ComparerCollection",
    "text": "Save / load the ComparerCollection\nIt can be useful to save the comparer collection for later use. This can be done using the save() method:\ncc.save(\"my_comparer_collection.msk\")\nThe comparer collection can be loaded again from disk, using the load() method:\ncc = ms.load(\"my_comparer_collection.msk\")",
    "crumbs": [
      "User Guide",
      "Workflow"
    ]
  },
  {
    "objectID": "examples/Metrics_custom_metric.html",
    "href": "examples/Metrics_custom_metric.html",
    "title": "Custom Metrics",
    "section": "",
    "text": "ModelSkill comes with many metrics to choose from, but you can also define your own.\n\nimport numpy as np\nimport modelskill as ms\n\n\nfn = '../data/SW/HKZN_local_2017_DutchCoast.dfsu'\nmr = ms.model_result(fn, name='HKZN_local', item=0)\no1 = ms.PointObservation('../data/SW/HKNA_Hm0.dfs0', item=0, x=4.2420, y=52.6887, name=\"HKNA\")\no2 = ms.PointObservation(\"../data/SW/eur_Hm0.dfs0\", item=0, x=3.2760, y=51.9990, name=\"EPL\")\no3 = ms.TrackObservation(\"../data/SW/Alti_c2_Dutch.dfs0\", item=3, name=\"c2\")\ncc = ms.match([o1, o2, o3], mr)\ncc\n\n&lt;ComparerCollection&gt;\nComparers:\n0: HKNA - Significant wave height [m]\n1: EPL - Significant wave height [m]\n2: c2 - Significant wave height [m]\n\n\nStandard set of metrics\n\ncc.skill()\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nobservation\n\n\n\n\n\n\n\n\n\n\n\n\nHKNA\n386\n-0.202413\n0.355195\n0.291877\n0.255866\n0.971708\n0.093967\n0.903554\n\n\nEPL\n67\n-0.071238\n0.224923\n0.213344\n0.189455\n0.969760\n0.082482\n0.931793\n\n\nc2\n113\n-0.004701\n0.352470\n0.352439\n0.294758\n0.975050\n0.128010\n0.899121\n\n\n\n\n\n\n\nSome metrics has parameters, which require a bit special treatment.\n\nfrom modelskill.metrics import hit_ratio, metric\n\n@metric(best=\"+\")\ndef hit_ratio_05_pct(obs, model):\n    return hit_ratio(obs, model, 0.5) * 100\n\n@metric(best=\"+\")\ndef hit_ratio_01_pct(obs, model):\n    return hit_ratio(obs, model, 0.1) * 100\n\n\ncc.skill(metrics=[hit_ratio_05_pct, hit_ratio_01_pct])\n\n\n\n\n\n\n\n\nn\nhit_ratio_05_pct\nhit_ratio_01_pct\n\n\nobservation\n\n\n\n\n\n\n\nHKNA\n386\n86.528497\n27.720207\n\n\nEPL\n67\n98.507463\n26.865672\n\n\nc2\n113\n85.840708\n17.699115\n\n\n\n\n\n\n\nAnd you are always free to specify your own special metric or import metrics from other libraries, e.g. scikit-learn.\n\n@metric(best=\"-\", has_units=True)\ndef mcae(obs, model):\n\n    res = obs - model\n\n    res_clipped = np.clip(res,0,np.inf)\n\n    return np.mean(np.abs(res_clipped))\n\n\ncc.skill(metrics=mcae).style()\n\n\n\n\n\n\n \nn\nmcae\n\n\nobservation\n \n \n\n\n\n\nHKNA\n386\n0.229\n\n\nEPL\n67\n0.130\n\n\nc2\n113\n0.150",
    "crumbs": [
      "Examples",
      "Custom metric"
    ]
  },
  {
    "objectID": "examples/Hydrology_Vistula_Catchment.html",
    "href": "examples/Hydrology_Vistula_Catchment.html",
    "title": "Hydrology example from the Vistula catchment in Poland",
    "section": "",
    "text": "The Vistula catchment is the largest catchment in Poland, with an area of 194,424 km2. This notebook shows how a hydrological model can evaluated using ModelSkill.\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport modelskill as ms\nfldr = Path(\"../data/Vistula\")\ndf = pd.read_csv(fldr / \"stations.csv\", index_col=0)\ndf\n\n\n\n\n\n\n\n\nStation\nLong\nLat\nArea\n\n\nId\n\n\n\n\n\n\n\n\n6458010\nVISTULA (TCZEW)\n18.80556\n54.08722\n193922.9\n\n\n6458500\nVISTULA (WARSAW (WARSZAWA))\n21.03250\n52.24750\n84945.1\n\n\n6458753\nPILICA (PRZEDBORZ)\n19.87528\n51.08944\n2550.1\n\n\n6458715\nWIEPRZ (LUBARTOW)\n22.64361\n51.49806\n6389.8\n\n\n6458713\nWIEPRZ (KRASNYSTAW)\n23.17667\n50.98528\n3010.2\n\n\n6458520\nKAMIENNA (KUNOW)\n21.27889\n50.96194\n1110.4\n\n\n6458460\nVISTULA (SANDOMIERZ)\n21.74611\n50.67250\n31809.9\n\n\n6458450\nVISTULA (SZCZUCIN)\n21.07722\n50.32694\n23869.3\n\n\n6458406\nDUNAJEC (NOWY SACZ)\n20.68722\n49.62722\n4337.4\n\n\n6158100\nPOPRAD (CHMELNICA)\n20.73023\n49.28918\n1262.0\n\n\n6458950\nWISLOK (TRYNCZA)\n22.54722\n50.16222\n3523.6\n\n\n6458863\nPISA (PTAKI)\n21.79250\n53.39306\n3575.7\n\n\n6458805\nNAREW (SURAZ)\n22.95500\n52.94889\n3425.3\n\n\n6458924\nLIWIEC (LOCHOW)\n21.67833\n52.51000\n2471.4\n\n\n6458555\nKRZNA (MALOWA GORA)\n23.46750\n52.10361\n3041.9\ndef get_comparer(df, mods, id):\n    \"\"\"Get a Comparer object for a given model and station id\"\"\"\n    q = ms.Quantity(name=\"Discharge\", unit=\"m3/s\")\n\n    # create Observation object\n    fp = fldr / mods[0] / f\"{id}.csv\"\n    dfd = pd.read_csv(fp, index_col=0, parse_dates=True)\n    o = ms.PointObservation(dfd, item=\"Qobs\", name=df.loc[id].Station,\n                            x=df.loc[id].Long, y=df.loc[id].Lat, quantity=q)\n    \n    # create ModelResult objects\n    mm = []\n    for m in mods:\n        fp = fldr / m / f\"{id}.csv\"\n        dfd = pd.read_csv(fp, index_col=0, parse_dates=True)\n        mm.append(ms.PointModelResult(dfd, item=\"Qsim\", name=m, quantity=q))\n    \n    return ms.match(obs=o, mod=mm)",
    "crumbs": [
      "Examples",
      "Hydrology Vistula Catchment"
    ]
  },
  {
    "objectID": "examples/Hydrology_Vistula_Catchment.html#compare-a-single-observation-with-two-model-results",
    "href": "examples/Hydrology_Vistula_Catchment.html#compare-a-single-observation-with-two-model-results",
    "title": "Hydrology example from the Vistula catchment in Poland",
    "section": "Compare a single observation with two model results",
    "text": "Compare a single observation with two model results\n\ncmp = get_comparer(df, [\"sim1\",\"sim2\"], df.index[0])\ncmp\n\n&lt;Comparer&gt;\nQuantity: Discharge [m3/s]\nObservation: VISTULA (TCZEW), n_points=3653\nModel(s):\n0: sim1\n1: sim2\n\n\n\nPlots\ntimeseries, scatter, boxplot, hist, kde, qq, taylor\n\ncmp.plot.timeseries();\n\n\n\n\n\n\n\n\n\ncmp.sel(model=\"sim1\").plot.scatter();\n\n\n\n\n\n\n\n\n\n\nSummary statistics\n\n# set default metrics\nms.options.metrics.list = [\"kge\", \"cc\"]\n\n\ncmp.skill().round(3)\n\n\n\n\n\n\n\n\n\nn\nkge\ncc\n\n\nmodel\nobservation\n\n\n\n\n\n\n\nsim1\nVISTULA (TCZEW)\n3653\n0.617\n0.794\n\n\nsim2\nVISTULA (TCZEW)\n3653\n0.809\n0.829\n\n\n\n\n\n\n\n\n\nStatistics aggregated by month\n\ncmp.data[\"month\"] = cmp.time.to_series().dt.month\n\n\ncmp.skill(by=[\"model\",\"month\"]) #[\"kge\"].plot.bar();\n\n\n\n\n\n\n\n\n\nobservation\nn\nkge\ncc\n\n\nmodel\nmonth\n\n\n\n\n\n\n\n\nsim1\n1\nVISTULA (TCZEW)\n310\n0.385138\n0.440905\n\n\n2\nVISTULA (TCZEW)\n283\n0.578280\n0.803975\n\n\n3\nVISTULA (TCZEW)\n310\n0.454622\n0.730561\n\n\n4\nVISTULA (TCZEW)\n300\n0.509017\n0.834517\n\n\n5\nVISTULA (TCZEW)\n310\n0.575944\n0.697614\n\n\n6\nVISTULA (TCZEW)\n300\n0.344820\n0.493330\n\n\n7\nVISTULA (TCZEW)\n310\n0.052140\n0.298390\n\n\n8\nVISTULA (TCZEW)\n310\n0.219232\n0.667376\n\n\n9\nVISTULA (TCZEW)\n300\n0.376622\n0.552289\n\n\n10\nVISTULA (TCZEW)\n310\n0.626824\n0.717061\n\n\n11\nVISTULA (TCZEW)\n300\n0.643888\n0.741710\n\n\n12\nVISTULA (TCZEW)\n310\n0.288263\n0.452674\n\n\nsim2\n1\nVISTULA (TCZEW)\n310\n0.580579\n0.622109\n\n\n2\nVISTULA (TCZEW)\n283\n0.844779\n0.887547\n\n\n3\nVISTULA (TCZEW)\n310\n0.669936\n0.767161\n\n\n4\nVISTULA (TCZEW)\n300\n0.764530\n0.809858\n\n\n5\nVISTULA (TCZEW)\n310\n0.487875\n0.655435\n\n\n6\nVISTULA (TCZEW)\n300\n0.496136\n0.695364\n\n\n7\nVISTULA (TCZEW)\n310\n0.235510\n0.540092\n\n\n8\nVISTULA (TCZEW)\n310\n0.269188\n0.773781\n\n\n9\nVISTULA (TCZEW)\n300\n0.526274\n0.741995\n\n\n10\nVISTULA (TCZEW)\n310\n0.719504\n0.863399\n\n\n11\nVISTULA (TCZEW)\n300\n0.721616\n0.840079\n\n\n12\nVISTULA (TCZEW)\n310\n0.506460\n0.560932\n\n\n\n\n\n\n\n\ncmp.skill(by=[\"model\",\"month\"])[\"kge\"].plot.line()\nplt.xlabel(\"Month\")\nplt.xticks(np.arange(1,13), [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]);",
    "crumbs": [
      "Examples",
      "Hydrology Vistula Catchment"
    ]
  },
  {
    "objectID": "examples/Hydrology_Vistula_Catchment.html#compare-multiple-observations-with-two-model-results",
    "href": "examples/Hydrology_Vistula_Catchment.html#compare-multiple-observations-with-two-model-results",
    "title": "Hydrology example from the Vistula catchment in Poland",
    "section": "Compare multiple observations with two model results",
    "text": "Compare multiple observations with two model results\n\n# loop through all stations in df and create a Comparer for each\ncmps = []\nfor id in df.index:\n   try:\n      cmps.append(get_comparer(df, [\"sim1\",\"sim2\"], id))\n   except ValueError as e:\n      pass\ncc = ms.ComparerCollection(cmps)\ncc   \n\n&lt;ComparerCollection&gt;\nComparers:\n0: VISTULA (TCZEW) - Discharge [m3/s]\n1: PILICA (PRZEDBORZ) - Discharge [m3/s]\n2: WIEPRZ (LUBARTOW) - Discharge [m3/s]\n3: WIEPRZ (KRASNYSTAW) - Discharge [m3/s]\n4: KAMIENNA (KUNOW) - Discharge [m3/s]\n5: VISTULA (SANDOMIERZ) - Discharge [m3/s]\n6: VISTULA (SZCZUCIN) - Discharge [m3/s]\n7: DUNAJEC (NOWY SACZ) - Discharge [m3/s]\n8: POPRAD (CHMELNICA) - Discharge [m3/s]\n9: WISLOK (TRYNCZA) - Discharge [m3/s]\n10: PISA (PTAKI) - Discharge [m3/s]\n11: NAREW (SURAZ) - Discharge [m3/s]\n12: LIWIEC (LOCHOW) - Discharge [m3/s]\n13: KRZNA (MALOWA GORA) - Discharge [m3/s]\n\n\n\ncc.skill(by=[\"model\",\"observation\"], metrics=\"kge\")[\"kge\"].plot.barh();\n\n\n\n\n\n\n\n\n\n# Average skill over all stations, weighted by sqrt(area)\narea = df.set_index(\"Station\").loc[cc.obs_names].Area\ncc.mean_skill(weights=np.sqrt(area)).round(3)\n\n\n\n\n\n\n\n\nn\nkge\ncc\n\n\nmodel\n\n\n\n\n\n\n\nsim1\n51142\n0.504\n0.709\n\n\nsim2\n51142\n0.586\n0.717",
    "crumbs": [
      "Examples",
      "Hydrology Vistula Catchment"
    ]
  },
  {
    "objectID": "examples/Directional_data_comparison.html",
    "href": "examples/Directional_data_comparison.html",
    "title": "Comparing Directional Data (e.g. wind direction)",
    "section": "",
    "text": "Comparing directional data is easy from version 1.0 if the quantity is defined as directional. This happens automatically if data is loaded from a dfs file with EUM unit in “degrees” or if loaded from a xarray dataset with attribute “units” set to “degrees”. The quantity can also be created as directional manually by ms.Quantity(..., is_directional=True).\nIn the below example, the EUM unit is “degrees”.\n\nimport modelskill as ms\nimport mikeio\n\n\nfn = \"../data/wave_dir.dfs0\"\nds = mikeio.read(fn)\nds\n\n&lt;mikeio.Dataset&gt;\ndims: (time:9026)\ntime: 2006-12-20 22:00:00 - 2007-12-31 23:00:00 (9026 records)\ngeometry: GeometryUndefined()\nitems:\n  0:  China_Model: Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  1:  China_Measured: Sign. Wave Height &lt;Significant wave height&gt; (meter)\n  2:  China_Model: Mean Wave Direction &lt;Mean Wave Direction&gt; (degree)\n  3:  China_Measured: Mean Wave Direction &lt;Mean Wave Direction&gt; (degree)\n\n\n\ncmp = ms.from_matched(ds, obs_item=3, mod_items=[2])\ncmp\n\n&lt;Comparer&gt;\nQuantity: Mean Wave Direction [degree]\nObservation: China_Measured: Mean Wave Direction, n_points=9026\nModel(s):\n0: China_Model: Mean Wave Direction\n\n\n\ncmp.quantity\n\nQuantity(name='Mean Wave Direction', unit='degree', is_directional=True)\n\n\nCircular metrics are used to compare directional data if the quantity is defined as directional.\n\ncmp.skill(metrics=[\"c_rmse\",\"c_max_error\"]).round(1)\n\n\n\n\n\n\n\n\nn\nc_rmse\nc_max_error\n\n\nobservation\n\n\n\n\n\n\n\nChina_Measured: Mean Wave Direction\n9026\n60.7\n179.9\n\n\n\n\n\n\n\n\ncmp.plot.timeseries(figsize=(8,5));\n\n\n\n\n\n\n\n\n\ncmp.plot.kde();   # note: the KDE estimate is not directional! (yet)\n\n\n\n\n\n\n\n\n\ncmp.plot.scatter();  # note: regression line and Q-Q are not shown",
    "crumbs": [
      "Examples",
      "Directional data comparison"
    ]
  },
  {
    "objectID": "examples/Skill_vs_dummy.html",
    "href": "examples/Skill_vs_dummy.html",
    "title": "Is my model better than predicting the mean?",
    "section": "",
    "text": "It is easy to be convinced that a model is good if it has a low error.\nBut it is always a good idea to compare your model to a baseline, to see if it is actually better than just predicting the mean.\nThis can be done easily in modelskill thanks to the DummyModelResult class.\n\nimport modelskill as ms\n\nfn = '../data/Oresund2D.dfsu'\nmr = ms.model_result(fn, item='Surface elevation')\nmr\n\n&lt;DfsuModelResult&gt;: Oresund2D\nTime: 2018-03-04 00:00:00 - 2018-03-10 22:40:00\nQuantity: Surface Elevation [m]\n\n\n\nfn = '../data/smhi_2095_klagshamn.dfs0'\nobs = ms.PointObservation(fn, x=366844.15, y=6154291.6, item=0)\nobs\n\n&lt;PointObservation&gt;: smhi_2095_klagshamn\nLocation: 366844.15, 6154291.6\nTime: 2015-01-01 01:00:00 - 2020-09-28 00:00:00\nQuantity: Water Level [m]\n\n\n\ndmr = ms.DummyModelResult(data=0.0)\ndmr\n\nDummyModelResult(name='dummy', data=0.0, strategy='constant')\n\n\n\ncmp = ms.match(obs=obs, mod=[mr, dmr]).remove_bias()\ncmp.skill().round(3)\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\n\n\n\n\nOresund2D\nsmhi_2095_klagshamn\n167\n-0.0\n0.041\n0.041\n0.033\n0.84\n0.378\n0.704\n\n\ndummy\nsmhi_2095_klagshamn\n167\n-0.0\n0.075\n0.075\n0.061\n-0.00\n0.695\n0.000\n\n\n\n\n\n\n\n\ncmp.skill().rmse.plot.barh(title=\"Better than predicting 0.0\");\n\n\n\n\n\n\n\n\nAbove we created a DummyModelResult which always predicts 0.0.\nBut we can be even more lazy and just use the DummyModelResult with the mean strategy, which will predict the mean of the observed values.\n\ndmr2 = ms.DummyModelResult(strategy='mean')\ndmr2\n\nDummyModelResult(name='dummy', data=None, strategy='mean')\n\n\n\ncmp2 = ms.match(obs=obs, mod=[mr, dmr2]).remove_bias()\ncmp2.skill().round(3)\n\n\n\n\n\n\n\n\n\nn\nbias\nrmse\nurmse\nmae\ncc\nsi\nr2\n\n\nmodel\nobservation\n\n\n\n\n\n\n\n\n\n\n\n\nOresund2D\nsmhi_2095_klagshamn\n167\n-0.0\n0.041\n0.041\n0.033\n0.84\n0.378\n0.704\n\n\ndummy\nsmhi_2095_klagshamn\n167\n-0.0\n0.075\n0.075\n0.061\n0.00\n0.695\n0.000",
    "crumbs": [
      "Examples",
      "Compare with dummy results"
    ]
  }
]